{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karanghai/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain import PromptTemplate\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/karanghai/Library/Python/3.9/lib/python/site-packages/InstructorEmbedding/instructor.py:7: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name=\"hkunlp/instructor-large\", model_kwargs={\"device\": DEVICE}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OK, good morning, everybody. So last week, we stopped at the question, how do we calculate the gradients for more complex loss functions and classifiers? And we saw that the thing that we need is the backpropagation algorithm. So we want to make use of the chain rule of calculus to determine the gradient of some complex compute graph. So we take one compute graph where we know the gradient for each of the nodes, and we use the chain rule to multiply those individual gradients, and thereby getting the gradient for the more complex function. And if, for example, we use a the compute graph for logistic regression, where we say, OK, we have two inputs, so two parameters for each of the input dimensions, and one bias term, our compute graph is this dot product over here, adding the bias term, getting this linear unit over here, taking the sigma. OK. And then we can use the sigma function of all of this and doing, performing, calculating our loss function. And for each of those steps, we know the gradients for each',\n",
       " \"And for each of those steps, we know the gradients for each of those. For the loss function and the sigmoid, they are slightly more complicated, but we can just look up those gradients for each function and thereby get the gradient over there. And after we've looked it up, we can just add it into the compute graph, and we are happy. And if we say, OK, we put in our current values, so we're assuming this is the data point that we are looking at, and our current values for the three free parameters are those, we can do the forward calculations, so calculating the stock product, going forward, getting the result of the linear unit, calculating the sigmoid, and then getting the loss that we get. If we did a prediction that was with 37% probability, we think that the result is a positive example. So we would classify it as a 0. And actually, it is a positive example. So we somehow were off. So it means there should be some loss over here. And if we used cross entropy formula, we get a loss of close to 1. And if\",\n",
       " \"used cross entropy formula, we get a loss of close to 1. And if we do the backward calculation, we go through all of those parts over here and add in the values that we computed going forward into the formulas for the gradients. So here we need the y and the y hat that we calculated over here. We can plug this in, get this value for the gradient over here. We can plug in y hat. And we can plug in the y hat in the formula over here. So we have 0.378 times 1 minus 0.378. Get the value over here for the gradient here. And we can basically do that for all the other steps. It's kind of easy because we have linear parts over here. So the gradients are always 1. And for the last step over here, with multiplication, it's, it's always the value on the other side of the multiplication. So we have a minus 2 over here and 3 over here. And now using the chain rule, we can calculate, now that we know the individual gradients, we can just multiply up everything on the path down to each of those parameters that we are\",\n",
       " \"on the path down to each of those parameters that we are interested in. So we have three parameters. So we have three different paths that we can take through this entire graph. And if we multiply everything up, we're going to have, OK. we get the gradient for each of our parameters. So, and nothing changes if we make our neural network bigger. So, this logistic regression, which is a one-layer neural network, works like this. We get the gradients. In this case, we could also easily write down the formulas for each of the gradients for each of those terms because it's a small network. We could just write down the formulas. But as soon as it gets much, much bigger, the formulas get pretty unwieldy. And to help us there, using backpropagation and the compute graph representation, it doesn't matter how large everything from the parameter up till the loss function is. We can just kind of... mechanically do the gradient calculations by going through the compute graph and get the resulting gradients. There are a\",\n",
       " \"the compute graph and get the resulting gradients. There are a few things we can do to make calculations easier. In this case, if we combine the sigmoid and the loss function into a single node, then the gradient gets a little simpler because a lot of things cancel out over there. So, the gradient for the combined loss function, and sigmoid for combining cross-entropy loss and the sigmoid is just y hat minus y. So, this times this one over here will, in the end, just be y hat minus y. So, that kind of makes calculations easier because in a lot of cases, we use those in conjunction and we don't have to do that. The gradient of those in conjunction is just this simpler number. So, when implementing all of this, the hardest part is basically getting the vectorization parts right. So, in almost all cases, we just deal... So, at some point, we have to do the gradients for activations functions or loss functions, which are slightly more complicated. But in almost all cases, the gradients are that simple. So, the\",\n",
       " \"But in almost all cases, the gradients are that simple. So, the gradient of addition, multiplication, it's always just taking one of the numbers. We are multiplying up a lot of those gradients in the end, but we get away with basically just addition and multiplication in all of those cases. We just need to make sure to multiply and add the right entries everywhere. And if, for example, we do the gradient for the dot product, then if we do the gradient in the direction of w, it means we basically have this formula w1 times x1 plus w2 times x2 plus and so forth. And if we take the gradient in the direction of w1, everything here drops, and this one goes away too, and we are left with x1. So, the gradient in the direction of w1 would be x1. Same goes for in the direction of w2. Everything else drops. We are left with x2 and so on. So, the total gradient will just be a vector x1, x2, xn, which is just the entire vector x. So, it turns out... that the gradient of the dot product is kind of exactly the way that\",\n",
       " \"the gradient of the dot product is kind of exactly the way that the gradient works for... like if I just have two scalars that I multiply with each other, and so if I have a times b, and I want to take the gradient in the direction of e, that would just be b. So, a gradient in the direction of a would just be b. So... And for a dot product, it works exactly the same way. And in... somehow, this also kind of carries over if we do matrix vector multiplications later. So, if I have like... if we later on multiply some matrix with some vector, then we get kind of a... a lot of entries in here. So, and for each of those... and... for each of those entries, we just have like dot products over. And for each of those, again, we want to make sure that kind of the entries are correct. So, it's always kind of matching entries to where they belong. And we'll get more... do more about this later when we do... get to... like doing proper neural networks. But it's... kind of... always remember it's... it will... the\",\n",
       " \"But it's... kind of... always remember it's... it will... the results will... for all the calculations that you need to do will always be... kind of a... something pretty simple. Like in this case, it's kind of getting the gradient in the direction of W. It will be... it's X. And the... complicated part is always... just... getting the shape of those things right. And knowing which entry... sits in which position of the vector or the matrix that you are dealing with. So, it's... that's kind of... that's... what you have to keep in mind for... all of those things. So... that was backpropagation. And backpropagation is kind of the... the basic for... everything that we do when training... any kind of... larger machine learning system. Yeah? When do we use... the word content when... there is... an activation? There is no clear-cut rule for this. So, as an activation... So... there... there is certain cases where... where... you always use a sigmoid. So, for example, if you... have... so, if... if... if...\",\n",
       " \"So, for example, if you... have... so, if... if... if... So... if you think of a larger neural network... where you have like multiple layers going through those... in between those... and we'll talk about this more in a minute... you might use any kind of activation function... and it's kind of an... engineering fine-tuning thing to... determine which one works best. The final output... here you are more constrained... because... it depends on your use case. So, if you, for example, want to predict... one class... so it's either zero or one... then... you almost always want to use a sigmoid function there... because that one gives you something that you can interpret as a probability of... okay, how likely is it that I'm in this class over here? So, it's a number between zero and one... and you can... and this is kind of... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can... you can...\",\n",
       " \"can... you can... you can... you can... you can... you can... this is kind of... scaled in a way that it works as if it was a probability in some way. So... if you want to predict a binary class... you will always use a sigmoid. If you have multiple classes that you want... from which you want to predict one... you will always use the softmax function. If you want to predict just any kind of number, so... like the price of a house or whatever... you will always use like the identity function... so don't do anything for... for... for... with your output, just use the number that comes out of it. And yeah, that's basically it. So if for those, so it's basically just have those three cases for the outputs that you have. Like you want to have one number, some have a binary output, or have like a lot of discrete outputs. So one, zero, one, two, three, four, five. So, and for each of those cases, your activation function is kind of determined because there's like one activation function that fits to that output.\",\n",
       " \"there's like one activation function that fits to that output. And in all the other cases, so for these intermediate layers, you can use any activation function you like. We'll talk a little bit more about other activation functions that are used, that are commonly used in practice. But which one works best, there is no proper way to know that beforehand. So as like a little bit of experience for certain use cases, that you know in certain use cases, it might be this way. And the general advice is just use the Renu activation function in between because it usually works well and it's fast to compute. So that's kind of the general advice, but yeah. Otherwise there's no way to know what works best. So if we, logistic regression is a one layer neural network. And here we use the sigmode as the last activation function, function because we have a binary output. And the logistic regression does a direct mapping from our input to one output using one linear layer. So the next step is we want to add another layer\",\n",
       " \"linear layer. So the next step is we want to add another layer here. And just do the same thing that we did in the layer that we did before. So if we say this is logistic regression over here, it takes some inputs, does some linear operation, applies the sigmoid, and gets the properly scaled output, which we interpret as a probability. And this layer over here, it basically doesn't really care where its inputs come from. So if those inputs were x1, x2, x3, we would call it a logistic regression. If those inputs were the outputs of another neural network layer, we would call it a neural network. So it's the but this layer over here doesn't know anything about what happens. So it's the logistic regression. So it's the logistic regression. So it's the logistic regression. So it's the logistic regression. It just gets three inputs and does a logistic regression to determine its output. If we build a neural network, we just add additional steps over here. And each of those does a small little logistic regression\",\n",
       " 'here. And each of those does a small little logistic regression or some other linear transformation, almost linear transformation to modify its inputs and produce some more refined output that this last layer over here can use to make a better prediction over here. The terminology here is we talk about our input, which are the original features that we get from in our data. We have the output layer, which is the last layer where we do observe the output and where we actually have some, proper interpretation for the output, where we know what this output should be. And everything else we call a hidden layer. And we can have a lot of those. If we put all of this into formula, then we say, OK, we have our inputs. And we have like a little dot product over here for this first neuron over here, where we say, OK, we do the dot product of some. We have some vector w1, 1. And we have a bias term for this neuron over here. So this is the result of the linear operation that we calculate in this neuron over here. And',\n",
       " \"operation that we calculate in this neuron over here. And we call this output z1. And we apply some activation function over here, for example, the sigmoid, and get something that we call the activations of the first layer. So we get like one number as an output over here. And this number would be a1 superscript 1. And we do the same thing for each of those neurons. So we have like three neurons over here. So this one would be neuron 1, 1. This is neuron 1, 2. Neuron 1, 3. Neuron 2, 1. And because we will have like a lot of layers and different neurons and the different indices within the neurons. We have to fight a little with sub and superscripts for to get the mathematical notation somehow consistent. And probably I'll also have still some errors in the slides at some points where I mix up the indices. So I'll use this superscript in square brackets to determine the layer. So this is like layer 1. This is layer 1. This is layer 1. This one is in layer 2. And I use the subscript over here to determine the\",\n",
       " \"in layer 2. And I use the subscript over here to determine the individual neuron within the layer. So I have like this is the output of the first neuron in the first layer, the second neuron in the first layer, the third neuron in the first layer. And the output layer has just one neuron. So I could make a subscript over here. But I'll just leave it out because I just have a single output over here. And we'll have to add more indices later on when dealing with more dimensions and making things more complicated at some point. But for now, remember, the square brackets indicates the layer. And the subscript indicates kind of the neuron, which we are using. So if we think about this hidden layer over here, what we are doing is we have like a dot . product over here, a dot product over here, a dot product over here. So we do three dot products producing three activations or producing three so-called logit values. So this one would be Z1, Z2, Z3, each of the first layer. And those get mapped using the sigmoid or\",\n",
       " 'of the first layer. And those get mapped using the sigmoid or some activation function into the activations. And those are the input for the next layer. And what we want to do is batch together all those operations to vectorize more of the things. So what we can do is we can batch together all those individual dot products over here into one matrix vector operation. So if we write those... individual vectors W as rows of one large matrix W1, so which in this case will be a three by three matrix. So we have like three different neurons in the layer and each of those neurons has three different inputs. So this would be number of neurons. This is the number of inputs those neurons have. All of this gets turned into a vector. So we have a matrix vector operation where this is kind of the matrix with those values. This is a vector with all the bias terms. And then as an output, we get a vector with all those Z values. So this would be the vector with that one, one, Z2, one, Z3, one. So nice thing about writing it',\n",
       " \"that one, one, Z2, one, Z3, one. So nice thing about writing it like this is we kind of can get rid of one, one, Z2, one, Z3, one. So this is kind of the matrix that's not going to be the one, the subscript index because we only need to keep the number... the index that tells us for which layer this matrix is relevant. Because we kind of already grouped together all the neurons into one large matrix with parameters. So this SIGMOD function again in the way that NumPy does it and we need to do it over here is applied to the script. Right? That's right. This is the script. Okay. That's the script. for each of the elements over here. So it's element-wise applied to each of the entries in the z-vector over here. So if we put all this together, so if we put all the calculations from start to finish into one formula, we get that our predicted value is the sigmoid of vector w2 dot product with the sigmoid of matrix product of w1 times x plus bias term 1. And again, this whole thing will be added with bias term b.\",\n",
       " \"1. And again, this whole thing will be added with bias term b. And so there is always still some errors with the indices. So it's b2 over here. So what is inside here, we call the logit of the... of the first layer, z1. After mapping it through the sigmoid, we call it the activations of the first layer. Then the next linear operation gives us the logit of the second layer. And the sigmoid over here gives us the activations of the second layer. And because that was the last layer, the activations of the last layer is also the final output. So if we put all this... if we try to write down all this, as a compute graph, basically we get this one over here. We have this matrix product over here. Adding a bias term, mapping it through a sigmoid, multiplying it with a matrix, adding another bias term, and doing another sigmoid over here. And of course, if we would add the loss function over here, we also would get a loss over... a node for the loss over here, which also gets a y as an input over here. So in some\",\n",
       " \"here, which also gets a y as an input over here. So in some way, if we think... what we often think about is having this idea of a single neuron, where we have one value as an output, which is kind of what we do with logistic regression. But when building neural networks, we basically always think in entire layers. We don't really care about... We don't really care about... the individual neurons of one layer, because we always batch them together. We usually think in terms of an entire layer for a neural network. And the layer is... by using this matrix vector operation, we kind of batch together all those individual operations for each of the neurons by having one matrix operation over here and getting... and getting... the activations for each of those neurons in here. And we usually never really think in terms of individual neurons, because we kind of always combine operations as much as possible. So a tricky part, I told you this again and again, is getting dimensions right. So let's think a little bit\",\n",
       " \"again, is getting dimensions right. So let's think a little bit about the dimensions that we are dealing with. So we have the size of the input vector. So we call this n superscript 0. So this would be the dimension of the input vector. After the first layer, we are dealing with activations of size n superscript 1. So this would be the size of the activations after the first layer. And if we have those sizes over here, that means our matrix here in the first layer, so w1, would be a matrix n1 times n0, because that's the size of the input and that's the size of the output of this operation here. If this is the size of the output of this vector matrix multiplication, we know we need bias terms for each of the outputs. So the bias vector will have dimension n1. And because that's the size of the output, the output will have size n1 again. Somehow, again to kind of illustrate how the matrix vector multiplication works. So if we have like a matrix A and a matrix B and multiply them together, we multiply this\",\n",
       " \"A and a matrix B and multiply them together, we multiply this element and this one, add this one, and this one, this one, and this one, we add all those together to get the result over here. So, and we keep doing that for each of the outputs. And the thing to remember is, if A is an L by M matrix, and B is an M by N matrix, then the Ms in between have to be the same and will cancel out and give us a result that is an L by N. If A is a L by N matrix, and if B turns out to be a vector, then the N will be a one. So the result will also be a vector again with dimension this way. That's kind of the image that you need to keep in mind to remember what your inputs and outputs have to be. And so you can kind of remember this and get back to... And if you have errors and things do not match and NumPy throws weird errors for you, we can use broadcasting to do these calculations over here, not just for a single example, but we want to probably do all those operations for a lot of examples. So we don't want to just\",\n",
       " \"operations for a lot of examples. So we don't want to just calculate the activations for one input example, but we want to do that for a lot of examples. And so I'll just give you kind of a brief example over here with NumPy. Okay, so... If we... So if we have like a single example over here, a single input here, then our z values... Our z values will again be a vector of entries. So the same would be if I just remove this one, then... And things do not work because I do a matrix, matrix, multiplication over here. So if I... In the basic formulation, we would do something like... Let's call this a small x equals np random.rand and make this length 4. So let's leave this one out. And small z would be w, times x, plus b. And... So... So... Where do I go wrong over here? So this one... Ah, yeah. So and this... And this one would also be just a... A regular vector. And I get the result that I expect over here. So I get... I have like x is some vector. W is a matrix. B is another vector that has like the size of\",\n",
       " \"W is a matrix. B is another vector that has like the size of the output dimension. And if I do the matrix multiplication w and x, I get something that has length 3 out of the input that had length 4. I add the bias term with length 3 and get my... My logits. And later on, after that, I would push those through a sigmoid function to get the activations. Now, if I want to vectorize stuff, I'll need to make sure that I put in a lot of examples over here. So I'll just assume that I have like five different examples. So each example has size 4. And I use... Five of those examples. So I don't deal with a vector x anymore. I have a matrix x where each of those columns is one of the input... Of the input data I deal with. So and everything else should kind of stay the same. And if I do this, things do not work out as nicely... Work out anymore. Because... Z turns out now to be again a matrix with one output. So it's 3 by 5. So I get... Again, I have three outputs. But I have one of those vectors for each of my data\",\n",
       " \"outputs. But I have one of those vectors for each of my data points. So I had five original data points as input. And now I still have five data points as output. And I have the results of this... Of this linear... Curation for each of my data points. And to make sure that I now add... The bias term... Individually to each of those data points. I must make sure that I tell NumPy which is the... Dimension over which to broadcast. And the so-called batch dimension. Which is where I put in... The... Over which I index my different examples. Which in this case is the last dimension. Over here. And it kind of often is the last dimension. I'll have to tell... Make sure that NumPy knows that... It has to broadcast over this operation. Over this batch dimension. So I'll... Put... When I define my bias term over here. I don't define a vector of length 3. But I make it a matrix of length... Of size 3 by 1. So that... This operation here... Works out in the way that I expect it to do. And that's kind of the motivation\",\n",
       " \"way that I expect it to do. And that's kind of the motivation over here to... Why each of those is kind of written as... As a two-dimensional... Or to... A NumPy object with two shapes. So that the broadcasting works over this batch dimension. When I'm using... I'm calling... Doing this... This addition over here. So... But the nice thing is everything works. Even if... I'm putting in a lot of input examples. And this way I can kind of... Batch together a lot of operations. Into a... Into like single... NumPy operations. And make them... Being computed pretty efficiently. So... These things... Over here... I call it the activations. And it's the output of like mapping each individual entry... Through the activation function. And there's probably one question. Why do we actually need the activation function anyway? So what is... What is the activation function good for? So the easiest way to find out is by trying to just leave it out. So what happens if we leave out the activation function? So if we have our\",\n",
       " \"if we leave out the activation function? So if we have our formula for... For our two layer neural network. So we have like a two... Two layers. So... And two operations. W2 and times W1 times X plus B1 plus B2. And in the original version we would have had... A sigmoid around here. And a sigmoid around... In front here. But now if we... Or any kind of activation function. But if we leave it out... We can do some arithmetic to change this formula over here. So we could just say... Okay, this thing is the same as W2 times this. Plus W2 times this one. So... Got this one wrong. So there should be a W2 in front of the B1 over here. So W2 times B1. And... Um... What we then can do is... Group those together. We can say... Okay, I'll just multiply the parameters that I had in here... With the parameters I had here. Get a new... In this case this will be... This matrix W prime will be a vector. Because I have a single output over here. So we get like a vector with entries over here. And if I multiply this matrix\",\n",
       " \"a vector with entries over here. And if I multiply this matrix with this one... And add this vector over here... I get another vector B prime over here. And... Um... All together... This entire formula collapses to... This simple linear operation over here. So... Having... And this kind of means... Having all the operation... All those parameters over here. So I have like a big matrix of parameters over here. And to make lots and lots of calculations. But I could get the same result. The very same prediction over here. Using just... A simple dot product down here. So the result that I calculate over here... Is the very same... As if I just... Used much, much fewer parameters... And just did a dot product down here. And that is the reason why... We need the activation function... To make sure that those parameters cannot just... Cannot just be grouped together... And do the very same thing. We actually want... Um... Um... Uh... Just throwing in a lot of parameters... Doesn't help us if we cannot calculate\",\n",
       " \"a lot of parameters... Doesn't help us if we cannot calculate something... That we could just have calculated with a... Simple linear operation. Because that means... This more complicated formula... Has the same predictive power... As... The simple formula down here. It calculates the very same thing. So we could... Uh... And if we had... Up here... Probably W2 had... Uh... If W2... Was some vector of... Like... Uh... Like... Ten... Ten parameters... And W1... Was a matrix that had... Uh... Uh... That... That had ten outputs... And three inputs... So we had like thirty parameters in here... And ten parameters in here... So in total we have like forty parameters... Just in the W's alone... And down here... W prime would just be a vector with like... Three entries... Uh... Uh... With like... With just three entries... So the inputs over here... And... Would it... And... And everything that can be calculated... With those forty parameters over here... Can also be calculated... Just with three parameters\",\n",
       " \"here... Can also be calculated... Just with three parameters here... Over here... I just have to choose those parameters more carefully... And different... But... There's nothing that those... Forty parameters over here can... Can calculate that... Those three parameters... Down here... Cannot calculate... And that means... Um... Whatever I want to predict... I could... Do that with this linear function... So this thing also just calculates a linear function... And that... That's... That's kind of... Kind of what... What... What we... Where we need to make sure that this doesn't happen... So... We need this activation function... So that... Those... The... That... That we actually get something that is more powerful... Than just a linear operation... And we... But we... We are actually pretty free in... What we want to choose as an activation function... So... So far we have usually chosen the sigmoid... Which is this function over here... So it maps everything between zero and one... But we can choose other\",\n",
       " \"maps everything between zero and one... But we can choose other activation functions... So this is kind of the natural... Natural choice for the output layer of a binary classification... As I already told... Said... So there... If for binary outputs... That's always the last... The choice for the last layer... But... As the intermediate... For the intermediate layers... We might want to choose different activation functions... So we also can kind of make an index for the activation functions... Because we want... Probably want to have different activations in different layers... And... Another activation function that is pretty popular... Is the hyperbolic tangent... And that is something like a scaled version of the sigmoid... So it's... The... The difference being that it maps... Not from zero to one... But from minus one to zero... To one... And... There... It... This has... A nice property for... For the... For the hidden layers... Because... The mean... Of what this thing maps to... Is closer to\",\n",
       " \"The mean... Of what this thing maps to... Is closer to zero... And... That is usually... Some... That is usually some property that is... That is pretty nice... Because that... We... It... It... It usually... Usually the most interesting parts... Happen... When switching from positive to negative numbers... Because that is kind of the difference between... I want to... It's a positive example... It's a good example or a bad example... It's a zero or a one... And the most interesting parts usually happen over here... And... Having like this property that it's... That... That... It's getting scaled close... It's to a mean that is closer to zero... Zero usually... Works a little bit better... Than the one where the mean is scaled to 0.5... So... Or... Where the interesting parts happen at 0.5... So it's... That's... That's usually... So... This tangent superbolicus... Work... Usually works a little bit better... For the intermediate layers... Than the sigmoid... But it also has... Some disadvantages... And...\",\n",
       " \"the sigmoid... But it also has... Some disadvantages... And... One thing is... So if we look at... The gradient... For example... Over here... Over here... Over here... Over here... Over here... Over here... Over here... Over here... Over here... The slope... Of this function... Is... Not very large... Over here... So the gradient here... Is pretty close to zero... And the further... The larger we get... Over here... Or the smaller we get... Over here... The smaller the gradient gets... There's only a small area... Where we actually have... A pretty steep gradient... And things work... Almost linearly... Over here... And then the gradient starts to... To... To go down... When we get larger... Larger values... And... That is... That can be... Quite a problem... Because... If you have very... Very small gradients... Then gradient descent... Doesn't make a lot of progress... Because... If you... If you remember... We always subtract... Learning rate... Times... The gradient... From the values... And... Which\",\n",
       " \"Times... The gradient... From the values... And... Which means... If the gradient is incredibly small... We will... Make a step in the right direction... But it will be also be incredibly small... And that means... Our algorithm might run for a long long time... What is the... Vanishing gradient problem? So it's... Not... When talking about vanishing gradients... We'll also talk about those... It's usually a different problem... That's... The vanishing gradients usually happen... Due to... If you remember... In backpropagation... We multiply everything up... If you multiply a lot of numbers... That are smaller than one... You get also something that is close to zero... So that usually vanishing gradients happen... Due to... I multiply up a lot of numbers... That are smaller than one... So that this way they vanish... In this case... They all... Also vanish... Due to... The... The... The... A single step in the... In the neural network... So... The vanishing gradient problem... Is usually something else...\",\n",
       " \"The vanishing gradient problem... Is usually something else... That we... That... If you talk about this... But it's also... It's... In general... It's also one of the possible reasons... Why your... Gradients might get close to zero... And... So... It's kind of a... There's a lot of reasons... Why zero... Gradients could get close to zero... And... When... Using this term... Vanishing gradients... One usually talks about a different... Issue... Reason for that problem... But... There's... The problem that they might go close to zero... Can come from a lot of sources... Yeah... So... And... But... And... Yeah... Having... Having... Having gradients that get... Go close to zero... Is... Is kind of one of the main reasons... Why... Training doesn't work well... So... That... Our algorithm will... At some point... Get into the proper region over here... If we just train it long enough... So it will... It will work at some point... But... It might... It might take ages... And... We don't... Might not have this\",\n",
       " \"It might take ages... And... We don't... Might not have this time... And... Solving this... For example... The ReLU... Activation function... Which is kind of the maximum of... Some value and zero... So it's... This value... I should not... Mix... Those things up over here... So... If... This input value Z... Is greater than zero... I'll just take the value Z... And otherwise I take zero... This is kind of... If you think about it... It's this... It's... It's in some way... The stupidest... Activation function... That you can use... Which... Fulfills... That it's not a linear function... So it has to be something... That is not a linear function... For... To... To make sure that we don't... Our... Our... Our weights do not... Cannot be... Be just joint linear... So we... Basically just say... Okay... We... Just... Take one point... Which is not linear... Everywhere else... Our function is a linear function... It's a linear function over here... It's a linear function over here... It just isn't linear... At\",\n",
       " \"It's a linear function over here... It just isn't linear... At this... One single point... And... That you... In a lot of cases... That already does the trick... So... By... By... Adding this incredibly small... Non... Non-linearity over here... That is enough to make sure that the... Entire neural network will learn something useful... And... Because it can now make a distinction over here... Between... Values that are larger than zero... And smaller than zero... And for those that are smaller than zero... It kind of can make sure that... It doesn't matter how small it is... It always gets mapped to the same value... And that can... It then can... It basically can use that... If you think about... If you have a classifier... And... The classifier is supposed to... Distinguish between positive and negative examples... And a linear classifier... Can only... Predict some... Some straight line over here... But using this small non-linearity in the layers... Our neural network basically can... Make something\",\n",
       " \"layers... Our neural network basically can... Make something that works like this... So that it can also get like... Use this non-linearity... To... Split up... The... The decision boundary into... Into... Smaller linear parts... So it kind of... If you use the regular activation function... Then you give your... Classifier the ability to add... Those kind of kinks into the decision boundary... And... Which is what we need to get better predictions in some cases... And... So... How about the gradient of this thing? So the gradient of this... Is one... If we have values... That are greater than... Than zero... And it's zero over here... And... No matter how big... How large the... The value is that we have over here... The gradient will always be one... So it's not... It's... It's not going to zero... As long as... If we have an incredibly large value over here... We always have a proper gradient to go down here... Only thing is... If we are negative... The gradient gets zero... And the algorithm has no way\",\n",
       " \"The gradient gets zero... And the algorithm has no way to... Figure out that it has to travel into some direction over here... And there is a fix for this... And this is the so-called... Leaky ReLU... Which is... After zero... I'm not mapping exactly to zero... But to some small value over here... So I'll basically take the maximum of x... And 0.01x... Or something like this... So if x is greater than zero... I'll just take x... And if it's small... Then I'll just map it to a very small variant of this... This means that the gradient here will be 1... And here it would be 0.01... So I still have a gradient that helps me... Traveling out of this region over here... And getting over the non-linear part over here... This often works slightly better than the basic ReLU function... It's possible to choose another value over here... So this is something that you can freely choose... In this picture I chose 0.1 over here... Because otherwise if it's 0.01... You don't even see the difference between the ReLU\",\n",
       " \"it's 0.01... You don't even see the difference between the ReLU function in the picture... Just so you know that I made this more extreme... So you can actually see something here... In practice Leaky ReLU is not used that often... Which is mainly because it just works slightly better than ReLU in most cases... But it's kind of... It's interesting that... That... That... That... The fact that the gradient over here goes to 0... Doesn't seem to matter that much in practice... And so that fixing this problem doesn't... It's not that relevant... Another activation function that we can use is the identity function... And obviously this is a bad choice for all hidden layers... Because of all the things that we already talked about... So there's no reason to use this in any hidden layer... But for the final layer we might want to use that... So as an activation... Because we might... If we just... If we have some kind of regression problem... Where we want to predict any kind of number... We want to make sure that\",\n",
       " \"want to predict any kind of number... We want to make sure that we just predict that number... Can predict any kind of number... So it might be a good choice... Or the proper choice for the last layer of a neural network... So those are... Those are the most common choices for an activation function... You can think of others... And basically any kind of non-linear function... Where you have... You have like a good derivative... And can calculate it easily... Can work as an activation function... Yeah... Yeah... This is kind of... You can take any number here... It's usually some... So the idea is... You want to have something that is close to zero... So it's... It's like the ReLU function... But it still has a gradient... That kind of makes sure that... If you're over here... You have a way to know that... The gradient descent has a way to know that... If it wants to predict something larger... It should have traveled this way... So you want to add something that is... Is small... So that it's close to\",\n",
       " \"to add something that is... Is small... So that it's close to zero... But big enough that you still make some progress... Into that direction... If needed... So that's kind of... So... It usually will be something like 0.01... So... But it... Could... Could be any... Any kind... Any number... So... You could even... Put a 10 over... In here... And... Then it's not the maximum... Or something like this... But you could also... Make something that is kind of... Works the other way around... And just make it very weird... It probably won't work in practice... But it would... Like... Give you the... The properties that you need... So... It... And... Probably... So... So... Basically... As I say over here... It's kind of... You can... Take almost any function... As long as it has some non-linearity in there... And... You kind of have a derivative... Almost everywhere... So... In this case... You kind of... This is an... The whole function is not differentiable... Because there is like this point... Where there is\",\n",
       " \"Because there is like this point... Where there is no derivative... In mathematical terms... But... In... As... As... As practical... As... As... As practical engineers... We don't care about this... Because we can say... It's... It's just one point... And actually... You will never be exactly at this point... So... We just say... Okay... The derivative on this... At this point is... It... Is... Let's say... In this case... It's... It's... It could be... 0.01... Or it could be 1... And we just choose one of those... If we are at exactly 0... So... In... For... So... Every... Over here... It would be 0.01... Over here... It would be 1... And exactly at this point... We say... It's... It's 1... So... We just choose one of those... Possible derivatives... And... That's... For... For... For practical reasons... For... For practice... That works sufficiently good... So... Even though it's not... Not completely mathematically sound... But... Having like... Any function where we have like... A derivative... Almost\",\n",
       " \"Any function where we have like... A derivative... Almost everywhere... That's... That... That works in practice... So... And... You can choose any kind of activation function... Function you want to... But... Do... And not... Not any... Any activation function will work in practice... So it's kind of... Relu turned out to be... A function that is easy to compute... And works pretty... Pretty... Sufficiently well... So it's kind of the go-to function... You can... But you could... Could use any function... But... Yeah... You will need to make experiments... And see... Okay... Does it work... Actually work better... And... Do I make... So... And... If it's a very complicated function... And... I need more calculations... And it takes longer to calculate it... Then probably... Just having another layer... With a Relu function... Would do the same trick... And I can... Put in another... Because I have more... I have less... It takes less calculation... To calculate Relu... I can have more time... That I could\",\n",
       " \"To calculate Relu... I can have more time... That I could use to... Add another layer in the neural network... And then probably... Relu with another layer... Is better than my fancy function... With a layer less... And then I could... I've also just used Relu... And... Done nothing... So... It's kind of... Finding something... That actually works better... Than the... The simple ones... It's not that easy... So... Now we have basically... Introduced all the things... That we need for... One of our neural network neurons... And... Each of the neurons... Has basically two... Jobs that it has to do... One is... I allow my inputs... To interact... And that is part... That is what the linear part... Of my operation does... So I have like... Some... Allow that... I mix... Up all those... Different inputs... Weighted by something... In some way... But I have... This way... I allow those... Those... Inputs to interact... In some way... And then... I introduce some non-linearity... To make sure that... I just don't\",\n",
       " \"some non-linearity... To make sure that... I just don't have... Linear operation... All the way through... The entire network... And... And... Basically... These are also... The kind of... Two minimal... Requirements... That I need... That a... Neural network... With some depth... Makes sense... So multilayer... Neural networks... Make only sense... If I have basically... Those two properties... And... The neurons... That we use... Only... Kind of fulfill... Those minimal properties... So we could... Try to make... More fancy neurons... But like the neurons... That we use... Only... Fulfill the minimal... Amount of work... That is needed... Needed to... Be meaningful... For having... multi-layer neural network. So there is no talking about multi-layer neural networks without talking about the XOR problem. So that's kind of the simplest problem where a single layer classifier doesn't work. So if I have two inputs, X1, X2, and they can be either 0 or 1, and the output that I want to have is also either 0 or 1.\",\n",
       " \"or 1, and the output that I want to have is also either 0 or 1. And so if both are 0 or both are 1, I want to predict 0 and 1 otherwise, which is kind of the logical XOR gate. If I draw this in this way, it's kind of easy to see that there is no linear decision boundary that I can put in there that would perfectly separate the Xs and the circles. So there is no way I could draw a linear decision boundary that would separate them. So there is no linear classifier that can properly separate them. But if I have two layers, I could do that. So one way would be to define my weights in this way that I have the activations A1 would be ReLU of X1 minus X2. A2 would be minus X1 plus X2. And then for the output, I just add up those activations. And then for the output, I just add up those activations. And then for the output, I just add up those activations. And so if I go through the calculations, A1 would be 0 minus 0 is 0. 0 minus 1 is minus 1. Gets mapped to 0. 1 minus 0 is 1. 1 minus 1 is again 0. And if I do the\",\n",
       " \"to 0. 1 minus 0 is 1. 1 minus 1 is again 0. And if I do the same thing for A2, I get 0 here. 0 and 0 is 0. And 0 and 1 is 1. And minus 1 plus 0 is minus 1. Gets mapped to 0. And minus 1 plus 1 is 0 again. So we get those outputs. And if I just add them up, we get kind of 1 over here and 1 over here. And this also shows you why this ReLU over here is actually important. Because otherwise, if I didn't have the ReLU over here, this 0 over here would be a minus 1. And this 0 over here would be a minus 1. And this 0 over here would be a minus 1. And this 0 over here would be a minus 1. And if I add them up over here, I get 0s over here. So the trick that this neural network does is by making sure that once I get smaller than 0, I just map everything to 0. And this way, I can get this kind of kink into the decision boundary. And that's kind of what... And it also shows that even the simple ReLU function is already sufficient in providing enough non-linearity that kind of this logic gate now works. So kind of if I\",\n",
       " \"that kind of this logic gate now works. So kind of if I plot those values a1 and a2 after the first layer, then after the first layer, I kind of get it mapped to those points over here. And I have like two circles over here, which just are above each other. So these are the first activations. And now the second layer can just make a linear decision boundary between those mapped values a1 and a2. And if I don't have a ReLU function, then kind of those points would be all on the same line. And again, I cannot draw... Even after the first layer, I can still cannot put in any linear decision boundary here. So, it's kind of visualizes and gives us the intuition why the activation function is actually important to make sure that, for instance, we have some sort of a line capture field. So that you don't always get anything in the same line after the first layer, which is important. So that you don't always get anything in the same line after the first layer, which is important. So that you don't always get\",\n",
       " \"first layer, which is important. So that you don't always get anything in the same line after the first layer, which is important. make sure that we can make some non-linear prediction over here. So if we have these activation functions, we kind of need, for each activation function that we want to use, we need to know the derivatives of those to do the backpropagation calculations. So for the sigmoid, we already had that one. So if our activation function is the sigmoid, then the derivative of the sigmoid is the sigmoid times 1 minus the sigmoid. We already had that when talking about backpropagation. For the hyperbolic tangent, the derivative is, again, something that is a little bit more complicated, but we can just look that up and see, okay, the sigmoid of the hyperbolic tangent, is 1 minus the hyperbolic tangent squared. So after looking it up, we can just use the formula for that. For rectified linear units, the gradient is incredibly simple. We talked already about this. So it's 1 for every number\",\n",
       " \"We talked already about this. So it's 1 for every number that is bigger than 0 and 0 otherwise. And this is kind of pretty neat that we have, like, we don't even need to, in this case, we need to do a few calculations to get the derivative. And so the number of calculations we need to do when doing neural networks add up and can take quite a lot of time. And, like, having very, very simple calculations is pretty nice when it comes to, when you think about, okay, what we have to do. And if we can save time, training works faster and everything works faster. For the Leaky Reload, it's similarly simple. We just don't have a 0 over here, but, like, the slope that we had on, that we have in the leaky part over here. So now we have, like, we have the different building blocks for how to do the calculations for, the relevant calculations for a neural network. Now if we want to do gradient descent with multiple layers, we need, what we have is, a lot more parameters. And for each of the parameters, we need to\",\n",
       " 'lot more parameters. And for each of the parameters, we need to calculate the gradient. So we have, like, for each layer, we have a matrix with the weights for each of the inputs. And we have the bias terms. And we have that for each of the layers. So, and, like, the dimensions here, we have the formula. We remember this is like the input for the first layer, output of the first layer, input for the second layer. Which is the same as the output of the layer before, and output of the second layer. And if we think about it, okay, when we do gradient descent, we want to optimize some cost function. And we usually call that the function J, which is the cost function over the entire data set, or the entire training batch. And the cost function is dependent on all the parameters that our neural network has. So we have, like, a lot of different parameters. We have each of the matrices, and each matrix has kind of potentially a lot of parameters. And our cost function then is the mean of the training examples that',\n",
       " \"cost function then is the mean of the training examples that we looked at. And probably the, and if we do classification, this will be the cross entropy loss for each of those data points. Now if we do gradient descent, the update step will be going into the direction of the gradient for each, or into the opposite direction of the gradient for each of the parameters that we had, scaled by the learning rate. And that's the same thing for each parameter. So I wrote down a lot of stuff over here, but it says the same thing for each of the parameters, in each of the cases over here. And having more and more data points, more layers and more parameters doesn't change anything here. So if we get more parameters, more layers in the neural network, the formulas will stay the same. We need to calculate the gradient into the direction of the respective parameters and do a little step into the opposite direction of those scaled by the learning rate. So you can guess how this loop would look if we have more layers. So\",\n",
       " \"can guess how this loop would look if we have more layers. So if we do the backpropagation algorithm, we have two steps that we do. The forward propagation step, where we calculate the value that we predict. So that is calculating Z1, which is W times X plus B. Then calculating the activations by using the first activation function on those values Z over here. So... This should be probably a smaller Z over here. Then doing the linear operation on the output first activations, getting the first logits over here, applying the next activation function on those logits over here. Again, this would be small Zs over here. And getting the second activations, which turn out to be our predictions for this two-layer neural network. And the activation... The function over here turns out to be a sigmoid, because for the output, we definitely want to use the sigmoid over here. One thing to note, and this is why I mixed up small and big letters over here. We probably don't want to do this for a single vector X over here,\",\n",
       " \"probably don't want to do this for a single vector X over here, but for an entire matrix of X, which is of dimension N0, we just want to do a flat matrix over here. And then I just choose my matrix and then standardize the entire matrix. And then I click Upon. Then you just type the data at the endpoint after the above steps through. And then our project becomes ingrained with this confidence. And so, the marking defended above is made down B. But we also have to 여러분ize one more matrix over here. So that's too much work. But here we get a big VX plus E. Then we orash an E into the essential kernel over here. Because we only want to go out the physical erzählt, because the matrix is big A over if any. the data points in the same operation. So if I try to draw this as a compute graph, I'm starting to combine more and more operations into the individual nodes of the compute graph so that it doesn't get too large. So in this case, I have like a linear layer and the linear layer has weight matrix as inputs, a\",\n",
       " \"layer and the linear layer has weight matrix as inputs, a bias term as inputs, and like the original input features as an input and as an output I get the values z from the linear layer, then I map those through the activation functions, get my activations a and get another linear layer up till the the final outputs y hat, which I then put into the loss function and get my final loss number, which I want to optimize. So when doing back-propagation when doing the forward propagation we kind of calculate through this compute graph to get the final loss waiting back propagation we need to calculate the individual gradients. So I'll write it down and in kind of mathy terms over here and for the exercises we will kind of try to program all of those things in NumPy and and it's even, which still can still be a bit challenging, even though you know all the formulas for each part here. So if the gradient for the loss function, we already saw that we can kind of batch together the sigmoid and the last loss function,\",\n",
       " \"kind of batch together the sigmoid and the last loss function, so we can kind of batch these two operations together when calculating the gradient, because it's an easier gradient that we get at the end. So we get like the activations, the second activations, minus, which is just y hat, minus y, as the gradient into the direction of z2. So we kind of already have the gradient of the loss into the direction of z2, so we get the gradient up to the point down here. So if we now want to take the gradient, into the direction of the parameters w2 over here, we need to multiply the gradient that we just had before, times the gradient from here till here, and the gradient from here till here will just be the inputs that we put in here, so it will just be the a1 over here, and, so if we want to multiply, and we need to multiply that with the gradient that we got from over here, so the gradient into the direction of w2 will be the gradient that we got up here, times the inputs from over here, so, and again, all these\",\n",
       " 'here, times the inputs from over here, so, and again, all these are vector and matrix operations over here, so, and written down in the way that the proper derivative ends up in the proper position, for this matrix over here, so, and kind of remember that, if I do a matrix vector multiplication, so I multiply w, and a, so, this thing over here, is affected by, so, this value over, so this one over here times this value over here, gives you the value over here, and if I have like multiple inputs a, so if I have like another input here, then this value over here, times this one over here, gets results in this value over here, so, what we will need to do is, we already have the gradients for each of those values, which are the ones that are in here, so, we have the gradients for each of the values over here, and each of those, need to be multiplied with the corresponding value over here, and we will need to add them up to get the gradient, for this value over here, and this is kind of what happens, if we do',\n",
       " \"value over here, and this is kind of what happens, if we do this, this operation over here, to make sure that, the gradient for each of the, that the correct gradient of, ends up at the position, in this matrix over here, that we need for, that's, kind of is each of the output values that are affected by this one and each of the input values which are multiplied up with this value over here. So if we go one step, go to the other direction, if we go to the bias term over here, it's just a linear operation. So we multiply the gradient over here with one because the gradient from here to here is just one, so it's just the gradient that we already calculated over here. Now we go down one step further, we calculate the gradient into the direction of the activations A1. So we take the gradient, so we have had the gradient this way, we had the gradient this way, now we need to calculate the gradient this way, and now it's the gradient that we have over here, but we need to multiply it with the weights from over\",\n",
       " \"here, but we need to multiply it with the weights from over here because we are kind of on the other side of the product, so it's this matrix over here multiplied with this gradient over here, and to make sure that everything ends up at the right position, we need to transpose the matrix so that everything works out and probably a good exercise for the next exercise sheet if you want to understand this more properly, it's kind of a good thing to write out this matrix multiplication, in full to see why we need to transpose it so that the gradients end up at the right positions. Next, over here we need to make the step down here for the gradient, so we need to multiply the gradient that we just had with the gradient of this activation function that we have over here. And in this case, this thing here is the element-wise multiplication because we have the element-wise multiplication over here, and in this case, this thing here is the element-wise multiplication because there's no proper mathematical symbol for\",\n",
       " \"because there's no proper mathematical symbol for doing this operation that is kind of the normal NumPy multiplication between two vectors where I just want to have another vector where I multiply this by this and put the result over here, and if I want, and so on, and kind of this element-wise multiplication, I'll introduce this symbol over here for that one, which is kind of the standard NumPy multiplication if I multiply two vectors, because obviously... Otherwise, in math, you usually always take the dot product between vectors, which is something different. So we take the gradient that we had for each of our activations and multiply it with the gradient of the activation function at each of the individual intra-entries, and this is kind of... Over here and over here, it's kind of hard to get those transpositions and matrix operations right. Over here, it's actually pretty simple because usually we have just the formula over here and we just do element-wise stuff, so it's kind of pretty easy to go down\",\n",
       " \"do element-wise stuff, so it's kind of pretty easy to go down this way. So we end up over here. Next step is we kind of need to go down from here to the parameters W1, and this will be the same operation that we did over here already. So we take the gradient, that we have accumulated over here, and multiply it with the parameters that we have over here. So that's kind of the same thing that we did over here. And if we have more layers, it will stay the same even if we do more and more calculations. So going down even further will just be the same operations over and over again. The same thing for if we go over into this direction, we again multiply this one by one. So it's just the gradient that we already calculated going down, over here. So now we have like the gradients for each of the different parameters over here. We don't need to go further down this way because we don't need the gradient for the input parameters because we cannot change them. Again, in the same way that we batched everything and\",\n",
       " \"them. Again, in the same way that we batched everything and vectorized everything when we went up this chain, we also want to... make sure that everything going down the chain is vectorized properly. And here are some examples for this. So if we... when going down, doing the gradient computations, we also want to make everything batched over all the training data that we are looking at and vectorize everything. And... in some way everything works exactly the same way that we write down things over here. We just need to make sure that at some points we need to average over the entire training batch. So which is because if we basically take one over M times the individual loss functions. So if we kind of have this one divided by M, which needs to be the same, which needs to be part of certain of the calculations, and we kind of need to remember to put that in. So it's one thing that needs to be done to make sure that everything still works in the batched way. So this way kind of we can get... But otherwise all\",\n",
       " \"way. So this way kind of we can get... But otherwise all the calculations over here are kind of just the translations of those things into NumPy. So having all this and you'll be in the exercise cheat for next week, you'll be able to kind of put all this together to also to train your own NumPy based neural network and make put all this together so that we can kind of make a proper classifier with this. And we'll use the same data as for the logistic regression example. So we can see that, okay, adding more layers actually gives us some, advantage and makes the results actually better. So when we train logistic regression, we can just start by setting this entire, this vector W and this vector B to zero. This value B to zero. So a question is if we can, can we do this now that we are dealing with a neural network? And then, the short answer is no, but let's see why. And if one thing is if we have multiple layers, setting everything to zero will mean that all the gradients turn out to be zero at the end\",\n",
       " \"will mean that all the gradients turn out to be zero at the end because you start multiplying zeros in at some point and then for logistic regression, this doesn't happen because you kind of, if I take the gradient into the direction of W, I'll take the gradient X, which is not zero. So everything is fine. But if I have activations, which are already zero, then the gradient into the direction of W will again be zero and I don't make any progress because I multiply up zero gradients. So this is an issue. The other issue is symmetry. So let's assume our parameters for each of the neurons are not zero, but they are the same for each of the neurons. So I, basically, I can do this. So I can do this. So basically, my matrix W just consists of like ABCD, ABCD, ABCD. So if I have like the same values over here, so if I have the same values for each of the neurons, so each neuron has some values which are different, but each of the neurons is the same. So if I think about some of my inputs and I have some values that\",\n",
       " \"if I think about some of my inputs and I have some values that are different, I can do this. So I can do this. So I can do this. So I can do this. I can do this and go back miji. so if felicite is 0, I have a value number from 0 or five, but it will takeíchmasa zero. So zero here is am horizontally to zero because I have, because here is my models. Right here. And then I multiply by this CAN tomar and so I got the проблем where every neuron is the same for each of the neurons, because wonderful? This result is good. Then yes, there are there are some problems around F。」 So, the gradient turns out to be the same for every neuron, and if I now say that my matrix W is equal to W minus some learning rate times the gradient of W into the direction of W, then I'll just subtract the same thing in each row, and each row was the same beforehand already, so it's different, but it's still the same. So each row is still the same, so every neuron will have now a different output, but still the same output. So the neurons\",\n",
       " \"a different output, but still the same output. So the neurons never differentiate between each other. Every neuron will still produce the same output every time, and that is pretty bad, because no matter how long I train my network, every neuron will still give me the same output, and if it gives me the same output, I could have just left them out. I don't need 10 neurons which all say the same thing. I can just use one and multiply its result by 10 and still have the same effect. So we need to make sure that we can break this symmetry, that we don't end up in some symmetrical solution, and the easiest way to do that is just start with random values. And the nice thing is I don't even need random values for everything, not just for the values in my weight matrices. So the bias terms can usually be initialized. They are initialized with zeros, but for the weight matrices, I still need to put in random values and make sure that they are all different in some way. Does this not help when we are training our AI?\",\n",
       " \"in some way. Does this not help when we are training our AI? Like, does the neuron start 9 and a half and then we have a problem? Yeah. Yeah. So something like this might happen. So it's unlikely that they align perfectly. Thankfully thanks to numerics and everything, it's usually that there will still be some difference even if they get very close. It's incredibly unlikely that it turns out the two neurons get the exact same values at some point. But it's not impossible. It's perfectly possible. It's possible that you end up in some degenerate solution where you get two neurons due to some circumstances are forced to get the same values and then or after that are kind of useless in some way. But in practice, that doesn't seem to be an issue. So if you take random initializations, they usually tend to... they might still... it might still turn into a problem. But if you turn out that two neurons are too similar, that they don't make... that it's not very useful, what they are doing, but... or not usefully\",\n",
       " \"not very useful, what they are doing, but... or not usefully differentiated, but it's... you usually break up the symmetry this way. Something you usually do is that you multiply those random values with something small. So you want to make sure that those values are close to zero but not exactly zero. You just want to make sure that you break up the symmetry. It's... and that... and have some direction. Yeah. You have some direction to start with. So and the... one of the reasons for this is also that if you... so we want to have values that are close to zero. And if you think about all our activation functions, the interesting start... stuff always happens close to zero. So you want to make sure that whatever your neural network predicts, it should be cl... somewhere close by this interesting point because that's where you differentiate between like the... like the good and the bad. So we want to like put bad apples on one side, the good apples on the other side. And the... like having the non-linearity\",\n",
       " 'on the other side. And the... like having the non-linearity here should be the point that kind of differentiates between them. And because that is usually close to zero, you want to make sure that your values are also close to that point. But if you make this too small, then you are kind of getting problems again. But like some... something random close to zero usually does quite fine. Also when doing logistic regression, you always have like a clear-cut global minimum. So if you do gradient descent, you will end up at the same value... parameters every time, no matter where you started. When training your neural networks, you have a lot... you have a much more complex... so you have a lot of... you have a much more complex... so you have a lot of... you have a lot of problems. You have a lot of problems... So... and... There is... There can be local minima, so... And there can be a lot of issues when training neural networks. And if you like start again... start your training run again with different random',\n",
       " \"again... start your training run again with different random initialize... parameters, you might end up at a completely different solution. And it might even be better or worse than another one. So like this... this... this randomness over here also might give you completely different solutions when it comes to the final neural network that you have. So in general, we'll also talk a little bit more about this. It will not be such a big issue where you start exactly, but it's important to keep in mind we start, we randomize the starting position, and depending on where we start, we may end up at different local minima of the loss function and get different classifiers because it's not a simple surface where we are guaranteed to always end up at the same point like in logistic regression. So that's it for today. Do you have more questions? I know that I threw a lot of math at you today and a lot of those scary-looking gradient parts. It's when you start implementing all those things. At some point, it might\",\n",
       " \"start implementing all those things. At some point, it might click for you, and then you realize it's easier than the scary things over here look like because, again, as I already told you, it's just multiplications and additions in some way and put blocked into fancy operations, which are matrix-vector multiplications, but it's all addition and multiplication at the lowest level. And so do the exercises and try to figure out... figure out what actually happens deep down in there, and then usually the scary part goes away when it clicks at some point. And see you on Friday. So welcome to artificial intelligence. Some organizational things first. So there is an OLAT course for this. So I hope this link is the right one. Yeah, so and the OLAT course has some kind of the links to the relevant links. And I will upload exercises here and the solutions for exercises. Exercises are in some way completely optional. You can do them, you can not do them. I prefer if you do them, or at least you should prefer that\",\n",
       " \"I prefer if you do them, or at least you should prefer that because if you don't, that's your loss. The OLAT course has links to the slides I'm using and the slides are available. I'm sorry, I've got to go. And I'm sorry, I'm sorry, I'm sorry. So if you don't, that's your loss. We the OLAT course has links to the slides I'm using and the slides are basically just web pages with fancy web pages if you want to. So it has like the slides itself. And version is the print version. So the print version is basically also just a web page, but one which is kind of better suited for directly printing slides if you want to do that. Printing in a lot of cases, the print looks the way it should look. But in some cases, the slides, if they slides have interactive elements, then printing doesn't really make sense. And then printing also doesn't work that well. I will, I have created a Teams channel for this course. So you don't have to, but probably it's a good idea to register there and for asking questions and getting\",\n",
       " \"idea to register there and for asking questions and getting answers. So if you have any questions, please feel free to ask them in the chat. And I'll be happy to answer them. So if you have any questions, please feel free to ask them in the chat. And either from me or from somebody else in the course. So it's a good idea for communication. And in case there should be the next pandemic or don't know what we'll do, and we have to switch to making remote classes, I will also do that via Teams. So who knows what the future holds? I will record all the all the lectures and upload them into this Panopto folder. So obviously, so you can log in there with your THBing credentials. And once there was a first lecture there, you will see the videos there and can, for example, when doing exercises, it might be a nice thing to go through some parts of the course again, or when preparing for the exam at the end. I have created a JupyterHub for the exercises, and I will talk more about this later. But if you want to solve\",\n",
       " \"and I will talk more about this later. But if you want to solve some of the exercises, you can do that using this Jupyter instance that I put on one of the THBing servers. I'll talk about that later, more about this later. So we can do the exercises there. I'll talk about that later. So yeah, so we can do the exercises there. But for now, I will change off here for demonstration and let you speak. at the end of the course, there will be a final exam and termining rate and so on. The exercises will be posted in the form of Jupyter Notebooks. Okay. So basically, the Jupyter Notebook is a workbook. And I'm going to say my two photos in no time. So again, more on that later, and I will post them into this OLAT course over here. Jupyter Notebook is some kind of remote Python environment. Probably a lot of you have already some Python experience, but in case not, I'll use the exercise on Friday to make a brief Python introduction. So if you already are pretty experienced with it, with Python and with NumPy, one of\",\n",
       " \"pretty experienced with it, with Python and with NumPy, one of the main Python libraries we will be using in this course. You can basically skip Friday, but otherwise I'll give kind of an introduction into those things on Friday to bring you up to speed. So everything will be in form of Jupyter Notebooks. So maybe as a very, very brief introduction, just now Jupyter Notebooks are kind of a remote Python environment. They live, all the notebooks live on kind of a remote server and what you see is a small web front end to edit them and all the notebooks are comprised of small cells where you can write some small Python code. And, which you can execute individually and see the results and which gives, for at least for those small examples and small projects we will be doing here, it's kind of a pretty nice developing experience. Also, something nice about this is that the server has actually a lot more horsepower than probably your notebook has because it has two GPUs installed. and quite a bit of hard drive\",\n",
       " \"it has two GPUs installed. and quite a bit of hard drive and memory so that we can even do some more demanding tasks there and for most of the exercises that should not be necessary but for example doing larger image classification tasks doesn't necessarily require a GPU but it makes the difference between developing something in a few hours or waiting weeks for something to finish and it can be a nice thing to have those. You can use this Jupyter instance for other projects. So if you for example do your master thesis and need some compute power for that you can also use this Jupyter server for something there. So it's not restricted to this course. Just don't abuse it. So if I see anybody mining cryptocurrencies there it's kind of, I will press charges for that. So references for this course. There's kind of one really good book about deep learning by Ian Goodfellow. And Joshua Bengio and Aaron Colville which kind of is recommended but not necessary. So none of those references are necessary. And Andrew\",\n",
       " \"So none of those references are necessary. And Andrew Eng has put up a lot of good learning resources as well and learning videos and I'm following along a lot of his course material. So that's kind of also quite a good resource. So in total this course will, so artificial intelligence in general is a very, very, very, huge bucket of different things to do. And the main focus of this course will be on deep learning techniques. So that's not all there is to artificial intelligence even though at the moment it sounds a little bit like this if you follow the media. Everything that's all the big AI breakthroughs are deep learning based at the moment. And there's a lot of gold rush fever, around the deep learning topics, but it's not everything. It's not the entirety of what artificial intelligence is. And there's a lot of other techniques and algorithms that are also incredibly useful and widely used in a lot of industry contexts. But yeah, this course will be all about deep learning and how to build neural\",\n",
       " 'course will be all about deep learning and how to build neural networks, how to build deep learning based, systems to solve a variety of tasks. So going a little bit into the history of artificial intelligence. So in the 50s, many, many, many of the techniques here are old. Some are even older than this. So kind of machine learning and is first mentioned in this book, in a paper about the Perceptron, where they first built basically a machine to do machine learning. So that was the time where computers were still room-sized things and the Perceptron was a classic, a machine learning machine. So that was the time where computers were still room-sized things. So that was the time where computers were still room-sized things. So that was the time where computers were still room-sized things. A machine that could do classification tasks by learning from data. And the first instance of this was basically a machine for this single purpose. Sometimes later in the 60s, we had kind of way more techniques and some of',\n",
       " \"in the 60s, we had kind of way more techniques and some of those are kind of the backbone of what we are still using today. So like the back propagation algorithm is from the 60s. And it's kind of the same math, the same ideas that power all the neural networks in use nowadays. So I'm not sure if it's... It's kind of funny that there hasn't been any changes in the fundamentals there. So there's like little tweaks and some little engineering ideas to make it work better. But the core idea is still the same for the last 60 years. Back then, they discovered a few fundamental limits for neural networks. It's funny that back then, there was a big report about how a simple linear model, for example, a linear perceptron can compute and what it cannot compute. And this report led to a lot of funding for AI research being frozen and a lot of research being discontinued. Even though those fundamental limits are kind of... It's a pretty weak... It's not like they said a neural network cannot compute a lot of... Cannot,\",\n",
       " \"they said a neural network cannot compute a lot of... Cannot, for example, ever do image classification. It basically said that... For example, one layer neural network can never solve the XOR function. And, yeah, which doesn't say anything about two layer neural networks. And so kind of this report was misread by a lot of legislators back at the time. So in the 80s, people rediscovered backpropagation. And back then, we got the first proper industrial uses of neural networks. They had the first convolutional neural networks for identifying digits on letters. So the U.S. Postal Service was using a machine learning algorithm that used the convolutional neural networks. More on that later in the course. Which classified the individual letters for the zip code on the envelopes. And they... They were kind of read in the zip code automatically. Back then, a lot of things that we kind of rediscovered later on were already invented. So kind of reinforcement learning, support vector machines, recurrent neural\",\n",
       " 'learning, support vector machines, recurrent neural networks, convolutional neural networks, as I just said. But back then, people were lacking mainly two things. And that was... Sufficient data for training all those algorithms. And the compute power to really run big neural networks. And so... We... Interest all died down again. And it took some time until all those things were again rediscovered. So in the 2000s, there were like two things which started to get everything going. There was one thing, the Netflix price. Netflix... Put out a price money of one million dollars for somebody who could improve their movie recommender algorithms by 10% or more. And it turned out that... And they put out their movie recommendation data set. For everybody to use and to fine-tune their algorithms. And that was a pretty big thing, because that was kind of the first time... where a big proprietary data set was kind of free for the taking for everybody out there and to do research on it and probably the the price money',\n",
       " \"there and to do research on it and probably the the price money was net and the price itself was also a nice thing but the um the the the fact that they put out a really really huge data set for for everybody to work on was was kind of a novel thing up to until then most data sets existed in the world gardens and um kind of it's it uh this was one of the first first times that they or that was one of the first things that need to be solved the access to to a large amount of large amounts of data and later other people started image net which was a kind of library of publicly available images with uh attacked with classifications of what what you can see on the image and they that was also publicly available, that then also became publicly available. In the 2000s, it started that we solved some of these data access issues. And in the 2010s, a neural network called AlexNet did soft image classification on this ImageNet dataset on a level that was on par with humans. So it was almost as good as humans could\",\n",
       " 'on par with humans. So it was almost as good as humans could classify those images. And that basically led to the deep learning boom that lasts till today. Since then, people discovered, okay, now we have access to enough data to train those really large models, and we have enough compute power to train those models. And it seems that... It seems that we can now do really useful things with all those techniques that were discovered pretty far back then, which led to people doing more and more applications for this and finding more techniques to use these on different datasets, on different types of data, and to find new applications. Some of those applications, so we can nowadays basically do machine translation on a level where... So like 10 years ago, machine translation was still something you could ask Google Translate and sometimes get pretty funny results. And sometimes translations back in the day used to be still pretty shitty in some cases. Nowadays machine translated texts are basically as good as',\n",
       " \"Nowadays machine translated texts are basically as good as a human could translate them. So it's kind of... It's very rare that you see cases where a good machine translation is still pretty shitty. So it's kind of... It's very rare that you see cases where a good machine translation is still pretty shitty. So it's kind of... It's kind of... But even if it's a good machine translation software that doesn't do a proper translation or does something where it results in anything funny, we can do object recognition. We can identify objects and images, classify them. This image also kind of is kind of leading up to another application, which is kind of self-driving carving. So nowadays, image recognition is good enough that we can build reliable systems that can identify, okay, where is the lane on the street and where are other participants in the street? So I can reliably steer a car in this environment up to some limits. So it's not at the point where we can have fully autonomous self-driving cars, but the\",\n",
       " \"where we can have fully autonomous self-driving cars, but the tech is getting better and better. And I think it's just a matter of like next 10 years, I guess we will have fully autonomous self-driving cars as more and more issues get resolved. Some other applications, we got protein folding, which used to be an incredibly hard problem. So if you have a protein, it's easy to get a protein folding. It's easy to take a protein and see the sequence of the different molecules in the protein. So it's easy to get some substance and identify, okay, in which order are the different molecules within the protein? But that just gives you a long string of molecules. What is interesting and what determines the way that the protein works is the shape that the protein will take on in the real world. So if you take this long string of molecules, they will fold into a certain shape. And this shape determines the properties that the protein has. And it's not trivial to know if you just have the string of molecules, how they\",\n",
       " \"to know if you just have the string of molecules, how they will behave in the real world. It's kind of, the physics is kind of well understood. They will fold into the configuration of least energy. It's non-trivial to know what this configuration of least energy will be in the end. So a team from Google created this algorithm AlphaFold, which is a deep learning based system that trains on proteins where we already know this so-called tertiary structure. And learn, and from the two-dimensional structure, or from the long one-dimensional structure, and kind of learns how the different molecules tend to interact and does a pretty, pretty good job at predicting this three-dimensional structure. Which, so it's still pretty young, but there have been a lot of medical breakthroughs. Thanks to this now that they can do things like, we need a protein that kind of binds to certain other protein parts. And they can now do things like, okay, we test a lot of different protein configurations now and check, okay, what\",\n",
       " \"of different protein configurations now and check, okay, what will be the tertiary structure of that. And then from that, they get the result. They basically get the idea, okay, what is the protein that they need to synthesize and get kind of, and derive medications from there. So there has been some breakthroughs in, for artificial intelligence in games, where we had certain games where humans were always kind of better than the machine, than machines. So chess was pretty, was solved in the 90s with Deep Blue. But like more, more complicated games where there is social interact, there's interaction between people and complicated environments, which are hard to parse. That took much, much more than chess did back then. So you need to pass much more information in a visual image here. And it's much harder to, to, to, to probably build a bot that can, can, can write rules and, can refill bools. And, and, and, you know, it could be pretty the basicups of do is it not. Let's see if it can. Okay, if you say I\",\n",
       " \"of do is it not. Let's see if it can. Okay, if you say I want to preview, let's say if처럼, let's see if it can do bools. I will. So you just çaline with the elf to everyone and, and now, you have all the words and you, and you get to ask, okay, okay, arrey, there are 3 possible ways to solve game, so bzt, so if we just say that this, thiscription should be, this, uh, Uh, I could, For example, anything machine learning based will need, as the name suggests, something to learn from. And if we don't have the data to learn from, and if the data is not good enough to learn from, we have no chance to build a learning algorithm for the problem that we have. So there's still a lot of tasks where we don't have the proper learning data, the proper way to solve that. So we still need to think ourselves how to approach those problems. As I said in the beginning, artificial intelligence is a pretty big field. So what we will cover in this course mainly will be the deep learning part, which itself is a subfield of machine\",\n",
       " \"the deep learning part, which itself is a subfield of machine learning, which covers much more than just neural networks, which is... It itself is a subfield of artificial intelligence, which also covers other things. So artificial intelligence also covers things like planning algorithm, shortest path problem, for example. It's also an artificial intelligence problem that we won't cover here, or how to solve... For example, if you want to solve a timetabling problem, like making this timetable for a university like here, that's also an artificial intelligence problem, but one where, for example, a deep learning algorithm is not... The ideal choice for solving that. So a question that we already started to answer a little bit. Why do we have the deep learning boom right now? So why is deep learning something that took off like six years ago and is kind of creating so much fuss right now? Why didn't it in the 80s when a lot of those algorithms were already known? Why didn't it in the 90s when a lot of those\",\n",
       " \"already known? Why didn't it in the 90s when a lot of those algorithms were already known? So in some way, more information now is digital. So back then, almost no information was digital. So the internet was basically some kind of... Something that was used for universities to change a little bit of text data and communicate with each other, but not something everybody used. And so digital data was almost non-existent back then. Nowadays, all the information is digital. So we have images, texts, shopping transactions and whatnot. And it's all already available in digital form because the information is basically directly created digital. If we think of... So this image is scaled a little badly. So the axis here would be data. So kind of on a log scale. So... The amount of data. If we take very, very simple linear models, they kind of... They perform well with little data, but it doesn't matter how much data you throw at a very simple linear model. And so as long as you have only little data available, you\",\n",
       " \"And so as long as you have only little data available, you don't realize that your model has kind of fundamental limits in what it does. It can compute. But for... The bigger you build your model, the more powerful your model becomes, the more it can benefit from having large amounts of data available. So if you have like a very, very large neural network, you will basically have the effect that as long as you have only a little data available, it will underperform a linear model or a smaller neural network. But if you have a huge amount of data available, then it will start to give you more performance. And that is basically... As we were still in an age where there was not that much data available, there was no use in producing bigger models or training big neural networks. There was just not enough data to train them properly. So if you look at something like... ChatGPT nowadays, that is something that is trained on a huge amount of crawled internet data. So with several... We don't know how much data\",\n",
       " \"internet data. So with several... We don't know how much data they exactly use, but there is kind of... The open competitors to ChatGPT, they use certain crawled data sets which have a few terabytes of data available. Some of that... On the Jupyter server, I have a copy of one of those dumps. That is... That can be used. It's like two terabytes of text data. And two terabytes is an enormous amount of text data. That is more than... So if you take your average library and would digitize all the books in there, that's a few gigabytes at the most. Terabytes of text data is incredible amounts of information. So if you... Think about... All this, we don't do... Our plan is not to use neural networks because neural networks are incredibly cool. They are, but the goal is we want to solve problems. We want to build products that can be used by somebody and that do something useful. And to do that, we need kind of deep learning. And groups of people who can create those products. So the question is, what makes a\",\n",
       " \"who can create those products. So the question is, what makes a successful deep learning team? So what is a team that can build a successful deep learning product? So... And there's several factors that make teams that can build successful deep learning products. So one thing is, they are really, really good at acquiring data. So data is... Kind of the most important resource that you have when it comes to machine learning algorithms. So everything else, if you start with a shitty model, it's okay. You can improve on that later. If you have shitty data, you will never get better. So that's... It's kind of the... Having good and enough data is kind of the most important things to start with. And if you have no way to acquire that, your product will definitely fail. So that is kind of the... If you're good at this point, you have kind of got the most important issue out of the way. The second thing is, good deep learning teams use every opportunity for automation. So if you... If you... If you think about it,\",\n",
       " 'for automation. So if you... If you... If you think about it, artificial intelligence is all about automating things. So the idea is, we want to build algorithms that can solve something, that autonomously do something for us. And basically, if a good deep learning team kind of tries to do the same on the inside, so you want to try to automate all the things that you do even inside the team to scale up the resources that you have. So... And if you think about managing two terabytes of text data from the internet, you will not be able to kind of manually do anything in there. It has to be an automated pipeline. It has to be an automated pipeline that process the data and do all the things in between... in there. In a similar way, almost all companies have data that is stored away in different silos. So you have like different parts of the company and they rarely talk to each other. And an important part is that you kind of... that you are incredibly good at data processing. Data warehousing. So taking in the',\n",
       " \"good at data processing. Data warehousing. So taking in the different data streams from different sources and joining them together is also something that makes really, really good deep learning teams. And if you think about it, if you have like... Which companies are incredibly good in artificial intelligence nowadays? You have mainly companies for which kind of those... For example, where this first part was incredibly easy. For example, Google. Aggressive data acquisition is incredibly easy for them because they are already completely digital. So all the people come there, enter search terms into their web search engine and produce already immediately digital data that they can use later on to improve their search algorithms and their data processing. And so on. And they also basically started at this point. They are not like an old chemical industries company like BISF where they started without any kind of... They started where the internet didn't even exist. So joining all the data sources is kind\",\n",
       " \"didn't even exist. So joining all the data sources is kind of... They basically could start with... When they started, they were able to make sure that all the teams have access to all the data that is necessary for them. And they didn't even... They were able to not even build up the silos in the beginning. And you have the same with all the big internet companies like Amazon and Microsoft and so on, which now are kind of the dominant players as well when it comes to artificial intelligence. So this... Because they had it easy to get the data in the first place and to not have... Siloed data sources. And a lot of the big industry companies nowadays which try to also get good at this. Think of, for example, the big car makers. They have a much harder job to even get good at data acquisition. So Tesla kind of already built data acquisition into their product from the get-go. So if you drive a Tesla, they will gather driving data from your car all the time with every mile you drive. You're forced... Volkswagen\",\n",
       " \"the time with every mile you drive. You're forced... Volkswagen is not doing that. So especially if you have older Volkswagen models. So having this ability to immediately build in data acquisition into your product is kind of a pretty important thing. So this kind of gives you an idea of data is incredibly important and everything we do in this course will only be as good as the data that we use to... feed those algorithms. So and... Within the course, I will focus a lot about those algorithms. So you will learn how to build deep learning models. But a lot of those practical things, how to build data warehousing, how to build products in a way that you can immediately acquire data from the user will not be something... I can teach you in this course. It's kind of... It would be out of scope, but it is also something that is incredibly dependent on the industry. So if you... For example, how to build a web shop in the way that you can always collect information, what the user actually wants to see and what\",\n",
       " 'information, what the user actually wants to see and what not is kind of a very, very complicated thing user interface-wise because you need to do something to build the interface in a way that in a non-applicable... obstructive way, the user can give this feedback or automatically generates this feedback without giving you a shitty user experience. And that is kind of a very, very complex and skillful thing to do in the first place. So within this goal, I want to teach you the relevant deep learning models and where to apply them. So we will cover several model architectures. I will teach you how... deep learning works from the mathematical side, how to implement deep learning models. We will implement a lot of those completely from scratch and then slowly work ourselves up using frameworks that take away some of this... the necessary work and so we can build bigger and bigger models and more powerful applications. We will implement and train several deep learning models and I will try to help you getting',\n",
       " \"several deep learning models and I will try to help you getting the know-how how to debug those. So if you think about how does any kind of software project work in practice, it's usually you try to do something and it doesn't work. And then you start debugging. And so I will try to also teach you some ways of how to... to figure out why something you are doing is not working because that's usually the... the default status for every kind of software at least in the beginning. And yeah, make you able to fix those problems. So I will not cover other machine learning techniques like for example support vector machines or k-nearest neighbors or a lot of other things that are for machine learning or other artificial intelligence techniques. So this will... will not be part of the... at least of this course. So in the exercises we will implement a lot from scratch and to see how the details work. So we will... while there is a lot of deep learning frameworks where you can just say okay, I want to have a neural\",\n",
       " \"frameworks where you can just say okay, I want to have a neural network with three layers, this many neurons and this is the data, go train it. We will start with implementing everything from scratch. Say okay, this is the data, this way we turn it into vectors, these are the matrices that define our neural network, this will be the gradients of those matrices, this will be the updating rules, how the neural network would update in each step and so that you get a better understanding how all those things work under the hood because that is kind of the... the thing that will be incredibly important to be able to fix problems because if you just blindly use a framework, if it doesn't work, you have no clue why it doesn't work because you don't know what is the error mode, what went wrong and so my goal is to demystify those inner workings because kind of neural networks kind of tend to scare people away. They treat it as black boxes where nobody knows how they work on the inside and my goal is that at the end\",\n",
       " \"how they work on the inside and my goal is that at the end of this course you will know how they work on the inside and that this mystery will be lifted at least for you. And so... and that you know how the details on the inside work. So, I showed you... at the beginning, I showed you this Jupyter server where you find the link on... in OLAT. If you don't want to use that or if you, for example, want to work offline because you don't... the internet is bad, which at the university, can often be the case. So, the Wi-Fi here is kind of flaky in a lot of cases. You can install your own Jupyter environment. So, one way to do that is, for example, the Anaconda distribution which exists for most relevant operating systems and... and which is kind of one of the easiest ways to install kind of Jupyter distribution... Python distribution alongside with Jupyter and... and... and... and everything that you might want to use. But you can... for doing the exercises, you can do that any way you want to. So, it's not...\",\n",
       " \"exercises, you can do that any way you want to. So, it's not... there's no required way and especially if you have... if you are more proficient with your laptop setup, then probably you'll prefer some other way. But in that case, you also probably don't need my help to do that anyway. So, if you want to make a local Python and Jupyter installation, this Anaconda distribution is kind of the... the way I would recommend it for you. So, are there any questions regarding course logistics, the topics of the course? Yeah? I don't find the OLAT course for that. You don't find the OLAT course? Anybody else with that problem? No, I could find it on Jupyter. You could... okay. So, it should... so... I would say I'll send you the link via Teams, but probably that's the chicken and the egg problem. So... We can find it over the Masters course. So... True, there should be... there should be a general Masters course. So, are you registered in the Computer Science Masters course? There is... there should be one where\",\n",
       " \"Science Masters course? There is... there should be one where there's a link. Otherwise... So, if I'm... course... catalogue... So, otherwise, if you are going to the OLAT catalogue and go to thbingen and go to FB2 and then search for me, which is this nice looking guy here. Then it should... Then it should be... Then I was too stupid to make sure that the course is in there as well. So... This one... And... Yeah. Dis запairyюсь... Yeah. See, I'm quite the Maximal Girl for this. Mmm, like that. That's my inspiration. That's... That's great. That's... That's... Thank you. And... Yeah, there's another big thing I've gotta ask you. I'm not suppressively에 Wendy's master. I'm not jul였습니다 on those. But... What is it... So... This is a fear test. There's a feature called Scripture Name Speechㅎ,- and now probably the internet broke down because it should so and here we go so okay now you can find it in my course list here so otherwise you can also if you send me an email I'll try to send you the link as well so if\",\n",
       " \"send me an email I'll try to send you the link as well so if you that goes for the entirety of the course so if you have run into troubles or issues at any point feel free, ideally write something in the Teams channel because that means maybe somebody else might be even able to help you before I do and other people can also see the solution for the problem as well so if you have issues just write in the comments in the Teams channel ideally and then we'll try to resolve the problems so on Friday as I said I'll do kind of a small Python introduction now we'll start with the main part of the course so we'll start with the question what actually is a neural network so again I have some formatting issues with those images here so assuming I have some data so I have the size of the information about the size of a house and its price so I have like the number of square meters and I have the price on one axis so I have basically two dimensions of data and I have one, two, three, four, five, six houses and what I\",\n",
       " \"and I have one, two, three, four, five, six houses and what I want to do is I want to have a way to predict if I'm given any kind of size of one house I want to predict the price for it and so I have a number of square meters and I have the price on one axis so I have basically two dimensions of data and one of the easiest ways to do that is do linear regression so we can say okay I'll plot a line in here say which is a linear function of the size of the house and which which has two free parameters w0 and w1 and if those two once I know those two parameters I can calculate for any kind of size a price for that house doesn't need to be the correct price it's just a way I'm the way I'm modeling the world I'm saying I'm assuming the price is roughly a linear function based on the size of the house and I'm trying to learn the parameters of that function those are the two parameters that I want to learn and given I have them I have my entire model h and that model will give me a price for the house and what we\",\n",
       " \"h and that model will give me a price for the house and what we want to do is and this kind of linear model is kind of one of the earliest things for me to do is to do a linear model and this is a really useful method for this kind of linear model and it's a really useful method for machine learning in general so that was basically invented back by Gauss in the 1800 something how to calculate a regression line through several data points and what we want to do is calculate those parameters such that the distance and what the distance is we'll see later but that the distance is the distance between the actual prices of the data points that we have and the price that we predict gets minimal. But if you think about what this model that we have here does, then there is one issue that would be more obvious if the cropping wouldn't be so bad. But if we have a price, or if the size of our house gets pretty small, the price gets negative. And that is kind of very, very obviously wrong. So we can try to fix this\",\n",
       " \"kind of very, very obviously wrong. So we can try to fix this model and say, okay, we make a new model, and that model is take the maximum of the linear function and zero. So if the linear function that we just had, is bigger than zero, we'll just take that one. And if it's below zero, we just take zero. So we kind of cut our function off at zero and make sure it doesn't get below that. And this is probably a better predictor than the one we had before. So because we kind of have fixed one of the small issues that we have with this, we never get a negative price. And that makes things at least a little better than it was before. Still having a zero-priced house is probably pretty unrealistic, but it's at least not as wrong as it was before. And what we basically did here was we created a very, very small neural network. We have some input, which is the size of the house. We have our neuron, which is... this little function here, which... it takes... has a linear predictor, and this maximum of the linear\",\n",
       " \"takes... has a linear predictor, and this maximum of the linear predictor and zero part, so it has kind of something additional to this linear part, and outputs some estimated price. So it's... And the neuron here is basically this function. So that is mainly what one neuron, an artificial neuron, an artificial neural network is. Doesn't need to be those functions. It doesn't need to look exactly like this, but it's one way a neuron could look like. When you hear people talking about neural networks, then neural networks are often compared to the brain. And this is... It's somehow... The comparison doesn't always hold very well, especially in this case. A human neuron, as well, is a neural network. So a human neuron is way more complicated than what this neuron does. So like the information processing that happens within one human neuron is way more sophisticated and does way more than like this simple linear plus a little bit on top operation over here. So the comparison between like a human neuron and this\",\n",
       " \"here. So the comparison between like a human neuron and this artificial neuron that we created here is weak at best. So if... So the neuron that we have here, as I said, consists of a linear part and something on top of this. And this something on top of is called the activation function. Which is it's a one to one function. So it's a function that takes one input and produces one output. And in this case, we use one input and one output. So it's a one to one function. So it's a one to one function. So it's a one to one function. So it's a one to one function. So it's a one to one function. Also, it can be taken as a formless node to any node 활동 of any new member. So in the future, I'm going to use this original AvantRanch function to solve what deep part of this function I'm talking about now called the linear unit or or another way to call it linear. So now youHow is it an vector? rectified and so we make sure that it never drops below zero and this it will come to back to that later on but it's kind of\",\n",
       " \"and this it will come to back to that later on but it's kind of one of the most used activation functions for neural networks so this simple this very very simple predictor might do some okayish job for predicting the house price but we actually probably want to do better and to do better we need to take in more information so that we the the size of the house is one particular piece of information that we can use but we probably want to use more information and what we want to do is for example use more inputs like the size of the house number of bedrooms the location where it is the distance to the next public transport and so on so we have more information for each of our data points and we don't want to just use one stack of neurons but do something like have one neuron predict some intermediate feature so for example this neuron you can use this neuron to predict some intermediate feature so for example this neuron should predict not the price but the possible family size that the house could\",\n",
       " 'not the price but the possible family size that the house could accommodate and it could predict that from the size and the number of bedrooms and this neuron should predict the school quality of the surrounding schools which it should be it might be able to predict from the location or the zip code and it might be this neuron should predict the commute the commute time for for the inhabitant which it might be able to predict from the zip code and the distance to the nearest public transport this way those neurons derive some create some derived features they calculate something that is not directly in the input but can be computed from the input so we get more refined features and the next neuron will take those more refined features and predict the price of the house from it. And that is basically what deep and a real neural network is we have several layers of neurons each layer computes some more refined features from from its inputs and it gives those to the next layer of neurons which can use the more',\n",
       " \"gives those to the next layer of neurons which can use the more refined features to make either the final prediction that we want to have or create even more refined features and those are the things that we can use to predict the price of the house. So I think that's it for this presentation. Thank you very much. Thank you very much. Thank you very much. Thank you very much. Thank you very much. And we do and when using building in your network we usually do not observe those intermediate features we do not they they just get passed to the next layer of neurons. We only observe that part of that part here we look at the output that we are actually interested in. We do not look at those those intermediate features. And because we do not look at those we also actually don't care if what the what they actually represent. So what we will do in reality is we will let the algorithm figure out those intermediate features on its own. So it might turn out that one of those intermediate neurons will do something like\",\n",
       " \"that one of those intermediate neurons will do something like predicting the possible family size because it's a useful intermediate feature. But we do not force the algorithm to do exactly that. We will let the algorithm figure out on its own what might be a useful intermediate feature to make a better prediction for the price. And then it will kind of train those neurons to predict that intermediate feature so that this neuron has an easier job doing the price prediction over here. So the job of this neuron is basically figure out some intermediate property of the data that you have here so that this neuron has an easier job. To predict the price. And if you stack on more layers, each layer has basically the job of make the job of the following layer easier and predict some figure out some property that might make the job for the next layer somehow easier. And our training algorithm will later on figure out what the useful intermediate features will be. So also in this case, we have a very simple\",\n",
       " \"features will be. So also in this case, we have a very simple algorithm. In this case, we said, OK, this neuron predicts the possible family size from the size of the house and the number of bedrooms. Because we do not know what the final features will be, we usually do not put any limits on what kind of input which neuron can use, but say, OK, you can use any of those inputs to make your prediction and you figure out which input is important and how important which input is. So it might figure out that it doesn't need those. And puts a weight of zero on this edge and doesn't use the zip code. But it's up to the neuron to figure out what input features it wants to use and which not. We call this architecture being fully connected. So every input from the last layer will be connected to each of the inputs of the next layer. So each output from this layer is connected to each input of this layer and so on. So what the neural network does is each layer outputs new, more abstract features, which will make the\",\n",
       " \"layer outputs new, more abstract features, which will make the job for the next layer easier. So during training, the algorithm decides what features are most useful. So the algorithm will decide what it wants to learn to make the final prediction as good as it can. So I say something like, OK, let's trick a Satan or create a robot. So there's start to be a meat ass of those, which will then help to build new کوts of these functions. And that's your end point. And I can bend in this way. So instead of something that's in graph, I'm going to change the curve to govern what goes in right where it goes in a fundamental invested order to build as my new culture, body modelIDE löp E gif in thecios that I've changed statements. I changed the towards. What will be clear? What everybody quelleесь. other applications. So what we can for example do is we have an input like an advertisement and a user's cookie history and as an output we want to have did the user click on the ad or not which is kind of one of the\",\n",
       " \"did the user click on the ad or not which is kind of one of the earliest use cases for big data where people where internet marketing companies started to use those massive amounts of cookie history data from users to create more targeted ads which are haunting the internet ever since. Other things can be the input our input can be some kind of image and the output can be what object or objects are in the image. Like you want to take a photo or we want to find out if there is a cat on the image or not. So that's the way we do it. Our input can be some audio data and our output could be something like the text transcript of that audio and we want to kind of do speech recognition on some audio data. We could do something like machine translation where we have an English sentence as an input and one Chinese sentence as an output. We could have a lot of very very different inputs like image data from different cameras. Some radar or lidar information and we want to output the position of other cars and our\",\n",
       " \"and we want to output the position of other cars and our position relative to them for like an autonomous autonomous driving applications. Okay application. So when thinking about how to use deep learning for something we need to think about in this kind of abstract way what is kind of the input data that we have. What is the best at any point in time what data does the algorithm have access to. And what should be the prediction that the algorithm has to do. So what is what is it that the algorithm should produce when it sees something. And in some cases that is kind of pretty obvious. But for example if you think in some cases it's a little bit surprising. So for example with chat GPT the input is I have a text at the up to a certain point and the prediction target is what is the next character in the sentence. So and which is if you is it which is a pretty surprising thing. It is a thing because what when you start to build something like a chat bot you think about OK but what I want is an answer to some\",\n",
       " \"bot you think about OK but what I want is an answer to some certain kind of question or something like that. I have a question that I want to generate an answer but answers are something where we don't. Have any training data for but the next character is something where we have a lot of training data for. And if and surprisingly predicting the next character is doesn't give you the entire answer. But you if you do it often enough you will get the entire answer. So having it using this kind of surprising target for that we have here. In this case yields an incredibly powerful system at the end. And so thinking about OK what what what will our our algorithm get and what should it output and. Do I have enough data for exactly this kind of combination so I can think of a lot of things that I would want to have to want to have a prediction but where I don't have enough data for. And so we kind of have to think do we. Have enough. Audios with text transcriptions at the end so that we can create our speech\",\n",
       " \"text transcriptions at the end so that we can create our speech recognition system and. It's kind of the important thing to to to think about when when starting some some projects or what what exactly will be our input. What exactly will be the output that our algorithm has to predict at the end. And. How do we get enough data of those input output pairs. So that the algorithm can train on that. So. If you. When we go through those examples the first two of them are very very simple ones so it's kind of very structured data data so the cookie history will be like probably a list of different websites that the user visited and. We have like a binary output and this is just a number as an output so we have very structured data. And do some prediction. Predictions on this. And this will be kind of is kind of a use case for like classical fully connected. Your networks that one can use for this or like doesn't even have to be a neural network it could be also a use case for very very classical machine learning\",\n",
       " \"be also a use case for very very classical machine learning algorithms like just. Some kind of regression problem. When it comes when we look at other of those examples it gets more difficult to to think about what exactly those inputs and outputs. Are so it for an image we don't an image is not just that it is a way more complicated structure so you have like a. Basically a matrix of pixel values for each pixel you get the. The value of how the red value a green value of. A blue value. Which. Which which form the entire image and images can be different sizes some images are larger some. Are. Different. Sizes. Some images are larger some images are smaller. And. Different. Sizes. And. Some are smaller so they are not not constant in size so it's much much harder to handle those and for. Those kind of applications we will learn about different architectures of neural networks that can handle those kind of more complicated inputs. Same way in similar way if you think about all your data you get kind of a\",\n",
       " \"similar way if you think about all your data you get kind of a stream of. Audio signals and if you want to have a text transcription that is also not like a binary output. Or like. Just one number it's kind of again a stream of characters that you want to translate audio into and. Again we will look at the see about how several tricks that can be used to. To. To. To deal with like those more complicated. Structures of inputs so these. This for example is kind of the classical use case for convolutional neural networks those will be. The. The. The. The. The. The. The. The classical use cases for recurrent neural networks that can deal with sequences of informations. And something like this might even need something very very custom where you have like a very very diverse amount of inputs. So if you do auto autonomous driving you have kind of image input but you have also image input over time because like the part of the. The images. It doesn't just matter. Where what you see on those images and on your\",\n",
       " \"just matter. Where what you see on those images and on your sensors. right now but also what you saw like within the last 10 minutes because you might even if you don't see a certain car in any image at the moment it might still be around you and you might have to make an estimation of where it might possibly be and so something like this might require a very custom and very specialized architecture so if you if we think about for example image classification so what we want to we what we get as an input is some kind of image and what we want to produce is some kind of output is this a cat or is this not a cat and so we basically have a binary output one or zero and as an input we have kind of a lot of pixel values more of them later but we as before we have like two inputs x and outputs y and the input notation that we want to will use is we will say that our inputs are called X and they are vectors in an n-dimensional space so we have like an input vector so and a piece of input data and the corresponding\",\n",
       " \"input vector so and a piece of input data and the corresponding label that is one piece of data that we can train our algorithm on so and we don't need just one example to train on we need a lot of those so we will need an entire set of training examples and we call this detrain so our train data set training data set will be a set of m examples or m train examples each being a tuple of one input feature vector and the training label so and this number m is the number of training data that we that we can use something else that we will later use is the number of test examples so we will use a second later we will use a second data set which we call detest which also contains a number of examples that we will use for testing our algorithm and that we'll talk about this later again but this will be an important thing thing we should never build some kind of machine learning system and then just use it without ever checking how good how good it does on data that it has not seen before so the test data the the\",\n",
       " \"on data that it has not seen before so the test data the the idea of the test data is basically that we use some data that is not part of the training data that we can use to evaluate how well does our algorithm do if it sees new information that it has not seen beforehand and which is why we kind of need to withhold this information there are some exceptions to this if you for example train something like a language model like chat gpt on 20 terabytes of data and the amount of data that you have is so enormous that your algorithm during training will see each input example at most once then probably you will not need a testing data set anymore because you the amount of data that you the the the of data is humongous anyway and you can just use the data that you trained on also for testing because it doesn't matter anymore but on the other hand taking something out of the such a big data set this also doesn't matter anymore so if you have that many much data then kind of the the the the rules change a little\",\n",
       " \"much data then kind of the the the the rules change a little bit when doing any kind of calculations here um we try to use the to to to do as much as we possibly can using vector calculations so if you have ever worked with matlab or with numpy and python for example um using that if you if you can calculate anything in some kind of loop if you write a for loop for this the first value that and i multiplied with this the the first value in the other vector and do that again and again again again you will get incredibly slow code because the python code part of this code is incredibly slow and matlab is also a pretty slow scripting language on its own so you get pretty slow code if you do if you write anything in loops if you want to have fast code in python you need to vectorize things and use some kind of a library like numpy that does vectorized operations and then you can kind of uh kind of turn your loops into vector operations so and to do that we need to kind of uh to make sure that we don't don't do\",\n",
       " \"that we need to kind of uh to make sure that we don't don't do too many mistakes this way so one thing we will do is if we have like all of this training data that we have here we can basically each of those vectors here and we can write a matrix containing all those input vectors so let's say that we have training examples is one input vector of information and what we can do is we can write a matrix containing all those input vectors here so we get like the first input vector the second input vector the uh the last input vector and um write them into one large matrix which will be then an n input features so how many inputs did we have here so where like one input feature might be something like house size zip code distance to public transport number of bedrooms and so on and this is the first house the second house and the last house that we have and this way we get like one big matrix with all the input data and this we can do the same thing for our output in this case so we can say ok I have liked the\",\n",
       " \"for our output in this case so we can say ok I have liked the for the first output the second output and so on and put that into one big this is 1 by M matrix so we kind of just have one entry in in this in this direction but otherwise it's kind of it's it's stacked in the very same way then this vector was and this way is like something like this this way and this way is what I was doing in that way and this way is what I was doing in that way this way is what I was doing in that way so And now when we do some calculations, we can do them for not just for one of the examples, but we can do them for all the examples that we have at once, because we can kind of just multiply things with this metrics and this way we can, we avoid doing a loop over all the training examples, but we can kind of multiply, we'll later multiply this vector with something else and this way get kind of the benefit of avoiding some kind of loop over all the training examples. And this will be, doing this consistently as often as we\",\n",
       " \"And this will be, doing this consistently as often as we can will turn into a lot of performance benefits and make the difference between something that actually works on, actually works on something that is so slow that you will never see the results of it and at least till the term ends. So if we think, if we say, okay, we want to turn, we say we have some input features here. The question is how do we turn things into input features? So this is kind of, we say, we want to have one long vector of information here and we want, which we take as our input. If we start with our, the image of our cat here, how can we turn that into one long feature vector? So if we start with this image here, so I've turned this into gray scale now to simplify things, we get 544 by 564, seven pixels. So that is kind of the dimensions of this image. So it's 545 pixels wide, and 567 pixels high. And each pixel is a value between zero and 255. So that's kind of the, you usually reserve one byte for each pixel, for each color\",\n",
       " \"you usually reserve one byte for each pixel, for each color channel. So having, which means we get this number between one zero and 255 for each pixel. And so we can say, we can turn this image, into a long vector. And then we can turn it into this matrix here, which has kind of the pixel values at each position. So, and this is the number. So one always has to be careful with images and matrices, because matrices usually take the row as the first index and then the column as the next one. And if you talk about images, then most image libraries take the width as the first index and the height of the second index. And that is common source for, you know, for, you know, for, for a lot of bugs, because that's kind of, it's easy to mix those things, things up. And it's pretty annoying that we have different kind of conventions there, but yeah. This way we can, we can turn our image into, into a matrix this way and making sure that we don't mess up the height and width. Otherwise we wouldn't matter too much in\",\n",
       " \"the height and width. Otherwise we wouldn't matter too much in this case, because we just get a catch, which is flipped over. And this way we can, we have turned our input into one large matrix of information. If we have a color imagen, image, we usually have three input channels. So we have like a blue channel, a green channel, a red channel and each of them as its own matrix basically. So we get not one matrix but three matrices. So we, suddenly our information is kind of, close to the address. This can also be sorted as a point in the cable, which then we will change the interface, and it can also go down to Element and also to image. Just for, or Vamos, one more slide. So, it has all three shrinks. This system, this thing that I talked about is simply the, What were the numbers here? 5, 6, 7. 5, 6, 7 by 5, 5, 4. 5, 5, 4 by 3. So we have like a three-dimensional object here where we have a list of matrices. And each of them has one. Each entry contains one pixel information for one of the color channels.\",\n",
       " \"contains one pixel information for one of the color channels. Sometimes we even have a fourth channel which contains so-called alpha information which is kind of how transparent is the image at that pixel, which is, for example, I think GIFs have this information and PNGs also where you can have like a transparent image as well. So you get like a transparency channel as well. So you can also have four channels over here. So that's the simplest way to turn all this into like a feature vector is by just stacking those matrices. So we can just say, okay, I'll stack all this information. So I'll just say, okay, I'll take like the first pixel up here and it ends up here in a very, very, very long vector. And I'll just write this way. I write all the values from all the pixels down into one very, very long vector. And in this case, I get a resulting vector which has... 900, almost a million dimensions. But we... Which is a lot, but we... Suddenly we have turned our entire image into one... Into a one-dimensional\",\n",
       " \"have turned our entire image into one... Into a one-dimensional object. So into a one long vector with... Yeah, so with a lot of entries. So in every image... A problem here is every image has different dimensions. So kind of this... By the number of color channels might be the same for all our input images. The height and the width might be different for each image. So the resulting vector might be different as well. So the simplest way to kind of solve this is use some image modification software and rescale every image to have the same width and height. So... And make sure that all of them are the same. Question is how large should we make this? And the answer to this is usually just large enough that you as a human could classify it. So if you can identify what is on the image, then we can assume the algorithm should be able to do that as well. So if we... Turn the... Turn our cat image into this size, then that's probably still enough for you to identify the cat there. So probably for our cat\",\n",
       " \"for you to identify the cat there. So probably for our cat classification, that might be still enough. So... So we can... With 64 by 64 and color, we get 12,288 features. And if we can get away without colors, we can turn it into grayscale and this way turn it into 4,096 features. And... This... This kind of pre-processing will also be a big part of what needs to be done to make... To get actual deep learning systems to work because figuring out what is the minimum amount of data that we can get away with means if we scale everything down, everything else will work faster and probably even better than if we leave everything at the highest resolution. But this would also make it more difficult for the recognition to work, right? Like for me as a human, it is harder to... Yeah. So... The algorithm has one advantage. It kind of... It sees every pixel in the same size than otherwise. So it kind of... It's... But it's... It's... It's true that if you scale it down too much, then it will get harder for the\",\n",
       " \"if you scale it down too much, then it will get harder for the algorithm and it will get... The performance will drop. If you make it too large, the performance will also drop because for other reasons, we will cover those later, but if you get too many input dimensions, then the algorithm gets also a harder job at making a proper prediction and we will get to see other ways to work around those problems again, but it's often trying to find a sweet spot. So you usually have several constraints. The quality that you want to achieve at the end is one of those, but also kind of the compute power that you can invest in there and the time you have and the result of the number of input images that you can use for training and all those kind of determine what... what kind of size you can get away with here. So if you have too little images, you also need to scale it down because otherwise you will run into problems that are called overfitting and then the problem... Your algorithm won't work well and it's... It's\",\n",
       " \"the problem... Your algorithm won't work well and it's... It's usually a very fine trade-off and there is no silver bullet there. So you... You will need to do experiments and see, okay, if I scale it down even further, does it improve or does it get worse or if I scale it... If I scale it up a little bit, does it get better or does it get worse? And... It highly depends on the application of what is the right approach here. But yeah, it's... Making it smaller will make it more difficult at some point, but it will kind of resolve other issues that you could have and so making it smaller will help you up to a certain point and then it gets worth again. So... I think I'll stop here for today. So we covered quite a bit of basics how to turn data into vectors and everything we will do will be... We will process vectors here. So any kind of deep learning algorithm sees ever is a vector of inputs or maybe it's like several vectors of inputs, but everything will be numbers. So one of the things we will always need\",\n",
       " \"will be numbers. So one of the things we will always need to do is figure out how to turn things into numbers and... Which has a lot of interesting facets as well. For images, it's almost easy, but for texts, for example, and words, this can get also a pretty... There's also pretty interesting answers of how we can turn words into numbers so that an algorithm can work well with those. So... Do you have any more questions till now? Yeah? Will we have a written exam at the end? It will be a written exam at the end. Yeah. So... I'll upload... I also upload the first exercise sheet today so into OLAT. So there will be like a very... A first exercise sheet, which is only introduction into NumPy and Python and so on. So it's not... Nothing real deep learning so far. So we'll start with those then with the next exercise sheet next week. And will the exam be sent on the computer? Or will it be... No, it will be written. So... The exam will not have any parts where you need to write code. There might be parts where\",\n",
       " \"parts where you need to write code. There might be parts where there is some code and you need to identify what's wrong with it or something like that. So... But you don't... Will not be required to write code in the exam. So it's... In some way, I realize that it's... It's not the ideal form of examination for a course like this because what I want to teach you are practical skills. So you... I'm hoping you go away from this and are able to program your own neural networks and create your own deep learning systems. But... And like a written exam can only cover so much of that skill. So it's... I'm trying to make those things match but kind of the exam is only a poor representation of what I want you to learn here. Yeah? It's a good idea to bring your laptop for the exercises. So... So, for example, something you can do is try to follow along when we do the exercises. So for the... For the Friday... Part of the course, it's a good idea to bring your laptop. For the Wednesday part, it doesn't really matter\",\n",
       " \"your laptop. For the Wednesday part, it doesn't really matter because that will be more me doing... Showing you something. But for the exercise, it's probably a good idea if you have the ability to follow along. And even just typing something, just writing something, it's a good idea. And then, you can do it. So, I think that's it. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. Thank you. That's it. Thank you. If you're just typing something off and trying it on your own, it's sometimes helpful to figure out how things work. Okay. Any more questions? No. So, then... Then, see you next Friday. Okay, last week we talked about machine learning systems and that one of the first things we need to do is we need to make sure that we can feed those with data in form of simple vectors. There are several ideas how we can turn stuff into vectors. For example, if we say we have some kind of color image, we can interpret that\",\n",
       " \"we say we have some kind of color image, we can interpret that as having three matrices, each having the same size and dimensions, and one matrix is for each of the color channels. We have three channels. We have three colors. Each of them is an M by N matrix. So in total, we have some object that is M by N by three. And this object can be turned into one long vector by just stacking those matrices. So we can kind of, in NumPy, this would be taking this M by N by three object and just call reshape on that and just turn everything into one long vector. And this way we kind of get one vector with all the input data for this one image. So later when we talk more about images, we will see other ways how to properly deal with picture data. But for now, this is kind of the way how we can do that. So I think that's it. Thank you. Hopefully people focus on it. Great. So I think slide eight, one of the point in time, kind of the window that in this� have to be fixed in M is actually Star. And Star each image in this\",\n",
       " \"to be fixed in M is actually Star. And Star each image in this case can be controlled. So with Star, for instance, is mainly to apply to a column in multiple images. They can spawn in them. They can posted them, just a single left plus right. So they are. that we rescale the image. So one thing is that each of the images has like different dimensions, so these numbers change from image to image. So this is kind of a problem. And another problem is that we might want to make sure that we don't have to deal with a million dimensions over here. So one thing we want to do with images is often to rescale them. And like a rule of thumb is to make sure that we rescale it so that it's just large enough that we can classify it. So in this case for example a 64 by 64 image might do the trick. So it's big enough that we can still see the cat inside. So classifying a cat should still work. So for the final algorithm something like 64 by 64 might be the right number. And if we start experimenting at this point we can do\",\n",
       " \"number. And if we start experimenting at this point we can do a lot of work. So we can do a lot of work. So we can do a lot of work. So we can do a lot of work. can then start experimenting and see okay maybe it's maybe it should be 128 by 128 or maybe it should be 32 by 32 and we can kind of start experimenting from here and see if the performance of the algorithm will improve in any of those directions on this again later. So probably we can also remove the color channel and just make everything grayscale so that also kind of kind of reduces that the dimension we have over here. So this is kind of pre-processing our input. So we don't kind of pre-process the input just for the the sake of turning everything into a vector. What we wanted to have in the end is make some kind of prediction on the input data. So and like one thing we were to start with we want to start with a classification task. So that was unfortunate. So so if we want to So if we want to So if we want to do classification what does it mean\",\n",
       " \"we want to So if we want to do classification what does it mean that means so what it means is we want we have like a binary output in our case the picture is a cat or it's not a cat and if we have a binary output one thing that we want to predict is the chance that the image is actually a cat or not. So what we want to predict is so so ultimately we want to predict it is a cat yes or no so we have a binary output but the inter we have an intermediate goal here we want to predict the probability that the image is the target class so in this case a cat or it's not a cat given the input that we have so this is kind of the probability notation here so it's so probably you've seen that in some kind of statistics class beforehand so we say okay probability of some random variable given another random variable so it tells us given we already observed something of the world we want to give we want to give the probability of the input that we have. we want to give the probability of the input that we have. we want\",\n",
       " 'want to give the probability of the input that we have. we want to give the probability of the input that we have. of this random variable if we would remove this one it would basically say what is the probability that any kind of image is an image of a cat so that would be kind of we take how many images are there in the world and how many of those are images of cats so this would be kind of the probability that some random image is an image of a cat that is not that interesting so in our case we always deal with those conditional probabilities that we say we have some information about the world in this case the features that we observe and we want to know given the features that we have seen what do we think is the probability of this random variable which is the class that we want to predict at the end so and what we want to build is a machine that will give us or approximate this probability over here we want to know what is the probability of what what is this probability over here. and this',\n",
       " \"of what what is this probability over here. and this probability interpretation has some huge advantages in a lot of cases so in the case with the cat image image you might say okay this is not something that has something to do with probabilities because it's either a cat or it's not a cat so there's no no probability in here but in other cases there is actual probability so if you if you think about for example i want to classify i have a patient and i know the patient's blood pressure age some some some cholesterol level and so on and what i want to predict is does the will this person have a bad covid-19 19 outcome or not so and in this case even given the very same input features two patients with the same blood pressure same age same cholesterol level and so on one might have a good outcome the other might have a bad outcome so you can so even even if all the input in features are exactly the same one patient might might might be good the other might the other might have a bad outcome and this this\",\n",
       " \"other might the other might have a bad outcome and this this means there's a lot of tasks where only having those input features might not be enough to completely distinguish between those classes and in this case we you are actually you you actually have a probabilistic outcome so you might say something like given this blood pressure this age and so on you have a 90% blood pressure this age and so on you have a 90% chance that you will be fine given your COVID-19 infection. So 90% of the patients who look exactly the same will have this outcome over here. So in several cases, the probabilistic interpretation here is the only thing that makes sense because you might not have enough information to really know if somebody will have a good or a bad outcome. And the information that you have might only give you a statistical information. And that's why when dealing with machine learning systems, we always work with this statistical information and always say, OK, what we want to predict is a probability. It's a\",\n",
       " \"say, OK, what we want to predict is a probability. It's a probability that there is a cat in the... The image given those are the pixel values and a good classifier should have a very high confidence over here. So given some something here, a pretty good classifier should give you a very, very high probability over here. Because it's kind of the task is something where if there is a cat in there, it should give you a pretty high probability. But it will... What we will get is always some kind of the confidence of the classifier. If it gives you like a 50% probability. If it gives you like 50% chance, it means the classifier is pretty unsure and it doesn't really know if it has seen a cat. It might be something there's very famous pictures of where it's hard to distinguish if there's a muffin or a dog in the image. So it might be really hard to distinguish it. And this probability that we want to predict over here will kind of give us the level of confidence that our algorithm has in. The prediction it makes.\",\n",
       " \"confidence that our algorithm has in. The prediction it makes. So that's what we want to have. We want to predict this probability that we that there is a certain class given those input features. So and so that's what we want to have. How do we make how how can we make sure that this is what the algorithm will predict? We do that by saying. So. At least for as long as we we start with logistic regression and the logistic regression formula for this prediction is we take. A linear. Translation of our input features. So we multiply each of the features with some weight. At some bias. So this is kind of. This is like one value. If we have 4000 input features. This would be. A value. So it's a vector that has exactly the same length as our input features. And we take some kind of function of this and this function is called the sigmoid. So the sigmoid function is defined as one over. One plus. E to the power of minus whatever we put in here. And so this is how to do it. This is kind of the formula. And the way\",\n",
       " \"this is how to do it. This is kind of the formula. And the way this. We. We'll see in a bit how this looks like. So we. We have this the sigmoid function of. W. These are the learned parameters. And as I said. The learned parameters consist of a bias term B. So which is just one number. And a weight vector. Which has the same dimension as our input features. So. And. The. So we put this thing together. So this thing together we call hypothesis. Hypothesis. So this thing. Is. The hypothesis. That we want to learn. So it's kind of. We want to learn a certain function. This function is parameterized. By W and B. So there is like two free parameters. A vector. And this bias term. And. Depending. On. Of. Those values. Our prediction will also change. So we can modify those values. And get different predictions. And every kind of. Choice that we can take for this vector. And this bias term over here. Will give us a different hypothesis. So that's the building blocks that we need for logistic regression. How does\",\n",
       " \"building blocks that we need for logistic regression. How does the sigmoid function look over here. So what is this function? This function is basically something. That maps every input. To a number between zero and one. So if we put in a very small number over here. So that means this number. Gets gets very big. If this number gets very big. This number gets very big. So everything in the denominator. Down here. Gets very large. And if that gets very large. We get in total a very small number. So it approaches zero over here. And the other way around. If we get an incredibly large number over here. Then. This number gets. Close to zero. If it gets close to zero. The denominator gets close to one. And if it's close to one. We get one over one. So in this direction. The whole thing approaches one. So what the function maps. Kind of any value over here. To something between zero and one. And that is kind of a nice property. Because that is exactly what we want to have. If we want to predict a probability. If\",\n",
       " \"what we want to have. If we want to predict a probability. If we want to say the output should be some probability. Then. That should be a number between zero and one. So the probability over here. That should be a number between zero and one. Having like a probability of more than 100%. Doesn't make sense. And the probability of less than zero. Doesn't make sense either. So making sure that what this hypothesis. Predicts. Is always something between zero and one. Is kind of nice. So that means. No matter what values we choose over here. The output will. Always be a valid probability. So that's already kind of nice. So. Given this. We need. The next thing is. That we need to define is. How good is the hypothesis. So if we can choose any kind of value over here. We can choose any W. Any B. And depending on the choice we make over here. We get different probabilities over here. And if we get different probabilities over here. We get different predictions. So. For if it's a cat or if it's not a cat. And we have\",\n",
       " \"So. For if it's a cat or if it's not a cat. And we have to kind of evaluate. How well the prediction is that we make. So given any. Given any kind of data that we have. We need to define. If we make a good prediction or not. So if we say we have one. Data point. So one example. One input image. And the target class. So the information if it's a cat or not. What we want to have is. That. The prediction that we have. Should be close to the actual class. So the actual class will all either be a one or a zero. What we output here would be. It could can be any number between one and zero. So it could be either a very large number. So very large probability. Or a very small probability. And. What we want to have is. That this prediction should be pretty close to. The actual. The actual value. So that's what we want to have. So. For logistic regression. There is a very concrete loss function. That we always use. And. This loss function is. Defined like this. And this is called. The logistic loss. And so. Let's.\",\n",
       " \"this. And this is called. The logistic loss. And so. Let's. Let's. Look at what this does. So. Our target class. Y. Is either. Zero. Or it is one. If it's either zero or one. If it's zero. This means. This part vanishes over here. If it's one. It means. This part vanishes over here. Because this part. Thing becomes zero. So it means. Either. We have this part. Or we have this part. Of the. Loss function. Depending on. The value of y. So. If we say. Y is equal to one. And this part over here. Vanishes. And it means. We take. Our last loss function. Will be. The logarithm. Of. What. Our prediction. So. Logarithm. Of. Our prediction. So what. What is. If we. Get. A large. Prediction. So. How does. How does. The log. Of. Any. Of. Of. Any. Find. A function. Look like. So. I don't. Haven't. Made. Plot. Of this. Yeah. Would. Have. Been. Nice. If we. If I had. Some. Internet. Connection. Right now. Yeah. And. So. The. Logarstellen. Let's. See if. I can. Get. Some. Plot. Some. Plot. Of. The. Logarithm. So. The.\",\n",
       " \"can. Get. Some. Plot. Some. Plot. Of. The. Logarithm. So. The. Logarithm. Is. some function that getting closer to zero it approaches minus infinity and then levels off the closer the larger the input gets so if i take so if i take this one and i have one over here and i take and if my y hat so what i predict is very close to one that means if it's close to one then my the logarithm of the of my prediction will also be very very close to zero so it approaches zero so my loss if my target class is one and my prediction is very close to one then the loss over here that this number will be very close to zero so the loss function that i have for the loss function is very close to zero so if the loss function that i have for the loss function for this example will be close to zero if on the other hand i have my prediction is is off and i make a very some have some number that is very very small and that means my logarithm over here is very very very close to minus infinity so it gets closer to minus infinity to\",\n",
       " \"close to minus infinity so it gets closer to minus infinity to the the smaller this number over here gets and that means that it'll need to be very very close to zero because theki pretty much um so that it is together so that the practice of asta very if you drying this is null business because that means it gets closer from zero to zero when you get back at it that'! reason the idea of at certainly in case you have a记 in and then you get a you get a this volt here that one right then you can predict theみたい to be very low if I' get up there and get at it that' And I have one over here, so what I'm looking at is the logarithm of one minus my prediction. And if my prediction is also close to zero, then the logarithm over here will be close to one, and that means the output will be close to zero again. And if my prediction is far off, then the logarithm over here gets more and more negative, and my loss function increases again. So it makes intuitive sense that this thing penalizes whenever our prediction is\",\n",
       " \"sense that this thing penalizes whenever our prediction is on the other side than what we wanted to predict. So if we have some target, and our prediction is kind of on the other side, then this loss function over here increases. So, and that's exactly what we want. We want to have a function that is larger the more wrong we are. So the more wrong our predictor is, the larger this number should be. So for linear regression, so there's another form of machine learning task where we don't want to learn a binary target, so we want to have a function that is larger. So for linear regression, so there's another form of machine learning task, where we don't want to learn a binary target, so there's another form of machine learning task, where we don't want to learn a binary target, so if we want to learn some kind of real valued number, then, so if we have like our target is some kind of number, that is just any kind of number, and our prediction is not supposed to be some probability, but we want to predict\",\n",
       " 'is not supposed to be some probability, but we want to predict exactly that value, then what we often take as a loss function is the square of the difference of those. So we take like the difference between, yeah. So we take like the difference between, yeah. Our prediction and the actual value, and see how far off we are and square that. So that means the further away we are, the more it gets penalized, and that would be the loss function for linear regression. We will not be doing much linear regression tasks in this lecture because most things we want to do are more or less binary. So we usually want to predict something that is some kind of classification task where we have like a binary output that we want to predict, but just so you have heard it, depending on what we want to predict, we might want to choose a different loss function. And for classification, this logistic loss over here is kind of the standard thing to do. And using this loss function has another advantage. And that is, this loss over',\n",
       " \"function has another advantage. And that is, this loss over here, which is also called the cross entropy loss, using this loss function over here makes sure that what we have here, the numbers we predict here, can actually be interpreted as probabilities. And that's the one of the advantages of this logistic loss function. So it makes sure that the numbers we generate are calibrated as proper probabilities. Again, I won't go into the statistical details for this, but it's not like this number is, so if you look at this formula, it turns out that it's something where being wrong is penalized, and being right is not penalized, So it looks like it does the right thing, but the formula doesn't just fall from the heavens, but it's a number that makes sure that in the end, we will predict numbers for which this property over here holds, so that we can actually interpret those numbers as probabilities later on. So, long story short, this is the loss function for a single training example. So we have one data point.\",\n",
       " \"for a single training example. So we have one data point. If we have a lot of data points, we look at this cost function. So we look at the cost function across our entire training data set. So we take all the training data that we have, sum up the loss function for each of them, and we divide by the average, over how many data points we have. So m is equal to the size of the train. And this gives us the so-called training loss, the loss over the entire training set. This number over here is a little bit arbitrary. It's just a constant factor. It makes sure that... if we kind of take twice the amount of data, then the training loss will still stay the same, but it's a number that later on we can also drop, and it doesn't affect anything. But the main point is we kind of want to take the average of the losses of all the training examples over here. So having defined all those things, the real question is how do we get these parameters w and b? So that's when we defined our hypothesis. At the beginning, we\",\n",
       " \"So that's when we defined our hypothesis. At the beginning, we said that the hypothesis kind of depends on those two parameters over here. And we said, okay, the hypothesis is sigmoid of w, the dot product between those two vectors plus b. So having those... what we want to get in the end is we want to know these parameters, because if we know them, then we know the hypothesis, and then we can make predictions. So we can make predictions about new data points. So as soon as we have them, those we are happy. And the way to get them is we want to find w and b such that our training loss gets minimal. So we want to minimize this function over here. So we want to minimize... the training loss, the loss of all the training data, and we want to choose those parameters over here. So we want to get the training data such that this loss over here gets minimal. And... when we do logistic regression, there's several ways how to calculate those values. So there's several ways how one could decide on those. For linear\",\n",
       " \"there's several ways how one could decide on those. For linear regression, there's even analytical ways how to just calculate them, given the training data that we have. In our case, we want to do it in a way that's more logical. So we want to do it in a way that's more logical. So we want to do it in a way that's more logical. We want to use some technique that will always work even for something that is not logistic regression and that will later keep working when we do larger neural networks, and that is gradient descent. So if we think about this function here, j, the loss function is a function that depends on the parameters we put in here. So if we change those parameters, If we change W and B, then we change our hypothesis. And if we change the hypothesis, we change the training loss. So the training loss is mainly a function that depends on the parameters W and B. And if we want to minimize it, we look at the point where this function gets minimal. And if we think about, for example, if this would be\",\n",
       " \"minimal. And if we think about, for example, if this would be W and this would be B, so in just two dimensions, then this would be our training loss. And what we kind of look for is we look at the surface of our training loss. And if we start with some values for W and B, we want to say, OK, let's see if there is a direction in which the training loss decreases. And then we want to make a step into the direction. In which the training loss decreases and see, OK, we get new values for W and B. And then we want to look again in which direction does the training loss decrease now. And then we do another small step into that direction until we find a point where the training loss does not decrease any further. And this technique will keep working. Even for more complicated hypotheses. So in this case, our hypothesis is pretty simple. But the gradient descent approach where we say, OK, always do a very small step into the direction in which the training loss decreases will hold for many, many other hypotheses\",\n",
       " \"loss decreases will hold for many, many other hypotheses later on. So what is the direction in which the... The hypothesis, the training loss decreases the most. The direction in which something decreases the most is the gradient with respect to the parameters. So what we want... Gradient descent means we will repeatedly do an update step where we take our parameters and subtract from those parameters. The gradient of our training loss at the current point in the direction of the parameters. And we multiply this with a learning rate. The learning rate is some small number so that we don't overshoot our target. So if we choose the learning rate too large, then we will just... For example, in this point, we might make a step that is... Too large into this direction. And then we get off at a point where we are worse than we were before. So kind of the learning rate is something that makes the algorithm more stable. More on this again later. Let's look at this thing first. So what is the gradient? The gradient\",\n",
       " \"look at this thing first. So what is the gradient? The gradient is the generalization of the derivative. So if you had... If you remember your analysis classes from back in the day, then probably you still remember the gradient in some way. So if you have the derivative of some function, then... So if you have f of x is equal to x to the square, then you might remember that the derivative of it will be to x. And this works all nicely as long as you have only one input variable. If you have multiple input variables, and in our case we have potentially a few thousand input variables, you need to generalize this derivative. And what we will do is we take the partial derivative into the direction of each of those input variables. And for each of the input variables, we get one entry in the gradient. That gives us how much the function changes in that input direction. To make this more concrete, I'll take an example. So I have a function. That has two inputs and one output. And the function itself will be x1\",\n",
       " \"two inputs and one output. And the function itself will be x1 times x2 squared. So the gradient will be... I first take the derivative in the direction of x1. If I take the derivative in the direction of x1, this is a constant term. So what I get is this part vanishes. So it will be x2 squared. If I take the derivative... The derivative in the direction of x2. This is a constant term in this case. So the derivative will be 2x2 times this term over here. So it will be 2x1x2. So the derivative is kind of this vector over here that in each dimension tells us how much the function changes if we make a small step in the corresponding input dimension. So, for example, if I'm at the point 3, 2, it tells me if I do a small step in the first dimension... So if I, for example, look at f3.12, then the output will change roughly by 0.4. That's kind of what the derivative tells me. So if I... make a step in size of 0.1 into this direction of the first dimension, then my function will increase by 0.1 times 4, roughly. And\",\n",
       " \"then my function will increase by 0.1 times 4, roughly. And the same way if I look at f3.2.1, then I know that my function will change roughly by 1. So that's kind of what the derivative tells us. So putting all this together, so for each dimension, the gradient tells us the slope in that direction. So we could also say, okay, I have like a multidimensional function. So it looks something could be several directions. So I'm very bad at... drawing something multidimensional. And the gradient kind of tells us if I take like a cutout of this multidimensional function in one direction, then it tells us the slope on this plane that we are focusing on at the moment. So for each dimension, it tells us how much the function changes if we do a little step into that direction. The gradient in total is the direction in which the function increases the most. So if I'm at this point, then this is a vector in the direction in which the function increases the most. So if I want to increase it, so if my point is 3, 2, then\",\n",
       " \"most. So if I want to increase it, so if my point is 3, 2, then I want to make a step into the direction. So I'm going to make a step into the direction 4, 12. So it's probably a small step, so times 0.01 to increase the function value. So if... that it increases the most is kind of the reason why when back here, we have this minus sign over here. So this is the direction in which the function, our loss function increases the most. So we do a small step into the opposite direction so that we have like, this is the direction in which it increases the most and minus the gradient is conversely the direction in which it decreases the most. And as we want to decrease the loss function at the end, we do a small step in the opposite direction of the gradient. So this is kind of, that's the motivation why we do, at each iteration, we do a small step into the opposite direction of the gradient because that is the direction in which the function decreases the most. Another example, so if we... the entire gradient is\",\n",
       " \"the most. Another example, so if we... the entire gradient is the gradient into each input dimension. So we look at each of the inputs of our function and for each input here, we get an entry in the gradient. We can also take the gradient just for certain inputs. So we can say, okay, I have like a function with a lot of parameters and I only take the gradient for a few of them. And for each of the directions that I take over here, I get a parameter over here that will come in handy later that we can take the gradient for just the subset of the parameters. And this is kind of a selection of the entire gradient. So we just select a few parameters, a few parts of those, kind of like in Python that we take slices of lists. So let's make the example a little more concrete. So let's assume we have like this loss function over here. So which would be squared loss, like in linear regression. So we take, have some, we take the parameter and the parameter minus two squared will be the loss at the end. So if we start,\",\n",
       " \"minus two squared will be the loss at the end. So if we start, so what is the partial derivative? So we, in this case, we only have one dimension. So like we only have to look at this derivative over here. So the derivative of the whole thing will be two times W minus two. So it's like inner derivative times outer derivative. The inner is just one. So it's, we are left with this part of the derivative. And let's start at point W equals zero. So let's, if we start over here, the function value that we have will be four. So zero minus two squared is four. And the derivative is minus four. So if we put in zero over here, we have two times minus four. So minus two will be minus four. And minus four means the slope of the function of our loss function over here is minus four. So the slope over here of the tangent at this point is minus four. The derivatives points in this direction. Minus four, it points into this direction. It tells us to, if we want to increase the loss function, we have to go this way. So what\",\n",
       " \"to increase the loss function, we have to go this way. So what we will do is we go the other way around and say, we could make it this way. So we go this way. We make a small step. So learning rate, small step, into the other direction, going this way. And this way we will turn out, get a new point over here, get a new slope over here, make a new update. And this way slowly get closer to the point where our derivative gets zero. And we have like the smallest value for our loss function. So we have a little bit of a loss function over here. So in our case, the full update step that we have is we do the same thing for all the parameters that we have. So we have like, in our case, we have like two variables. One is a vector, the other is just a single value. And what we basically do is for each of the parameters, we make a small step into the direction of the, into the opposite direction of the derivative. So we have two variables. One is a derivative with respect to those parameters. So that's where the\",\n",
       " \"with respect to those parameters. So that's where the notation comes in handy that we can just select a few, a subset of the parameters over here. If we get more parameters, we will kind of do the same thing for other parameters. So it will be always the same thing that we do for each of the parameters. We will always keep doing this, that we do look at the derivative in the direction, that we do look at the derivative in the direction, that we do look at the derivative in the direction, of those parameters and do a small step into the opposite direction. So one thing we haven't talked about a lot yet, this learning rate eta over here, the learning rate determines how stable the convergence of this algorithm is. So if we, for example, take a very large learning rate, so if this number is very high, we might make a long, a big step into this direction and might end up at a point which, where we are further away from the optimum over here than we were before. So having a large learning rate means we might\",\n",
       " \"we were before. So having a large learning rate means we might make, we will do larger steps and we might reach the optimum faster but we might also have points where we run away from the optimum and making everything less stable. So that's the thing. If we use a very small learning rate, convergence will be more stable, so we usually not overshoot the optimum, but it might make everything slower, so we will need more iterations. And there is no golden bullet for this number over here. So whenever you train some kind of machine learning algorithm, the learning rate will decrease, but the learning rate will usually be something that you need to calibrate for your use case. So it's usually something that you start with 0.01 or 0.001, some number like this. And then you will see, okay, it doesn't converge at all, so you need to make this number smaller or that you realize, okay, it's going too small, so you start to increase the number over here. And you'll have to do a little bit of fine tuning and calibration\",\n",
       " \"you'll have to do a little bit of fine tuning and calibration to get a number here that's, that gives you a good training progress without your algorithm getting unstable. All in all, I would say it's better to have a learning rate which is slightly too small, so you shouldn't make it incredibly small, so because then it will take ages for your training algorithm to converge. But it's usually better to be a little bit on the safe side, and, you know, use a smaller number over here, so that you don't waste a lot of time waiting, and just to see that at the end, everything works out, but at the very end, stuff starts to diverge, so it's better to pay with a little bit more waiting time and having a smaller learning rate over here, so that you have a little bit more stability in training. So now, now that we have those parts, so we have kind of the basic setup for the algorithm, we need to determine this formula over here, so this gradient over here, we know that it's defined as being the partial derivatives in\",\n",
       " \"we know that it's defined as being the partial derivatives in each of the directions that we have as inputs, but we now need to determine how we can compute this derivative over here, so we need to, in this case, was easy, we kind of have the analytical formula for the derivative, and we now need to determine how we can compute this derivative over here, and we now need to determine how we can compute this derivative over here, and can say, okay, this is depending on where we are at the moment, we can determine which, what the derivative is at this point, and this way, determine the direction that we want to go. But in general, this might be a pretty complicated function over here, so in our case, in the logistic regression case, we already have that, we take this cross entropy loss, so we have, like for one single training example, we have y times logarithm of, so, and here we have the sigma of, so the sigmoid function of w transpose x plus b, and so this would be like what we predict, and then again, plus\",\n",
       " 'and so this would be like what we predict, and then again, plus one minus y times the logarithm of one minus, plus the sigmoid of w, w transpose x plus b, and so on, so. And this, this is just for logistic regression, where this function is still a very simple one, so, putting all this together, for this thing, we can still calculate the derivative by hand, and get kind of a good, a nice formula for this, but if we start making this number in here, so if we start making the prediction over here, more complicated, we need some automatic way to do the differentiation over here. And the way to do this is, we define all the computations that we do here, in the form of a compute graph. What is the compute graph? A compute graph is a directed acyclic graph, where every node represents a mathematical graph, where every node represents a mathematical graph, where every node represents a mathematical operation. So, for example, a node could be something like addition, where we say, okay, we have two inputs, a and b,',\n",
       " \"like addition, where we say, okay, we have two inputs, a and b, one output, c, and, for each of the incoming parts, we know the derivative in this direction. So we know the derivative in the direction of a, which for addition is just one, and the derivative in the direction of c, of b, which is also just one. So the derivative in those directions, just as a reminder, it's kind of the rate of change in that direction, and one can kind of imagine it this way. So if I have like a plus b, and I add a little epsilon in the direction of a, then c will also be one epsilon larger, so which is kind of the reason why the derivative in the direction of a, will be one epsilon larger, so which is kind of the reason why the derivative in the direction of a, will be one epsilon larger, so which is kind of the reason why the derivative in the direction of a, will be one, and the same goes for derivative in the direction of b. And we can now do that with all the simple mathematical operations that we need. So we can do that\",\n",
       " \"simple mathematical operations that we need. So we can do that for multiplication. And say if I have like a node that is a multiplication, I can say, okay, I have an input a and an input b, and the derivative in the direction of a is b, and the derivative in the direction of b is a. And the derivative in the direction of b is a. And the derivative in the direction of b is a. So I have like my operation is a times b, and if I change a a little bit, then the output will change by a little b, and if I change b by some kind, a small number, then the output will change by a times this small number, so that's kind of the derivatives into those directions, and multiplication is kind of one of the main operations for which the, we will need the derivative, so, we will need the derivative, so, So it's kind of nice to repeat again that in the direction of A, the derivative is just B, and in the direction of B, the derivative is just A. So it's always the value on the other side that determines the derivative on the\",\n",
       " \"value on the other side that determines the derivative on the other side. All right. So we can now do that for all the mathematical building blocks that we might need. Subtraction, so if we do A minus B, we have minus one for the derivative of B. If we square things up, we can define the derivative of that function. So it's a single input function, so we have just one input, and it's like 2A will be the derivative for A squared. If we have some function like rectified linear, which is a function that is linear as long as the input is positive, and after that, it's just zero. So if we have a function like this, the derivative will be one if the input is bigger than zero, and then... and zero otherwise. So this thing here is notation for an indicated one, so it will be one as long as this condition is true, and otherwise it will be zero. So it's one if A is greater than zero, and otherwise the derivative over here will just be zero. We can take the... If we have, for example, a maximum function, so it's\",\n",
       " \"the... If we have, for example, a maximum function, so it's something that takes the maximum of A and B, we again can take the derivatives over here. So we have like in the direction of A, if A is bigger than B, then the derivative is one in the direction of A, so increasing A makes the maximum larger as long as A already is the maximum. If it's not the maximum, then the derivative here will be zero, and nothing changes if I change A. And the same goes for the input B. If I... If B is larger than A, then B is already the maximum, and if I change B, then also the maximum changes. But if B is smaller than A, then the derivative here will be zero because changing B doesn't affect the maximum. So... And we can do that for all kinds of small... of primitive mathematical operations, and from those, we can create complex functions. So I can... Like create a compute graph where I say... For example, I have a function that is A times B, and the result will be squared. And if I do that, I can say, okay, this will be\",\n",
       " \"be squared. And if I do that, I can say, okay, this will be this compute graph over here. I multiply B and A, get an intermediate results that I call C, then I will take C squared and get a result, which is D. So... And how do I calculate the derivative over here? And the way to do that is, so I want to calculate the derivative of the final output. So the... I want to calculate the derivative of my entire function of D into the direction of A. And the chain rule basically says, the derivative of D into the direction of A is equal to the derivative of D into the direction of C times the derivative of C into the direction of A. So it kind of... So as in... So to make it easy to remember, so if you could like just cancel those DCs out, then you would get... D D, right? D D divided by D A. So it kind of... It looks as if you can just cancel those out. So it's kind of helps to remember here. So what we basically do is we have a product over here. We have a product of two smaller derivatives. We have like the\",\n",
       " \"We have a product of two smaller derivatives. We have like the large derivative over here that we want to have, and we divide it into a product of two smaller derivatives, where we... We make a smaller step. So this is like a big step from here till here. And we divide it into two parts where we have the derivative of here till here. And then we do a step from here till here. So we divide it into two small steps. And for each of those smaller steps, we basically have the derivative written onto this arc over here. So we have like this arc where... D D... And then we have this arc where we have drug görüşs which are actually plain're. So let's not do that anymore. We have like a fluid. We have totallyилась basic府 in the nowhere tables almost, what's term that comes out of this is called seen method , is where you ask yourself what does that mean? Is it possible to understand it to an extent that can be pretty much difficult to understand them away from us. What's the式 aspect? What would be the physical你 Right\",\n",
       " \"from us. What's the式 aspect? What would be the physical你 Right with some... That hacer made with filling in, to a is just what we wrote over here. So it will be just b over here. So now we have kind of, the chain rule tells us that this will be the derivative from d into the direction of a. And c is basically just the forward computation from going forward over here. So it's basically we can replace c by a times b. So we get this formula over here. And if we kind of multiply this out, then we get that the whole derivative will be 2 times a times b squared, which again, if you would like, just go from the calculus way of deriving this derivative, you would take the inner derivative times the outer derivative and would derive a times b. So 2 times a b squared as the derivative in the direction of a for what we have here. So what we did over here kind of works. And the nice thing about this is the algorithm that we used over here, that will work for arbitrarily large compute graphs. So no matter how many nodes\",\n",
       " \"arbitrarily large compute graphs. So no matter how many nodes you have over here, you can kind of always do this calculation over here that you split up the entire gradient into all the small steps that you have in between. At each step, you know the derivative of this small step over here. And at the end, you need to calculate all those small derivatives and just multiply all of them. And this way you get the entire derivative all the way up. So kind of putting all this together, you can do this. So that gives us the back propagation algorithm. And the algorithm is that for each of the compute nodes, we define two values, the forward value and the backward value. The forward value is just what you would do if, yeah, you calculate the result of the compute graph. You put in some value here, some value here, and just do all the computations through the graph up to the last of, to the final result. So that's, those are the forward values. And the backward values will be the gradients coming from the final\",\n",
       " \"the backward values will be the gradients coming from the final value and going downwards to, towards the input values again. So you kind of start multiplying up those gradients from the intermediate nodes. So we kind of, we're going to do this. We kind of start calculating at the leaves to get the forward values. And then we start at the root node of the compute graph and calculate those gradients backwards till we reach the leaf nodes again. So let's do an example for this. If we have a logistic regression, then we say our loss function is this one over here. Then we say our loss function is this one over here. For a single example, so if we have like one single example, we say the loss, this will be the loss we have. Y hat is defined as the sigmoid of some value z, where this is the sigmoid function. And z is defined as some linear operation where we have like a weight for the first input variable, a weight for the second input variable, and some bias term b. So these three are the input parameters. So if\",\n",
       " \"bias term b. So these three are the input parameters. So if we have those building blocks, we need kind of, it's a nice thing to say, to define one node so we can, could say okay these are like several mathematical nodes for several operations, but as this is kind of used a lot, it makes sense to kind of define the derivative of this function, of the entire sigmoid function, and make it a little bit easier to do. And so we can use that as a single node in our compute graph and say okay, if we have some value z, that's the input of our sigmoid function, and the derivative of the sigmoid function is the sigmoid of z times one minus the sigmoid of z. So if you want, if you feel like it, you can try to value, to validate that by calculating it by hand, but for now I'll just give you this result. So if I have to take the derivative of this, kind of get, I get, like, this value for the derivative, and this value is just that number here, so it's kind of the sigmoid of z times one minus the sigmoid of z, which is\",\n",
       " \"of the sigmoid of z times one minus the sigmoid of z, which is kind of, it would be this number, so if I, if you remember that, one minus one, that's the number, and then if I, if I, if I, if I, if I, if I, if I, if I, if I, if you remember that y hat, so our prediction is just the sigmoid of z, so the derivative will be the prediction that we made, times one minus the prediction that we make. So that's the derivative term over here. If we look at our loss function, so, the loss function was this number over here, and again, we will create one, and again, we will create one, and again, we will create one, compute node for this function over here, so again, this is kind of used a lot, it makes sense to kind of, do those calculations instead of like, splitting it up into smaller nodes, and the derivative of the cross entropy loss, so the cross entropy loss, which is this number, it turns out to be this number over here, which is minus, what the number that we wanted to predict, divided by what we have\",\n",
       " \"the number that we wanted to predict, divided by what we have predicted, plus one minus the number that we, the actual class, divided by one minus our predicted class. So, which is the derivative into the direction of y hat. Why don't I write the derivative into the direction of y over here? Why don't I write the derivative into the direction of y over here? That is because we never take the derivative into this direction. Why don't we take the derivative into this direction? Because we don't care, we cannot change this value over here, that state that's just a data point. We can change what we predict over here, we can make a change in what we do predict, we can never change what the data was. So, we can do the change, that obviously if we like change the data points, but we cannot, our algorithm, our algorithm, takes those values over here, as its ground truth, and it only observes them, and uses those to kind of calculate the loss function over here. But we don't need to take the derivative into this\",\n",
       " \"over here. But we don't need to take the derivative into this direction, because we cannot change those values. So, we only can change the parameters that we have downstream this way. So, we don't need the derivative into this direction. We only need to go down this way, when calculating derivatives, because over here there's no parameter, that we can change. So, let's go further in our example. We have, let's assume that we have a data point, that where x is minus two and three. So, that is our input features x. Y is equal to one, and that is kind of the class that we would have liked to predict for this input example. And let's assume, the weights that we currently have, are two and one. And there should be some value for b as well, because b is kind of also something that we need later on. So, I really have to work on the formatting of those images here. I'll make this full screen. No. So, this is our compute graph. We multiply w one with x one, multiply w two with x two, add those values, then add the\",\n",
       " \"one, multiply w two with x two, add those values, then add the parameter b, the result will be put into the sigmoid function, and the result of that will be compared with our, with the target class for our loss function. So, in this case, we only have like one data point. In general, we would have again, a sum of those loss functions. So, we would sum up a lot of loss functions for a lot of data points. But for now, we just skip that part. So, it would just mean one more addition up here. So, this is the compute graph that we have. And, we can put in the derivatives at each of the branch, into each of those directions through the graph. So, let's put in values over here. So, if we have those input values over here, and b should be, is 0.5 over here. So, if we put in w one as two, x one as minus two, and again, w two is one, x two is three, b is 0.5, and the target class that we want to predict is one. So, these are kind of the given values that we have at this moment, that we want to calculate the gradient\",\n",
       " \"we have at this moment, that we want to calculate the gradient into this direction, this direction, and this direction. So, these are the values that we want to change at some point, at the end. So, we can say that we have now, we have a gradient here, and we want to change it at this point. So, we want to adjust them, so we need the gradient into those directions. What do we do? We start with the forward step. So, we multiply two by minus two, and get minus four. One by three is three. Minus four plus three is minus one. Minus one plus 0.5 is minus 0.5. And the sigmoid of this turns out to be 0.37. So, we have 378. So, at this point, we'll stop having round numbers. But, yeah, that's just what, if we have a number that is slightly smaller than zero, we also will get a probability that is slightly smaller than 0.5. If you remember the sigmoid function. So, if we have, like zero was here, and this would be 0.5. So, if we go slightly this direction, we will have a probability that will be slightly below 50%.\",\n",
       " 'we will have a probability that will be slightly below 50%. So, this is kind of the probability that we predicted. And our loss function will now be the cross entropy between this and this one. So, again, this will not be a round number, but it will be something that is quite a bit larger than zero, because we are kind of off from this. So, we predicted something smaller than 50%, even though the actual class is one. So, this should be a sufficiently large number to reflect this. And the smaller we get over here, the larger this number should be. And what we need to do now is calculate the derivatives backward. And how do we do that? We kind of just fill in those formulas over here. So, we go back through each of those arcs over here. So, we take, we know that for this formula, we need the values of y and y hat. So, we have all them. We computed them in the forward step. So, we kind of fill in those numbers over here and get this value over here as the derivative of the loss function into the direction of y',\n",
       " 'as the derivative of the loss function into the direction of y hat. So, this is the derivative into the direction of our loss function, of our prediction. And that basically says us, tells us that if we decrease the prediction, our loss will increase. So, makes sense. sense if we make our prediction even smaller then our loss will be even larger so it also tells us we should increase the value that we predicted to get a smaller loss at the end so if we could directly control the prediction it would tell us please decrease the predicted value to decrease the loss that we had at the end makes sense so far next step we calculate the derivative into this into this direction so to get the derivative of our predicted value into the direction of the value that we put into the sigmoid function which we call z over here and this will be a so we we put in 0.378 into this formula over here so we can get it get get the loss function over here and this tells us that if we want to include we should increase that in order',\n",
       " \"us that if we want to include we should increase that in order to increase y and which again makes sense and tells us kind of also the magnitude of how much we would should increase that to increase the loss function over here so we can get the loss function over here into this box over here also this form way and then if we bottom line increase the derivative over here we is jumper over here and if we overline this a small factor each of those actions we smoked over these letter was the Dirivative number in the S Flotas and this was essentially the Y and I gave it the wissen that Y is a sign because we took out the difference in theине was the difference in the two Solid and nT constant which is Yt raised by minus one which is tenth and one plus nT которая also though og that that was and actually if you like we can write just that as several weights but by a of illegal eighty nt or even ten cook at y nuclearanda which is a number of faces is like a two still nT and that's events that over here for this is\",\n",
       " \"a two still nT and that's events that over here for this is twelfth and that is also positive nonначalization of this is n number five percent for and to come back this will give you a solid reflux expression and And for this one, it's 3. And for the b, we already got the derivative into this direction. And now comes the last step that we need to do. And that formatting here is incredibly off. What we need to do now is, if we want to do the derivative into the direction of w1, we multiply each of those partial derivatives on the entire path from the root node to w1. So it will be... This times this times this times this times this. And the same way into the direction of w2 and in the direction of b. So we get the derivative of... There's no way to get this right at this moment. But if I have the derivative into the direction of w, I have this formula over here, which tells us... I should decrease w1 to decrease the loss function. And I should increase w2 to decrease the loss function. And in the same way, I\",\n",
       " 'w2 to decrease the loss function. And in the same way, I should increase the parameter b in order to get a better loss function. And if we think about this, we want to have... We want to have a smaller prediction over here. And... So we wanted to have... In order to get a better prediction over here, we want to have a larger value over here. So increasing b would make this value larger. So it would increase this value over here. So it would increase everything up the chain up here. So increasing b would increase this value over here. Increasing w would again... This is a positive value over here. So everything should increase this path. And decreasing w1 would again increase everything up the chain over here. So it kind of makes sense that what the derivative tells us... The gradient tells us is some way to increase the entire value y hat over here, which should decrease the loss function. So and the derivative kind of is something that tells us exactly in which direction we should change each of the',\n",
       " \"us exactly in which direction we should change each of the parameters in order to get close... To get a better loss function at the end. And so it looks... It kind of always... It looks scary, the entire calculations. But it's nice that each step consists of a very simple calculation. So each step along the compute graph... Is kind of plugging it in something into a formula that you know. And then just multiplying up everything at the end... Along the entire chain of calculations that we have here. Turns out things will get a lot complicater later on when we do a lot of matrix multiplications. Because it kind of... You need to make sure that you remember which dimension you have to multiply with which to get the right result at the end. But... It's... It's... It's... You always need to remember that the... What you are doing under the hood... Is just what we did here. So... One step after the other in a larger compute graph to multiply up the partial derivatives. One thing that one can do quite often is...\",\n",
       " \"derivatives. One thing that one can do quite often is... Combining those two loss... Those two derivatives. Because the derivative of the loss func... The cross entropy loss... And the sigmoid function... They kind of cancel out nicely. So... The derivative of... The... Loss function was this one. And the derivative of the sigmoid was this one. And if you multiply those... You get... This... Times this... And... As you can kind of see that you have like this thing over here and this thing. Those match and so you can kind of... Uh... Like multiply everything... Everything here with... This number over here and... In total get something that is simpler than... All the parts over here. So if... What one kind of often does is kind of combining... The sigmoid function and this loss function into like one single node... To make the calculations of the derivative a little bit easier because... If... If... If one just combines them into one node it gets... You get an easier derivative. It's not strictly necessary\",\n",
       " \"You get an easier derivative. It's not strictly necessary but it's kind of my... Sometimes makes calculations a little easier. Because things... If you take this one you can kind of multiply out everything and... It turns out that... Putting everything together... Just yields like y hat minus y so if... It kind of tells you... If my prediction was... Too large... If my prediction was too small... Then I need to increase the value and if it was too large I need to decrease it. So and it's just like linear into the... In the direction of... What... Of my prediction. So and because we kind of all... Very very often have like cross entropy and sigmoid as... As like some things that we need to... To use together. When we want to do neural networks... We need to vectorize things and... That's... That's why we... It's useful to use kind of the... Derivatives of vectorized operations. So if I want to take the gradient... Into the right direction of w... Of this dot product between w and x... It's just the vector x.\",\n",
       " \"Of this dot product between w and x... It's just the vector x. So it's kind of the same way if I have like a single value... W times x... Then the derivative... The gradient of... The gradient of... This function... Into the direction of... W would be... Just x. So and it's kind of... If we vectorize things... It's the... It's... It kind of stays the same. And... When doing any kind of calculations... Any kind of like... Like gradient computations... We always want to... To... To... To... Try to... To... To... Put... Put everything into a vectorized form again. So... Some... Something like this. And... If we have like more dimensions... Then it's kind of... We also still want... Want to... To keep... Keep... Everything in the... In the... In the vector form. Do you have questions so far? So probably... That... That... That was... Was a lot to take in. So... The... The first exercises that go into this direction... Will be a little bit tough for you. Because it's kind of... You need to go through those...\",\n",
       " \"you. Because it's kind of... You need to go through those... Those kind of... It's... The... My... My hint for you is... Try to make... Try to... Put... Do everything in... In the little... In little steps. So it's like... Kind of like we did over... Like we did over here. As long as you do very, very small steps... Everything is kind of simple. Because like... If you have like... Multiply two things... The derivative into one direction... Is kind of the... Value on the opposite side. And like... Additions... The... Derivative is one. So... Kind of break... If... If you do something... Try to... To... Calculate derivatives for some small neural network... Break things up in this way. Draw the compute graph... Try to calculate... Okay... Which is multiplied by which... What is the... The entire... Entire compute graph that I deal with over here... So that you kind of... Get comfortable with the... With what... What's happening over here. Once this clicks... You start to realize that what we do here is\",\n",
       " \"this clicks... You start to realize that what we do here is actually pretty simple. Because it's just those... The... Basically what I... I told you... The derivative always tells you... Should I increase or decrease the value that I have at the moment over here? So it kind of... This... This... This... This... This... This... This... This... This... This... This... This... This, this number here tells me... This... This... This... This... If I want to increase the loss function I should decrease the value that I predicted over here... So... And as... So... Obviously I want to go into the opposite direction to decrease the loss function. So that's what this number over here tells me. And... For going this way... This way up here... The sigmoid kind of tells me if I want to increase... I... I... I... I... I... I... I... I... I... I... I... I... increase the prediction that I made, I should increase whatever this number z that I put into the sigmoid function. And so if I want to decrease the prediction, I\",\n",
       " \"function. And so if I want to decrease the prediction, I multiply this by this number and thereby get kind of that if I want to, if I want to increase the entire loss function, what should I do with my value z? I should put this one multiplied by this one. So I should decrease the value z over here so that my loss function over here changes again. And that goes for the sum over here. It should also be, I multiply those things. So it should also be increased. And the product over here should also be decreased if I want to increase the loss function and so on. So while multiplying up, I always multiply the sum over here. So I should know that at this point, I want to increase or decrease the value. And I also know by how much. So the direction is kind of just the sign over here. So it's kind of the easiest thing to argue about, but it also tells me how much compared to all the other values. So how much should I increase or decrease a certain value over at a certain node compared to all the other nodes that I\",\n",
       " \"over at a certain node compared to all the other nodes that I have in order to increase the loss function? And at the very end, I just flip the sign because I want to actually decrease the loss function. So that was a lot to take in. And I hope to be so. At the beginning, we will start trying to build neural networks completely from scratch using those things that we had here. So we will go through all those parts, building up the gradients of the single layers that we have to get kind of built a small, small, new one. So that's pretty much it. And I'll leave that to you for the rest. Thank you. It's a pleasure. Goodbye. Thank you. Goodbye. neural networks completely from scratch, so that you can build this intuition what those gradients do and how those, what happens when we train a machine learning system. And later on we will start to push out this work to the frameworks that we want to use and where the framework does basically, manages this compute graph and does those calculations for us. But like the\",\n",
       " \"compute graph and does those calculations for us. But like the first exercises we will try to build a complete neural network completely from scratch so that we kind of see what happens under the hood and what the framework later on does for us when we do kind of auto differentiation using those. And if there's no more questions, then thank you and see you on Friday.\"]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('chunks.json', 'r') as file:\n",
    "    chunks = json.load(file)\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = FAISS.from_texts(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "# You are Karan, a student at TH Bingen University. Act as Karan and reply all questions on his behalf. Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "# \"\"\".strip()\n",
    "\n",
    "\n",
    "# def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
    "#     return f\"\"\"\n",
    "#       <|system|>\n",
    "\n",
    "#       {system_prompt}\n",
    "\n",
    "#       <|user|>\n",
    "\n",
    "#       {prompt}\n",
    "\n",
    "#       <|assistant|>\n",
    "# \"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "You are Karan, a student at TH Bingen University. Act as Karan and reply all questions on his basis. Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def generate_prompt(prompt: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT) -> str:\n",
    "    return f\"\"\"\n",
    "[INST] <>\n",
    "{system_prompt}\n",
    "<>\n",
    "\n",
    "{prompt} [/INST]\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = generate_prompt(\n",
    "    \"\"\"\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOllama(model=\"llama2:latest\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=db2.as_retriever(search_kwargs={\"k\": 2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:81\n",
      " * Running on http://172.20.10.4:81\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [12/Mar/2024 06:31:05] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Mar/2024 06:31:21] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, render_template_string\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "html_template = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Chatbot</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #f0f0f0;\n",
    "        }\n",
    "        .chat-container {\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #ffffff;\n",
    "            border-radius: 10px 10px 0px 0px;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .chat-form{\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #ffffff;\n",
    "            border-radius: 0px 0px 10px 10px;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .chat-message {\n",
    "            background-color: #f9f9f9;\n",
    "            border-radius: 10px;\n",
    "            padding: 10px;\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        .user-message {\n",
    "            text-align: right;\n",
    "        }\n",
    "        input[type=\"text\"] {\n",
    "            width: calc(100% - 100px); /* Adjust width of input */\n",
    "            padding: 8px;\n",
    "            border-radius: 5px;\n",
    "            border: 1px solid #ccc;\n",
    "            margin-right: 10px;\n",
    "        }\n",
    "        #input_submit{\n",
    "            background-color: #555555;\n",
    "            border: none;\n",
    "            color: white;\n",
    "            padding: 8px 10px;\n",
    "            text-align: center;\n",
    "            text-decoration: none;\n",
    "            display: inline-block;\n",
    "            font-size: 16px;\n",
    "            margin: 4px 2px;\n",
    "            cursor: pointer;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"chat-container\" id=\"chat-container\">\n",
    "    <h3>Welcome to the Artificial Intelligence QnA service.  You may ask me anything 🙃</h3>\n",
    "        {% for message in chat_history %}\n",
    "            <div class=\"chat-message {% if message['sender'] == 'user' %}user-message{% endif %}\">\n",
    "                {{ message['content'] }}\n",
    "            </div>\n",
    "        {% endfor %}\n",
    "    </div>\n",
    "    <div class=\"chat-form\">\n",
    "    <form action=\"/\" method=\"POST\" id=\"chat-form\">\n",
    "        <input type=\"text\" name=\"input_text\" id=\"input_text\" placeholder=\"Message Chatbot...\">\n",
    "        <input type=\"submit\" id=\"input_submit\" value=\"Send\">\n",
    "    </form>\n",
    "    </div>\n",
    "    <script>\n",
    "        document.getElementById('chat-form').addEventListener('submit', function(event) {\n",
    "            event.preventDefault(); // Prevent default form submission\n",
    "            var inputText = document.getElementById('input_text').value;\n",
    "            if (inputText.trim() !== '') {\n",
    "                var inputBox = document.getElementById('input_text');\n",
    "                console.log(\"inputBox\", inputBox);\n",
    "                var chatContainer = document.getElementById('chat-container');\n",
    "                var userMessage = document.createElement('div');\n",
    "                userMessage.className = 'chat-message user-message';\n",
    "                userMessage.textContent = inputText;\n",
    "                chatContainer.appendChild(userMessage);\n",
    "                document.getElementById('chat-form').submit(); // Submit form\n",
    "            }\n",
    "        });\n",
    "    </script>\n",
    "    \n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    global chat_history\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.form['input_text']\n",
    "        inputAfterSimilaritySearch = db2.similarity_search(query=input_text, k=2)\n",
    "        output_text = qa_chain({\"input_documents\": inputAfterSimilaritySearch[0].page_content, \"query\": input_text})\n",
    "        chat_history.append({'sender': 'user', 'content': input_text})\n",
    "\n",
    "        # Add logic here to generate response based on input_text\n",
    "        # For demonstration, simply echo the input_text as response\n",
    "        response_text = output_text['result']\n",
    "        chat_history.append({'sender': 'bot', 'content': response_text})\n",
    "\n",
    "    return render_template_string(html_template, chat_history=chat_history)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:81\n",
      " * Running on http://172.20.10.4:81\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [12/Mar/2024 06:38:28] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Mar/2024 06:38:36] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [12/Mar/2024 06:38:44] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# response_text = ''\n",
    "\n",
    "# @app.route('/', methods=['GET', 'POST'])\n",
    "# def index():\n",
    "#     global response_text\n",
    "\n",
    "#     if request.method == 'POST':\n",
    "#         input_text = request.form['input_text']\n",
    "#         inputAfterSimilaritySearch = db2.similarity_search(query=input_text, k=2)\n",
    "#         output_text = qa_chain({\"input_documents\": inputAfterSimilaritySearch[0].page_content, \"query\": input_text})\n",
    "#         response_data = {\n",
    "#             'result': output_text['result'],\n",
    "#             'source': inputAfterSimilaritySearch[0].page_content\n",
    "#         }\n",
    "#         return jsonify(response_data)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host=\"0.0.0.0\", port=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template_string\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "html_template = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang=\"en\">\n",
    "<head>\n",
    "    <meta charset=\"UTF-8\">\n",
    "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "    <title>Chatbot</title>\n",
    "    <style>\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 0;\n",
    "            padding: 0;\n",
    "            background-color: #f0f0f0;\n",
    "        }\n",
    "        .chat-container {\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #ffffff;\n",
    "            border-radius: 10px 10px 0px 0px;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .chat-form{\n",
    "            max-width: 800px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "            background-color: #ffffff;\n",
    "            border-radius: 0px 0px 10px 10px;\n",
    "            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);\n",
    "        }\n",
    "        .chat-message {\n",
    "            background-color: #f9f9f9;\n",
    "            border-radius: 10px;\n",
    "            padding: 10px;\n",
    "            margin: 10px 0;\n",
    "        }\n",
    "        .user-message {\n",
    "            text-align: right;\n",
    "        }\n",
    "        input[type=\"text\"] {\n",
    "            width: calc(100% - 100px); /* Adjust width of input */\n",
    "            padding: 8px;\n",
    "            border-radius: 5px;\n",
    "            border: 1px solid #ccc;\n",
    "            margin-right: 10px;\n",
    "        }\n",
    "        #input_submit{\n",
    "            background-color: #555555;\n",
    "            border: none;\n",
    "            color: white;\n",
    "            padding: 8px 10px;\n",
    "            text-align: center;\n",
    "            text-decoration: none;\n",
    "            display: inline-block;\n",
    "            font-size: 16px;\n",
    "            margin: 4px 2px;\n",
    "            cursor: pointer;\n",
    "            border-radius: 5px;\n",
    "        }\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"chat-container\" id=\"chat-container\">\n",
    "    <h3>Welcome to the Artificial Intelligence QnA service.  You may ask me anything 🙃</h3>\n",
    "        {% for message in chat_history %}\n",
    "            <div class=\"chat-message {% if message['sender'] == 'user' %}user-message{% endif %}\">\n",
    "                {{ message['content'] }}\n",
    "            </div>\n",
    "        {% endfor %}\n",
    "    </div>\n",
    "    <div class=\"chat-form\">\n",
    "    <form action=\"/\" method=\"POST\" id=\"chat-form\">\n",
    "        <input type=\"text\" name=\"input_text\" id=\"input_text\" placeholder=\"Message Chatbot...\">\n",
    "        <input type=\"submit\" id=\"input_submit\" value=\"Send\">\n",
    "    </form>\n",
    "    </div>\n",
    "    <script>\n",
    "        document.getElementById('chat-form').addEventListener('submit', function(event) {\n",
    "            event.preventDefault(); // Prevent default form submission\n",
    "            var inputText = document.getElementById('input_text').value;\n",
    "            if (inputText.trim() !== '') {\n",
    "                var inputBox = document.getElementById('input_text');\n",
    "                console.log(\"inputBox\", inputBox);\n",
    "                var chatContainer = document.getElementById('chat-container');\n",
    "                var userMessage = document.createElement('div');\n",
    "                userMessage.className = 'chat-message user-message';\n",
    "                userMessage.textContent = inputText;\n",
    "                chatContainer.appendChild(userMessage);\n",
    "                document.getElementById('chat-form').submit(); // Submit form\n",
    "            }\n",
    "        });\n",
    "    </script>\n",
    "    \n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def index():\n",
    "    global chat_history\n",
    "\n",
    "    if request.method == 'POST':\n",
    "        input_text = request.form['input_text']\n",
    "        inputAfterSimilaritySearch = db2.similarity_search(query=input_text, k=2)\n",
    "        output_text = qa_chain({\"input_documents\": inputAfterSimilaritySearch[0].page_content, \"query\": input_text})\n",
    "        chat_history.append({'sender': 'user', 'content': input_text})\n",
    "\n",
    "        # Add logic here to generate response based on input_text\n",
    "        # For demonstration, simply echo the input_text as response\n",
    "        response_text = output_text['result']\n",
    "        chat_history.append({'sender': 'bot', 'content': response_text})\n",
    "\n",
    "    return render_template_string(html_template, chat_history=chat_history)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host=\"0.0.0.0\", port=81)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
