{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85de6f1-6670-4169-905f-94c1e8e2224b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 11 22:54:01 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000               Off | 00000000:17:00.0 Off |                  Off |\n",
      "| 30%   59C    P0              86W / 300W |      4MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000               Off | 00000000:73:00.0 Off |                  Off |\n",
      "| 32%   61C    P0              91W / 300W |      4MiB / 49140MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f26074c1-f441-4ad7-9551-e103f8452f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-ido7ukoc\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-ido7ukoc\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (0.58.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (1.26.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (2.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (0.6.0)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.11/site-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.3.101)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pydub==0.25.1 in /opt/conda/lib/python3.11/site-packages (0.25.1)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain==0.1.9\n",
      "  Downloading langchain-0.1.9-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (1.4.51)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (3.9.1)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.9)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.21 (from langchain==0.1.9)\n",
      "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting langchain-core<0.2,>=0.1.26 (from langchain==0.1.9)\n",
      "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain==0.1.9)\n",
      "  Downloading langsmith-0.1.23-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (1.26.3)\n",
      "Collecting pydantic<3,>=1 (from langchain==0.1.9)\n",
      "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.11/site-packages (from langchain==0.1.9) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.9) (1.3.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.9)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.9)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.9) (2.4)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.26->langchain==0.1.9) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.26->langchain==0.1.9) (23.2)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain==0.1.9)\n",
      "  Downloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain==0.1.9)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic<3,>=1->langchain==0.1.9)\n",
      "  Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1->langchain==0.1.9) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.9) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.9) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.9) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests<3,>=2->langchain==0.1.9) (2023.11.17)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.9) (3.0.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain==0.1.9) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.9)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.9-py3-none-any.whl (816 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.0/817.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.6/66.6 kB\u001b[0m \u001b[31m152.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.9.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: pydantic-core, orjson, mypy-extensions, marshmallow, annotated-types, typing-inspect, pydantic, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
      "Successfully installed annotated-types-0.6.0 dataclasses-json-0.6.4 langchain-0.1.9 langchain-community-0.0.27 langchain-core-0.1.30 langsmith-0.1.23 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.9.15 pydantic-2.6.3 pydantic-core-2.16.3 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install pydub==0.25.1\n",
    "!pip install langchain==0.1.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1804ef42-08fe-4cae-a9fe-7849ff37c349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "import whisper\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d3ebe0d-72e2-4fba-88e6-19b1ea2583d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc741f17-2a69-4220-9b17-7e4857113c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio exported for Kint.mp4 to /home/jovyan/Kint.mp3\n",
      "Audio exported for Kint2.mp4 to /home/jovyan/Kint2.mp3\n",
      "Audio exported for Kint3.mp4 to /home/jovyan/Kint3.mp3\n"
     ]
    }
   ],
   "source": [
    "folder_path = os.getcwd()\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Extract audio from the video\n",
    "        video = AudioSegment.from_file(video_path, format=\"mp4\")\n",
    "        \n",
    "        # Create a corresponding mp3 file name\n",
    "        audio_output_path = os.path.join(folder_path, f\"{os.path.splitext(file_name)[0]}.mp3\")\n",
    "\n",
    "        # Export audio to mp3\n",
    "        video.export(audio_output_path, format=\"mp3\")\n",
    "\n",
    "        print(f\"Audio exported for {file_name} to {audio_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6109acce-b19d-42cd-8041-31b02fdd2c6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "202ca59a-8f5c-445d-9400-fbcf494325c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OK, good morning, everybody. So last week, we stopped at the question, how do we calculate the gradients for more complex loss functions and classifiers? And we saw that the thing that we need is the backpropagation algorithm. So we want to make use of the chain rule of calculus to determine the gradient of some complex compute graph. So we take one compute graph where we know the gradient for each of the nodes, and we use the chain rule to multiply those individual gradients, and thereby getting the gradient for the more complex function. And if, for example, we use a the compute graph for logistic regression, where we say, OK, we have two inputs, so two parameters for each of the input dimensions, and one bias term, our compute graph is this dot product over here, adding the bias term, getting this linear unit over here, taking the sigma. OK. And then we can use the sigma function of all of this and doing, performing, calculating our loss function. And for each of those steps, we know the gradients for each of those. For the loss function and the sigmoid, they are slightly more complicated, but we can just look up those gradients for each function and thereby get the gradient over there. And after we've looked it up, we can just add it into the compute graph, and we are happy. And if we say, OK, we put in our current values, so we're assuming this is the data point that we are looking at, and our current values for the three free parameters are those, we can do the forward calculations, so calculating the stock product, going forward, getting the result of the linear unit, calculating the sigmoid, and then getting the loss that we get. If we did a prediction that was with 37% probability, we think that the result is a positive example. So we would classify it as a 0. And actually, it is a positive example. So we somehow were off. So it means there should be some loss over here. And if we used cross entropy formula, we get a loss of close to 1. And if we do the backward calculation, we go through all of those parts over here and add in the values that we computed going forward into the formulas for the gradients. So here we need the y and the y hat that we calculated over here. We can plug this in, get this value for the gradient over here. We can plug in y hat. And we can plug in the y hat in the formula over here. So we have 0.378 times 1 minus 0.378. Get the value over here for the gradient here. And we can basically do that for all the other steps. It's kind of easy because we have linear parts over here. So the gradients are always 1. And for the last step over here, with multiplication, it's, it's always the value on the other side of the multiplication. So you have a minus 2 over here and 3 over here. And now, using the chain rule, we can calculate, now that we know the individual gradients, we can just multiply up everything on the path down to each of those parameters that we are interested in. So we have three parameters. So we have three different paths that we can take through this entire graph. And if we multiply everything up, we get the value over here. So we have a minus 2 over here and 3 over here. And we get the gradient for each of our parameters. So, and nothing changes if we make our neural network bigger. So this logistic regression, which is a one-layer neural network, works like this. We get the gradients. In this case, we could also write down the formula, easily write down the formulas for each of the gradients, for each of those terms, because it's a small network. We could just write down the formulas. But as soon as it gets much, much bigger, the formulas get pretty unwieldy. And to help us there, using back propagation and the compute graph representation, it doesn't matter how large everything from the parameter up to the loss function is. We can just mechanically calculate, do the calculation, gradient calculations by going through the compute graph and get the resulting gradients. There are a few things we can do to make calculations easier. In this case, if we combine the sigmoid and the loss function into a single node, then the gradient gets a little simpler because a lot of things cancel out over there. So the gradient for the combined loss and gradient. And sigmoid, for combining cross entropy loss and the sigmoid is just y hat minus y. So this times this one over here will, in the end, just be y hat minus y. So that makes calculations easier, because in a lot of cases, we use those in conjunction. And the gradient of those in conjunction is just this simpler number. So when implementing all of this, the hardest part is basically getting the vectorization parts right. So in almost all cases, we just deal with it. So at some point, we have to do the gradients for activations functions or loss functions, which are slightly more complicated. But in almost all cases, the gradients are that simple. So the gradient of addition, multiplication, it's always just taking one of the numbers. We are multiplying up a lot of those gradients in the end. But we get away with basically just addition and multiplication in all of those cases. We just need to make sure to multiply and add the right entries everywhere. So if we do the gradient for the dot product, then what is the? If we do the gradient in the direction of w, it means we basically have this formula, w1 times x1 plus w2 times x2 plus and so forth. And if we take the gradient in the direction of w1, everything here drops. And this one goes away, too. And we are left with x1. So the gradient in the direction of w1 would be x1. Same goes for in the direction of w2. Everything else drops. We are left with x2 and so on. So the total gradient will just be a vector x1, x2, xn, which is just the entire vector x. So it turns out that the gradient is just x1. The gradient of the dot product is kind of exactly the way that the gradient works for, like, if I just have two scalars that I multiply with each other. And so if I have a times b, and I want to take the gradient in the direction of e, that would just be b. So a gradient in the direction of a would just be b. And for a dot product, it works exactly the same way. And somehow, this all works. It's just a matter of time. And so this also kind of carries over if we do matrix vector multiplications later. So if we later on multiply some matrix with some vector, then we get a lot of entries in here. For each of those entries, we just have dot products over here. And for each of those, again, we want to make sure that the entries are correct. So it's always kind of matching entries to where they belong. And we'll do more about this later when we get to doing proper neural networks. But always remember, the results for all the calculations that you need to do will always be something pretty simple, like in this case, it's kind of getting the gradient in the direction of w. It will be its x. And the complicated part is always just getting the shape of those things right and knowing which entry sits in which position of the vector or the matrix that you are dealing with. So that's what you have to keep in mind for all of those things. So that was backpropagation. And backpropagation is kind of the basic for everything that we do when training any kind of larger machine learning system. Yeah? When do we use the word content when ? There's no clear-cut rule for this. So as an activation file, so there are certain cases where, where, where, where, where, where, where, where, where, where, where you always use a sigmoid. So for example, if you have, so if, if, if, if, so if you think of a larger neural network where you have like multiple layers going through those, in between those, and we'll talk about this more in a minute, you might use any kind of activation function. And it's kind of an engineering fine tuning thing to determine which one works best. The final output. Here you are more constrained because it depends on your use case. So if you, for example, want to predict one class, so it's either zero or one, then you almost always want to use a sigmoid function there because that one gives you something that you can interpret as a probability of, okay, how likely is it that I'm in this class over here? So it's a number between zero and one, and you can, and this is kind of scaled in a way. Yeah. So it's a way that it works as if it was a probability in some way. So if you want to predict a binary class, you will always use a sigmoid. If you have multiple classes that you want from, from which you want to predict one, you will always use the softmax function. If you want to predict just any kind of number, so like the price of a house or whatever, you will always use like the identity function. So don't do anything for, for, for, with your output, just use the number that comes out of it. And yeah, that's basically it. So if for, for, for, for those, so it's basically just have those three cases for the outputs that you have, like you want to have one number, some bind, have a binary output, or have like a lot of discrete outputs of one, zero, one, two, three, four, five. Uh, so, and for each of those cases that your, your activation function is kind of determined because the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, the, there's like one activation function that fits to that output, in all the other cases, so for these intermediate layers, you can use any activation function you like. We will talk about, a little bit more about other activation functions that are used, that, that are commonly used in, in, in practice, but which one works best, there is no proper way to know that beforehand. So as like a little bit of experience for certain use cases that you know, in certain use cases it might be this way. And, so, that's probably the one. Yeah. The general advice is just use the ReLU activation function in between because it usually works well and it's fast to compute. So that's kind of the general advice. But yeah, otherwise, there's no way to know what works best. So logistic regression is a one-layer neural network. And here, we use the sigmoid as the last activation function because we have a binary output. And the logistic regression does a direct mapping from our input to one output using one linear layer. Yeah. So the next step is we want to add a neural network. And we want to add another layer here. And just do the same thing that we did in the layer that we did before. So if we say this is logistic regression over here, it takes some inputs, does some linear operation, applies the sigmoid, and gets the properly scaled output, which we interpret as a probability. And this layer over here, it basically doesn't really care where its inputs come from. So if those inputs were x1, x2, x3, we would call it a logistic regression. If those inputs were the outputs of another neural network layer, we would call it a neural network. So it's the, but this layer over here doesn't know anything about what happens over here. It just gets three inputs. So it's a logistic regression. So it's a logistic regression. And does a logistic regression to determine its output. If we build a neural network, we just add additional steps over here. And each of those does a small little logistic regression or some other linear transformation, almost linear transformation to modify its inputs and produce some more refined inputs. And this is the more refined output that this last layer over here can use to make a better prediction over here. So, and the terminology here is we talk about our input, which are the original features that we get from in our data. We have the output layer, which is the last layer that, which output, where we do observe the output, and where we actually have some proper interpretation. So we have the output layer, which is the last layer that we have to interpret for the output, where we know what this output should be. And everything else we call a hidden layer. And we can have a lot of those. If we put all of this into formula, then we say, OK, we have our inputs. And we have like a little dot product over here for this first neuron over here, where we say, OK, we do the dot product of some vector, W1, 1, and we have a bias term for this neuron over here. So this is the result of the linear operation that we calculate in this neuron over here. And we call this output Z1. And we apply some activation function over here, for example, the sigmoid, and get something that we call the activations of the first layer. So we get one number as an output over here. And this number would be A1 superscript 1. And we do the same thing for each of those neurons. So we have three neurons over here. So this one would be neuron 1, 1. This is neuron 1, 2. Neuron 1, 3. Neuron 2, 1. And because we will have a lot of layers and different neurons and the different indices within the neurons, we have to fight a little with sub and superscripts to get the mathematical notation somehow consistent. And probably I'll also have still some errors in the slides at some points where I mix up the indices. So I'll use this superscript in square brackets to determine the layer. So this is like layer 1. This is layer 1. This is layer 1. This one is in layer 2. And I use the subscript over here to determine the individual neuron within the layer. So I have like this is the output of the first neuron in the first layer, the second neuron in the first layer, the third neuron in the first layer. And the output layer has just one neuron. So I could make a subscript over here. But I'll just leave it out because I just have a single output over here. And we'll have to add more. And we'll have to add more indices later on when dealing with more dimensions and making things more complicated at some point. But for now, remember the square brackets indicates the layer. And the subscript indicates the neuron which we are using. So if we think about this hidden layer over here, what we are doing is we have a dot product over here. A dot product over here. A dot product over here. So we do three dot products producing three activations or producing three so-called logit values. So this one would be Z1, Z2, Z3 each of the first layer. And those get mapped using the sigmoid or some activation function into the activations. And those are the input for the next layer. And what we want to do is batch together all those operations to vectorize more of the things. So what we can do is we can batch together all those individual dot products over here into one matrix vector operation. So if we write those individual vectors W as rows of one matrix, we have one large matrix W1, which in this case will be a three by three matrix. So we have three different neurons in the layer. And each of those neurons has three different inputs. So this would be number of neurons. This is the number of inputs those neurons have. All of this gets turned into a matrix vector operation where this is kind of the matrix with those values. This is a vector with all the bias terms. And then as an output, we get a vector with all those Z values. So this would be the vector with that one, one, Z2, one, Z3, one. So nice thing about writing it like this is we kind of can get rid of the subscript index, because we only need to keep the. Number of the index that tells us for which layer this matrix is relevant, because we kind of already grouped together all the neurons into one large matrix with parameters. And the sigma function, again, in the way that NumPy does it, and we need to do it over here, is applied for each of the elements over here. So it's element-wise applied to each of the entries in the Z vector over here. If we put all this together, so if we put all the calculations from start to finish into one formula, we get that our predicted value is the sigmoid of vector W2 dot product with the sigmoid of matrix product of W1, and then the matrix product of W2. One-by-one output, right? We don't say anything, which you will find things of various<|fa|> kinds across the magnificence of the 0. So it's a little tough but what we know remember we observed that the starting occurred in the education in some way. We also discovered that, because you discord approach scream protect the data components across to the electronic vectors, you now have Georg Demann, wants to understand that symbolization in the -, because he's really time is 공appropriately not唱 of the first layer. Then the next linear operation gives us the logit of the second layer. And the sigmoid over here gives us the activations of the second layer. And because that was the last layer, the activations of the last layer is also the final output. So if we put all this, if we try to write down all this as a compute graph, basically we get this one over here. We have this matrix product over here, adding a bias term, mapping it through a sigmoid, multiplying it with a matrix, adding another bias term, and doing another sigmoid over here. And of course, if we would add the loss function over here, we also would get a node for the loss over here, which also gets a y as an input over here. So in some way, if we think, we, what we often think about is having this idea of a single neuron where we have one value as an output, which is kind of what we do with logistic regression. But when building neural networks, we basically always think in entire layers. We don't really care about the individual neurons of one layer because we don't really care about the individual neurons of one layer. We always batch them together. We usually think in terms of an entire layer for a neural network. And the layer is, by using this matrix vector operation, we kind of batch together all those individual operations for each of the neurons by having like one matrix operation over here and getting the activations for each of those neurons in here. And, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, we usually never, never really think in terms of individual neurons because we kind of always combine operations as much as possible. So, a tricky part, I told you this again and again, is getting dimensions right. So, let's think about a little bit about the dimensions that we are dealing with here. So, we have the size of the input vector. So, and we call this n, superscript 0, so this would be the dimension of the input vector. After the first layer, we are dealing with activations of size n superscript 1. So this would be the size of the activations after the first layer. And if we have those sizes over here, that means our matrix here in the first layer, so w1, would be a matrix n1 times n0, because that's the size of the input, and that's the size of the output of this operation here. If this is the size of the output of this vector matrix multiplication, we know we need bias terms for each of the outputs, so the bias vector will have dimension n1. And because that's... the size of the output, the output will have size n1 again. Somehow, again, to kind of illustrate how the matrix vector multiplication works, so if we have a matrix A and a matrix B and multiply them together, we multiply this element and this one, add this one and this one, this one and this one, and we multiply those together to get the result over here. So we keep doing that for each of the outputs, and the thing to remember is, if A is an L by m matrix, and B is an m by n matrix, then the m's in between have to be the same, and will cancel out and give us a result that is an L by n matrix. And if we have, like, if B turns out to be a vector, then the n will be a 1, so the result will also be a vector again, with dimension this way. And that's kind of the image that you need to keep in mind to remember what your inputs and outputs have to be, and so you can kind of remember this and get back to... And if you have, like, errors and things do not match, and NumPy throws weird errors for you, you can use broadcasting to do these calculations over here, not just for a single example, but we want to probably do all those operations for a lot of examples. So we don't want to just calculate the activations for one input example, but we want to do that for a lot of examples. And so... I'll just give you kind of a brief example over here with NumPy. So... If we... So if we have, like, a single example over here, a single input here, then our z values... Our z values will again be a vector of entries, so the same would be if I just remove this one, then... And things do not work because I do a matrix multiplication over here, so if I... In the basic formulation, we would do something like... Let's call this a small x. So small x equals np random.rand, and make this length 4. So let's leave this one out, and small z would be... w times x plus b. And... So... I'll just... I'll just... I'll just... Where do I go wrong? Over here? So... This one... So... And this one... And this one would also be just a regular vector, and I'll get the result that I expect over here. So I get... Like, I have, like, x is some vector... some vector, W is a matrix, B is another vector that has like the size of the output dimension and if I do the matrix multiplication W and X, I get something that has length three out of the input that had length four. I add the bias term with length three and get my logits and later on after that I would push those through a sigmoid function to get the activations. Now if I want to vectorize stuff, I'll need to make sure that I put in a lot of examples over here. So I'll just assume that I have like five different examples so each example has size four and I use five of those examples. So I don't deal with, with a vector X anymore, I have a matrix X where each of those columns is one of the input, of the input data I deal with. So and everything else should kind of stay the same. And if I do this, things do not work out as nice, work out anymore because Z turns out now to be again a matrix with, one output, so it's three by five. So I get, again I have three outputs, but I have one of those vectors for each of my data points. So I had five original data points as input and now I still have five data points as output and I have the results of this linear operation for each of my data points. To make sure that I now add the bias term individually to each of those data points, I must make sure that I tell NumPy which is the dimension over which to broadcast and the so-called batch dimension, which is where I put in the, over which I index my different examples, which in this case is the last dimension over here. And it kind of often is the last dimension. I'll have to do this, but I'll have to do this, I'll have to make sure that NumPy knows that it has to broadcast over this operation, over this batch dimension. So I'll put, when I define my bias term over here, I don't define a vector of length three, but I make it a matrix of length of size three by one, so that this operation here works out in the way that I expect it to do. And that's kind of the motivation over here to, why each of those is kind of written as a two dimensional or a NumPy object with two shapes, so that the broadcasting works over this batch dimension when I'm using, I'm calling, doing this addition over here. So, but the nice thing is, everything works even if I'm putting in a lot of input examples. And this way I can kind of batch together a lot of operations into like single NumPy operations and make them being computed pretty efficiently. So, these things over here, I call it the activations. And it's the output of like mapping each individual entry through the activation function. And there's probably one question, why do we actually need the activation function anyway? So what is the activation function good for? So the easiest way to find out is by trying to just leave it out. So what happens if we leave out the activation function? So if we have our formula for our two layer neural network, we can just leave it out. So we have like two layers, so and two operations, W2 and times W1 times X plus B1 plus B2. And in the original version, we would have had a sigmoid around here and a sigmoid around in front here. But now if we, or any kind of activation function, but if we leave it out, we can do some arithmetic to check, but if we leave it out, we can do some arithmetic to check, but if we leave it out, we can do some arithmetic to check, we can do some arithmetic to change this formula over here. So we could just say, okay, this thing is the same as W2 times this plus W2 times this one. So got this one wrong. So there should be a W2 in front of the B1 over here. So W2 times B1. And what we then can do is group those two together. We can say, okay, I'll just multiply the parameters that I had in here with the parameters I had here, get a new, in this case, this will be, this matrix W prime will be a vector because I have a single output over here. So we get like a vector with entries over here. And if I multiply this matrix with this one and at this vector over here, I get another vector B prime over here. And all together, this entire vector, this entire formula collapses to this simple linear operation over here. So having, and this kind of means having all the operation, all those parameters over here. So I have like a big matrix of parameters over here and to make lots and lots of calculations, but I could get the same result, the very same prediction over here using just a simple dot product down here. So the result that I calculate over here is the very same as if I just used much, much fewer parameters and just did a dot product down here. And that is the reason why we need the activation function to make sure that those parameters cannot just, cannot just be grouped together and do the very same thing. We actually want, just for the sake of it, we actually want, just for the sake of it, just for the sake of it, I have to do a lot of many operations and a lot of these Aunt programming products. You know, it's not the end end. You can make some very good value and let's keep finding solutions and working with different type of nella existences. It's a really pretty Knight Она then we should not worry about I just want five efforts on just working because deservedly for more unknown what? I use one for weight projection or what else? vector of like 10 parameters and w1 was a matrix that had 10 outputs and 3 inputs. So we had like 30 parameters in here and 10 parameters in here. So in total, we have like 40 parameters just in the w's alone. And down here, w prime would just be a vector with like 3 entries. With just 3 entries, so the inputs over here. And everything that can be calculated with those 40 parameters over here can also be calculated just with 3 parameters over here. I just have to choose those parameters more carefully and different. But there's nothing that those 40 parameters over here can calculate. That those 3 parameters down here cannot calculate. And that means whatever I want to predict, I could do that with this linear function. So this thing also just calculates a linear function. And that's kind of where we need to make sure that this doesn't happen. So we need this activation function so that we actually get something that is more powerful than just a linear operation. But we are actually pretty free in what we want to choose as an activation function. So far, we have usually chosen the sigmoid, which is this function over here. So it maps everything between 0 and 1. But we can choose other activation functions. So this is kind of the natural choice for the output layer of a binary classification, as I already said. So for binary outputs, that's always the last choice. For the last layer. But for the intermediate layers, we might want to choose different activation functions. So we also can kind of make an index for the activation functions, because we probably want to have different activations in different layers. And another activation function that is pretty popular is the hyperbolic tangent. And that is something like a scaled version of the sigmoid. So it's the difference. Okay. The difference being that it maps not from 0 to 1, but from minus 1 to 1. And this has a nice property for the hidden layers, because the mean of what this thing maps to is closer to 0. And that is usually some property that is pretty nice, because that we... It usually... Usually the most interesting parts happen when switching from positive to negative numbers, because that is kind of the difference between... I want to... It's a positive example... It's a good example or a bad example. It's a 0 or a 1. And the most interesting parts usually happen over here. And having this property that it's getting scaled close... It's getting scaled close... It's to a mean that is closer to 0 usually works a little bit better than the one where the mean is scaled to 0.5. So... Or where the interesting parts happen at 0.5. So it's... That's... That's... That's... So this tangent superbolicus work usually works a little bit better for the intermediate layers than the sigmoid. But it also has some disadvantages. And... One thing is... So if we look at the gradient... For example, over here... The slope of this function is not very large over here. So the gradient here is pretty close to 0. And the further... The larger we get over here or the smaller we get over here, the smaller the gradient gets. There's only a small area where we actually have a pretty steep gradient. And things work almost linearly over here. And then the gradient starts to... To go down when we get larger values. And... That is... That can be quite a problem because if you have very, very small gradients, then gradient descent doesn't make a lot of progress because if you... If you remember, we always subtract learning rate times the gradient from the values. And... Which means if the gradient is incredibly small, we will make a step in the right direction. But it will be also be incredibly small. And that... That means our algorithm might run for a long, long time. What is the vanishing gradient problem? That... So it's... Not... The... When talking about vanishing gradients, we'll also talk about those. It's usually a different problem. That's... The vanishing gradients usually happen due to... If you remember, in backpropagation, we multiply everything up. If you multiply a lot of numbers that are smaller than 0... 1... You get also something that is close to 0. So that usually vanishing gradients happen due to... I multiply up a lot of numbers that are smaller than 1. So that this way they vanish. In this case, they all... Also vanish due to the... A single step in the neural network. So the vanishing gradient problem is usually something else that we... If you talk about this. But it's called... It's... In general, it's also one of the possible reasons why your gradients might get close to 0. And... So it's kind of... There's a lot of reasons why 0 gradients could get close to 0. And when using this term, vanishing gradients, one usually talks about a different... Reason for that problem. But there's... The problem that they might go close to 0 can come from a lot of sources. Yeah. So... And... But... And... Yeah. Having... Having gradients that get... Go close to 0... Is... Is kind of one of the main reasons why training doesn't work well. So that... Our algorithm will at some point... Get into the proper region over here. If we just train it long enough. So it will... It will work at some point. But we might... It might take ages. And... We don't... Might not have this time. And... Solving this, for example, the ReLu... Activation function. Which is kind of the maximum of... Some value and 0. So it's... This value... I should not mix those things up over here. So... If the... This input value Z is greater than 0. I'll just take the value Z. And otherwise I take 0. This is kind of... If you think about it. It's the... It's... It's in some way the stupidest... Activation function that you can use. Which fulfills... That it's not a linear function. So it has to be something that is not a linear function for... To... To... To make sure that we don't... Our... Our... Our weights do not... Cannot be... Be just joined linearly. So we... Basically just say... Okay. We... Just... Take one point. Which is not linear. Everywhere else our function is a linear function. It's a linear function over here. It's a linear function over here. It just isn't linear at this one single point. And... That... You... In a lot of cases that already does the trick. So... By... By... By... By... By... By adding this incredibly small, nonlinearity over here. That is enough to make sure that the entire neural network will learn something useful. And... Because it can now make a distinction over here... Between... Very... Values that are larger than zero. And smaller than zero. And for those that are smaller than zero... It kind of can make sure that it doesn't matter how small it is. It always gets mapped to the same values. and it basically can use that. If you think about, if you have a classifier and the classifier is supposed to distinguish between positive and negative examples and a linear classifier can only predict some straight line over here, but using this small non-linearity in the layers, our neural network basically can make something that works like this so that it can also use this non-linearity to split up the decision boundary into smaller linear parts. So it kind of, if you use the regular activation function, then you give your classifier the ability to add those kind of kinks into the decision boundary and which is what we need to get better predictions in some cases. And, so how about the gradient of this thing? So the gradient of this is one if we have values that are greater than zero and it's zero over here. And, no matter how big, how large the value is that we have over here, the gradient will always be one. So it's not going to zero as long as if we have an incredibly large value over here, we always have a proper gradient. So we have a gradient to go down here. Only thing is, if we are negative, the gradient gets zero and the algorithm has no way to figure out that it has to travel into some direction over here. And there is a fix for this. And this is the so-called Leaky ReLU, which is after zero, I'm not mapping exactly to zero, but to some small value over here. So I'll basically take the maximum of x and 0.01x or something like that. So if x is greater than zero, I'll just take x. And if it's small, then I'll just map it to a very small variant of this. This means that the gradient here will be one and here it would be 0.01. So I still have a gradient that helps me traveling out of this region over here and getting over the nonlinear part over here. So, this often works, slightly better than the basic ReLU function. It's possible to choose another value over here. So this is something that you can freely choose. In this picture, I chose 0.1 over here because otherwise if it's 0.01, you don't even see the difference between the ReLU function in the picture. Just so you know, it's that I made this more extreme. So you can actually see something here. In practice, Leaky ReLU is not used, that often, which is mainly because it just works slightly better than ReLU in most cases. But it's kind of, it's interesting that the fact that the gradient over here goes to 0 doesn't seem to matter that much in practice. Even, and so that fixing this problem doesn't, it's not that relevant. Another activation function that we can use is the identity function. And obviously this is a bad choice for all hidden layers because of all the things that we already know, we already talked about. So there's no reason to use this in any hidden layer. But for the final layer, we might want to use that as an activation because we might want, if we have some kind of regression problem where we want to predict any kind of number, we want to make sure that we just predict that number, can predict any kind of number. So it might be a good choice or the proper choice for the last layer of a neural network. So those are, those are the most common choices for an activation function. You can, you can think of others and basically any kind of nonlinear function where you have like a good derivative and can calculate it easily, can work as an activation function. Question for the value of functions earlier. Yeah. I don't really understand why this is, I mean if we take the 0.01, can we just take, can we just take any number? Yeah, this is kind of, you can take any number here. It's usually some, so the idea is you want to have something that is close to zero. So it's like the ReLU function, but it still has a gradient that kind of makes sure that if you're over here, you have a way to know that the gradient descent has a way to know that if it wants to predict something larger, it should have traveled this way. So you want to add something that is small so that it's close to, but big enough that you still make some progress into that direction if needed. So that's kind of, so it usually will be something like 0.01, so but it could be any kind of any number. So you could even put in 10 over in here and then it's not the maximum or something like this, but you could also make something that is kind of works the other way around and just make it very weird. It probably won't work in practice, but it would like give you the properties that you need. So basically, as I say over here, it's kind of you can take almost any function as long as it has some non-linearity in there and you kind of have a derivative almost everywhere. So in this case, you kind of, this is an, the whole function is not differentiable because there is like this point where there is no derivative in mathematical terms. But as practical engineers, we don't care about this because we can say it's just one point and actually you will never be exactly at this point. So we just say, okay, the derivative at this point is, let's say in this case, it could be 0.1, 0.01, or it could be one and we just choose one of those if we are at exactly zero. So over here, it would be 0.01. Over here, it would be one and exactly at this point, we say it's one. So we just choose one of those possible derivatives and that's for practical reasons, for practice that works sufficiently good. So even though it's not completely mathematically sound, but having like any function where we have like a derivative, almost everywhere, that works in practice. So you can choose any kind of activation function you want to, but not any activation function will work in practice. So it's kind of value turned out to be a function that is easy to compute and works sufficiently well. So it's kind of the go-to function. You could use any function, but you will need to make experiments and see, okay, does it actually work better? Okay. And do I make, so if it's a very complicated function and I need more calculations and it takes longer to calculate it, then probably just having another layer with a ReLU function would do the same trick and I can put in another, because I have more, I have less, it takes less calculation to calculate ReLU. I can have more time that I could use to add another layer in the neural network and then probably ReLU with another layer, is better than my fancy function with a layer less and then I could have also just used ReLU and done nothing. So it's kind of finding something that actually works better than the simple ones is not that easy. So now we have basically introduced all the things that we need for one of our neural network neurons. And each of the neurons has basically two jobs that it has to do. One is I allow my inputs to interact. And that is part, that is what the linear part of my operation does. So I have like some allow that I mix up all those different inputs weighted by something in some way, but I have this way, I allow those inputs to interact in some way. And then I introduce some non-linearity to make sure that I just don't have a linear operation all the way through the entire network. And basically these are also the kind of two minimal requirements that I need that a neural network with some depth makes sense. So multilayer neural networks make only sense if I have basically those two properties. And the neurons that we use only kind of fulfill those minimal properties. So we could try to make more fancy neurons, but like the neurons that we use only fulfill the minimal amount of work that is needed to be meaningful for having a multilayer neural network. So there is no talking about multilayer neural networks without talking about the XOR problem. So that's kind of the simplest problem where a single layer doesn't work, a single layer classifier doesn't work. So if I have two inputs, X1, X2, and they can be either 0 or 1, and I have the output that I want to have is also either 0 or 1, and so if both are 0 or both are 1, I want to predict 0 and 1 otherwise, which is kind of the logical XOR gate. If I draw this in this way, it's kind of easy to see that there is no linear decision boundary that I can put in there that would perfectly separate the Xs and the circles. So there is no way I could draw a linear decision boundary that would separate them. So there is no linear classifier that can properly separate them. But if I have like two layers, I could do that. So one way would be to define my weights in this way that I have like the activations A1 would be ReLU of X1 minus X2, A2 would be minus X1 plus X2, and then for the output I just add up those activations. And so if I go through the calculations, A1 would be 0 minus 0 is 0, 0 minus 1 is minus 1, gets mapped to 0, 1 minus 0 is 1, 1 minus 1 is again 0. And if I do the same thing for A2, I get 0 here. 0 and 0 is 0, and 0 and 1 is 1, and minus 1 plus 0 is minus 1, gets mapped to 0, and minus 1 plus 1 is 0 again. So we get those outputs. And if I just add them up, we get kind of 1 over here and 1 over here. And this is kind of also shows you why this ReLU over here is actually important. Because otherwise, if I didn't have the ReLU over here, this 0 over here would be a minus 1, and this 0 over here would be a minus 1, and if I add them up over here, I get 0s over here. So the trick that this neural network does is by making sure that once I get smaller than 0, I just map everything to 0, and this way I can get this kind of kink into the decision boundary. And that's kind of what... And it also shows that even the simple ReLU function is already sufficient in providing enough nonlinearity that kind of this logic gate now works. So kind of if I plot those values A1 and A2 after the first layer, then after the first layer, I kind of get it mapped to those points over here, and I have like two circles over here which just are above each other, so these are the first activations. And now the second layer can just make a linear decision boundary between those, the mapped values A1 and A2. And if I don't have a ReLU function, then kind of those points would be all on the same line, and again, I cannot draw... Even after the first layer, I still cannot put in any linear decision boundary here. So it kind of visualizes and gives us the intuition why the activation function is actually important to make sure that we can make some nonlinear prediction over here. So if we have like these activation functions, we kind of need... For each activation function that we want to use, we need to know the derivatives of those to do the backpropagation calculations. So for this one, we already have the sigmoid. So for the sigmoid, we already had that one. So if this is kind of the... If our activation function is the sigmoid, then the derivative of the sigmoid is the sigmoid times one minus the sigmoid. We already had that when talking about backpropagation. For the hyperbolic tangent, the sigmoid... The derivative is... It's something that is a little bit more complicated, but we can just look that up and see, okay, the sigmoid of the hyperbolic tangent is one minus the hyperbolic tangent squared. So after looking it up, we can just use the formula for that. For rectified linear units, the gradient is incredibly simple. We talked already about this. So it's one for every number that is bigger than zero and zero otherwise. And this is... This is kind of pretty neat that we have, like, we don't even need to... In this case, we need to do a few calculations to get the derivative. And so the number of calculations we need to do when doing neural networks add up and can take quite a lot of time. And, like, having very, very simple calculations is pretty nice when it comes to... When you think about, okay, what we have to do and if we can save time, training works faster and everything works faster. For the leaky ReLU, it's similarly simple. We just don't have a zero over here, but, like, the slope that we had on... That we have in the leaky part over here. So now we have, like, we have the different building blocks for how to do the calculations for the relevant calculations for a neural network. Um... Now if we want to do gradient descent with multiple layers, we need... What we have is... a lot more parameters. And for each of the parameters, we need to calculate the gradient. So, uh, we have, like, for each layer, we have a matrix with, uh... with the weights for each of the inputs. And we have the bias terms, and we have that for each of the layers. So, and, like, the dimensions here, we have, uh, the formula... Uh, we remember this is, like, the input for the first layer, output of the first layer, input for the second layer, which is the same as the output of the layer before and output of the second layer. And if we think about it, okay, uh, when we do gradient descent, we want to optimize some cost function. And we usually call that the function j, which is the cost function over the, uh, over the entire... uh, data set or the entire training batch. And the cost function is dependent on... all the parameters that our neural network has. So we have, like, a lot of different parameters. We have, uh, each of the matrices, and each matrix has kind of, uh, potentially a lot of parameters. And, um, our cost function then is, uh, the mean of the training examples that we looked at. And the... uh, probably the... and if we do classification, this will be the cross-entropy loss for each of those data points. Now, if we do gradient descent, the update step will be going into the direction of the gradient for each, uh, or into the opposite direction of the gradient for each of the parameters that we had scaled by the learning rate. And that's the same thing for each parameter, so it does... uh, uh... I wrote down a lot of stuff over here, but it says the same thing for each of the param... for... for... for... in each... each of the cases over here. And having more layers and more parameters doesn't change anything here. So if we get more parameters, more layers in the neural network, the formulas will stay the same. We need to calculate the gradient into the direction of the respective parameters and do a little step into the opposite direction of those scaled by the... by the learning rate. So, and you can guess what... how this loop would look if we have more layers. So, if we do the backpropagation algorithm, we have two steps that we do. The forward propagation step, where we calculate the predict... the value that we predict, so that is calculating z1, which is w times x plus b, then calculating the activations by using the first activation function on those values z over here. So, yeah, this should be probably a small z... a smaller z over here. Using... doing... then doing the linear operation on the output first activations, getting the first logits over here, applying the next activation function on those logits over here. Again, this would be small z over here. And getting the second activations which turn out to be our predictions for this two-layer neural network. And the... the activation function over here turns out to be a sigmoid, because we... for the output, we definitely want to use the sigmoid over here. One thing to note, and this is why I mixed up small and big letters over here, we probably don't want to do this for a single vector x over here, but for an entire matrix of x, and then we can do this, which is of dimension n0 times m, where m is the number of examples that we are looking at. So, and this is kind of... And we probably want to do everything batched for the entire set of data... for all the data points that we have, or that we are looking at at the moment. And then we also get, like, a matrix... a big z over here, and a matrix big A over here, because we get the outputs for each of the data points in the same... in the same operation. So if we... I try to draw this as a compute graph, I'm... I... I'm starting to combine more and more operations into the individual nodes of the compute graph, so that it doesn't get too large. So in this case, I have, like, a linear layer, and the linear layer has... weight... a weight matrix as inputs, a bias term as inputs, and, like, the... the original input features as an input, and I... as an output, I get the values z from... from the linear layer, then I map those through the... the activation functions, get my activations A, and get another linear layer up till the... the final outputs y hat, which I then put into the loss function, and get my final... my... my... my... the final loss number, which I want to optimize. So when doing back propagation... when... when doing the forward propagation, we kind of calculate through this compute graph to get the final loss. Doing back propagation, we need to calculate the individual gradients. And so I'll write it down in kind of mathy terms over here, and the exercises we will kind of try to program all of those things in NumPy, and... and it's even... it's... which still can... can still be a bit challenging even though you know all the formulas for each part here. So if... the... the gradient for the loss function, we already saw that we can... can... can... can kind of batch together the... the... the... the sigmoid and the last loss function, so we can kind of batch this... these two operations together when calculating the gradient, because it's an easier gradient that we get at the end. So we get, like, the activations... the second activations minus... oh, which is just y hat minus y as the gradient into the direction of z2. So we kind of already have the gradient of the loss into the direction of z2, so we get... got the gradient up till the... down here. So if we now want to take the gradient into the direction of the parameters w2 over here, we need to multiply the gradient that we just had before times... so... and... times the gradient from here till here, so that... which... and the gradient from here till here will just be the inputs that we put in here, so it's... it will just be the a1 over here, and... so if we want to multiply... and we need to multiply that with the gradient that we got from over here, so the gradient into the direction of w2 will be the gradient that we got up here times the inputs from over here, so... and... again, here... all these are vector and matrix operations over here, so... and written down in the way that the proper derivative ends up in the proper position for this matrix over here, so... and kind of remember that if I do a matrix vector multiplication, so I multiply w and a, so... this thing over here is affected by... so... this value over... so this one over here times this value over here gives you the value over here, and if I have like multiple inputs a, so if I have like another input here, then this value over here times this one over here gets... results in this value over here, so what we will need to do is we already have the gradients for each of those values, which are the ones that... are in here, so we have the gradients for each of the values over here, and each of those need to be multiplied with the corresponding value over here, and we will need to add them up to get the gradient for this value over here, and this is kind of what happens if we do this operation over here to make sure that the gradient for each of the... that the correct gradient of... ends up at the position in this matrix over here, that we need for... that... which kind of... is each of the output values that are affected by this one, and each of the input values which are multiplied up with this value over here. So if we... go one step... go to the other direction, if we go to the bias term over here, it's just a linear operation, so we multiply the gradient over here with... one, because the gradient into... from here to here is just one, so it's just the gradient that we already calculated over here. Now we go down one step further, we calculate the gradient into the direction of... the activations A1, so we take the gradient... so we... so we have had like the gradient this way, we had the gradient this way, now we... need to calculate the gradient this way, and now it's the gradient that we have over here, but we need to multiply it with the weights from this way... from over here, because we are kind of on the other side of the product, so it's the... this matrix over here, multiplied with this gradient over here, and to make sure that everything ends up at the right position, we need to transpose the matrix, so that everything works out, and probably a good exercise for... if we want to... if... for the next exercise sheet, if you want to... understand this more properly, it's kind of a good thing to write out this matrix multiplication in full, to see why... why we need to transpose it, so that the gradients end up at the right positions. Next, we... over here, we need to... make the step down here for the gradient, so we need to multiply the gradient that we just had, with the gradient... of... this... activation function that we have over here, and in this case, this thing here is the element-wise multiplication, because there's no proper mathematical symbol for doing this operation, that is kind of the normal NumPy multiplication between two vectors, where I just want to have another vector, where I multiply this by this, and add... put the result over here, and if I want... and so on, and kind of this element-wise multiplication, I'll introduce this symbol over here to... to... for... for that one, which is kind of the standard NumPy multiplication, if I multiply two vectors, because otherwise in math, that's usually... you usually always take the dot product between vectors, which is something different. So we... we take the gradient of... that we had for each of our activations, and multiply it with the gradient... of the... activation function... at each of the... of the... the... the... the individual intra-entries, and this is kind of... while... over here and over here, it's kind of hard to get those... those transpositions and matrix operations right. Over here, it's actually pretty simple, because this... usually we can have just the formula over here, and we just do element-wise stuff, so it's kind of pretty easy to go down this... this way, so we end up over here. Next step is, we kind of need to go down from here to... the parameters W1, and this will be the same operation that we did over here already, so we take the gradient... into... that we have accumulated over here, and multiply it with... the parameters that we have over here, so that's kind of the same thing that we did... over here, and if we have more layers, it will stay the same, even if we do more and more calculations, so going down even further will... just be the same operations over and over again, the same thing for... if we go over here... into this direction, we again... multiply this one by one, so it's just the gradient that we already calculated... going down over here. So, now we have like the gradients for... each of the different parameters over here, we don't need to go further down this way, because we don't need the gradient for the input parameters, because we cannot change them. Again, in the same way that we... batched everything... and vectorized everything... when we went up this chain, we also want to make sure that... everything going down the chain... is vectorized properly, and here are some examples for this, so... if we... when going down... doing the gradient computations, we also need to... want to... make everything... batched over... batched over the... all the training data that we are looking at, and vectorize everything, and... in some way, everything works... exactly the same way... that we write down things over here, we just need to make sure... that... at some points, we need to average over the... the entire training batch, so, which is because... if we basically take... one over m... times the... individual loss functions, so if we... we kind of have this... one divided by m, which needs to be part of the... of certain of the calculations, and... we kind of need to remember... to put that in, so it's... it's one thing that... needs to be done to make sure that... everything still works in the batched way, so... this way, kind of, we can get... kind of... but otherwise... otherwise, all the calculations over here... are kind of just numpy... the translations of those things into numpy... so... having all this, and... you'll be in the... in the exercise sheet for next week, you'll be able to... to kind of put all this together, to also... to train your own... numpy-based... neural network, and make... put all this together, so that we can kind of... make a proper classifier with it, and... we'll use the same data as for... the logistic regression example, so we can see that... okay, adding more layers... actually gives us some advantage, and makes... the results actually better. So... when we... train logistic... train logistic regression, we can just start by setting this entire... this vector w, and this vector b to zero... this value b to zero, so... can... a question is if we can... can we do this now that we are... dealing with a neural network? And... the... short answer is no, but let's see why. And... if... one thing... one thing is if we have multiple layers, setting everything to zero... will mean that all the gradients turn out to be zero at the end, because you start multiplying zeros in at some point, and... then... for... for logistic regression... this doesn't happen, because you... kind of... if I take the gradient into the direction of w, I'll take the gradient x, which is not zero, so everything is fine, but if I have activations, which are already zero, then the... gradient into the direction of w will... again be zero, and we'll... I'll... I don't make any progress, because I multiply up zero gradients. So, this is an issue. The other issue is symmetry. So, let's assume our parameters for each of the neurons are not zero, but they are the same for each of the neurons. So, I... basically, my matrix w... just consists of... like... a, b, c, d... a, b, c, d... a, b, c, d... So, if I have like the same values over... c, d... So, if I have the same values for each of the neurons, so it has... each neuron has some values which are different, but each of the neurons is the same... is the same. So, if I think about... some... my inputs, and... I have like three... four inputs and three neurons, and each of the neurons calculates the very same number. So, if I have my inputs over here, this one will report... say my output is five, and this one will say it's five, and this one will say it's five. Then, if I do my backtracking, backpropagation, if... everything over here was the very same thing for each of those neurons, then the gradient for each of the neurons will also be the very same. So, the gradient turns out to be the same for every neuron, and if I now say that... my matrix W is equal to W minus... some learning rate times the gradient of W... into the direction of W, then... I'll just... subtract the same thing in each row, and each row was the same beforehand already, so it's different, but it's still the same. So, each row is still the same, so every neuron will have now a different output, but still the same output. So, the neurons never differentiate between each other. Every neuron will still produce the same output every time, and that is pretty bad, because no matter how long I train my network, every neuron will still give me the same output, and if it gives me the same output, I could have just left them out. I don't need 10 neurons which all say the same thing. I can just use one and multiply its result by 10 and still have the same effect. So, we need to make sure that we can break this symmetry, that we don't end up in some symmetrical solution. And the easiest way to do that is just start with random values. So, and the nice thing is I don't even need to do that. The nice thing is I don't even need random values for everything, not just for the values in my weight matrices. So, the bias terms can usually be initialized with zeros, but for the weight matrices, I still need to put in random values and make sure that they are all different in some way. . Something like this might happen. So, it's unlikely that they align perfectly. So, it's... Thankfully, thanks to numerics and everything, it's usually that there will still be some difference even if they get very close. So, it's incredibly unlikely that you turn out that... It turns out that two neurons get the exact same values at some point. But it's not impossible. It's perfectly possible that you end up in some degenerate solution where you get... Where two neurons are... Due to some circumstances are forced to get the same values and then... Or... And after that, are kind of useless in some way. So, that's... But in practice, that doesn't seem to be an issue. It's... So, if you take random initializations, they usually tend to... They might still... It might still turn out that two neurons are too similar that they don't make... That it's not very useful what they are doing, but... Or not usefully differentiated, but... It's... They... You usually break up the symmetry this way. Something you usually do is that... You multiply those random values with something small. So, you want to make sure that those values are close to zero, but not exactly zero. You just want to make sure that you break up the symmetry. It's... And have some direction to start with. So... And one of the reasons for this is also that if you... So, we want to have values that are close to zero. And if you think about all our activation functions, the interesting stuff always happens close to zero. So, you want to make sure that whatever your neural network predicts, it should be somewhere close by this interesting point. Because that's where you differentiate between, like, the... Like, the good and the bad examples. So, we want to, like, put bad apples on one side, the good apples on the other side. And the... Like, having the non-linearity here should be the point that kind of differentiates between them. And... Because that's the point that we want to make. Because that is usually close to zero, you want to make sure that your values are also close to that point. But... If you make this too small, then you are kind of getting problems again. But, like, something random close to zero usually does quite fine. Also... When doing logistic regression, you always have, like, a clear-cut global minimum. So, if you do gradient descent, you will end up at the same value... Parameters every time, no matter where you started. When training your neural networks, you have a lot... You have a much more complex surface over here. So... And... There is... There can be local minima. So... And there can be a lot of issues when training neural networks. And... If you, like, start again... Start your training run again with different random initialization... Parameters... You might end up at a completely different solution. And it might even be better or worse than another one. So... Like... This randomness over here also might give you completely different solutions when it comes to the final neural network that you have. So, in general, we will also talk a little bit more about this. It will not be such a big issue where you start exactly. But it's important to keep in mind. We start... We randomize the starting position. And... Depending on where we start, we may end up at different local minima of the loss function and have... Get different classifiers. Because it's not... Not a simple surface where we are guaranteed to always end up at the same point like in logistic regression. So... That's it for today. Do you have more questions? I know that I threw a lot of... math at you today. And a lot of the... And a lot of the... Those... Those... Scary looking gradient parts. It's... When you start implementing all those things, at some point it might click for you. And then you realize it's not... It's easier than the scary things over here look like. Because... Again, as I already told you, it's just multiplications and additions in some way. And put... Blocked into fancy operations, which are matrix vector multiplications. But... It's all addition and... And multiplication at the... At the... Lowest level. And... So... Do... Do the exercises and... Try to figure out what... What... What actually happens deep down in there. And then usually the... The scary part goes away after... At... When... When... When it clicks at some point. And... See you on Friday. Bye-bye. Bye-bye. Bye. Bye-bye. Bye. Bye-bye. dice plays . One, two... Somebody raised me. Who's a jerk? Who's the jerk? A jerk? Jesus. Brock set me upET Shut up, welding man. I can't believe this. Just get down. Mac? Get down. You ok? Full escape into the shit. You ok? I know what happens throughout the speech. I know. Who the heck is with him? How? Jack and Tara. Who's this?\n",
      " So welcome to artificial intelligence. Some organizational things first. So there is an OLAT course for this. So I hope this link is the right one. Yeah, so and the OLAT course has some kind of the links to the relevant links. And I will upload exercises here and the solutions for exercises. Exercises are in some way completely optional. You can do them, you can not do them. I prefer if you do them or at least you should prefer that because if you don't that's your loss. The OLAT course has links to the slides I'm using and the slides are all linked to the slides I'm using. So that's the whole idea. So the OLAT course has links to the slides I'm using and the slides are all linked to the slides I'm using. So that's the whole idea. So that's the whole idea. So it has like the slides itself and a print version. So the print version is basically also just a web page but one which is kind of better suited for directly printing slides if you want to do that. Printing in a lot of cases the print looks the way it should look but in some cases the slides if the slides have interactive elements then printing doesn't really make sense and then printing also doesn't work that well. I have created a Teams channel for this course so you don't have to but probably it's a good idea to register there and for asking questions. So you don't have to but probably it's a good idea to register there and for asking questions. And getting answers either from me or from somebody else in the course. So it's good idea for communication and in case there should be the next pandemic or don't know what and we have to switch to making remote classes I will also do that via Teams. Who knows what the future holds. I will record all the all the lectures and upload them into the course. So I will also do that via Teams. So you can log in there with your THBing credentials and once there was a first lecture you will see the videos there and can for example when doing exercises it might be a nice thing to go through some parts of the course again or when preparing for the exam at the end. There I have created a JupyterHub for the exercises and I will talk more about this later but if you want to solve some of the exercises you can do that on using this Jupyter instance that I put on one of the THBing servers. I'll talk about that later more about this later so yeah so we can do the exercises there lecture recordings and at the end of the course there will be a final exam and we have termining great and so on. The exercises will be posted in the form of Jupyter notebooks so again more on that later and I will post them into this OLAT course over here. Yeah okay so basically basically basically basically basically basically basically basically basically basically the Jupyter notebook is some kind of remote Python environment. I probably a lot of you have already some Python experience but in case not I'll use the exercise on Friday to make a brief Python introduction so if you already are pretty experienced with it with Python and with numpy the Python what one of the main Python libraries we will be using. in this course you can basically skip Friday but otherwise I'll give kind of an introduction into those things on Friday to bring you up to speed so everything is will be will be in form of of Jupyter notebooks so maybe as a very very brief introduction just now Jupyter notebooks are kind of a remote Python. environment they live all the notebooks live on kind of a remote server and what you see is a small web front end to edit them and all the notebooks are comprised of small cells where you can write some small Python code and and and where which you can execute individually and see the results. So you can see the results. So you can see the results. So you can see the results. So you can see the results. And which gives quite a for at least for those small examples and small projects we will be doing here is it's kind of a pretty pretty nice developing experience. And also something nice about this is that the server has actually a lot more horsepower than probably your notebook has because it has two GPUs installed and quite quite a bit of of of hard drive and. and and and and memory. and so that that that we can even do some more more demanding tasks there and for for most of the exercises that should not be necessary but for example doing larger image classification tasks. and doesn't doesn't necessarily require a GPU but it's it makes the difference between. and and developing something in a few in a few hours or waiting weeks for something to finish and that that can be a nice thing to have those. and you can use this Jupiter instance for other. other projects so if you for example do your master thesis and need some compute power for that you can also use the stupidest server for for something there so if it's it's not not restricted to this course just don't abuse it. so if you for example do your master thesis and need some compute power for that you can also use the stupidest server for for something there so if it's it's not restricted to this course just don't abuse it so if I see anybody. mining crypto currencies there it's kind of I. I will press charges for that. So. References for this course. There's kind of one really good. book about deep learning. By I am good for the fall fellow and Joshua Ben Joe and Aaron Covell which kind of is it's recommended but not necessary so. So. And that's. And that's. And that's. And that's. And that's. I think one of those references unnecessary. And Andrew Ang has put up a lot of good learning resources as well and learning videos and I'm following along along a lot of his course material so that's kind of also quite quite a good good resource. So in total this course will so artificial intelligence in general is a very very very huge. Bucket of different things to do and the main focus of this course will be on deep learning. learning techniques. So that's not all there is to artificial intelligence, even though at the moment it sounds a little bit like this if you follow the media, everything that's all the big AI breakthroughs are deep learning based at the moment and there's a lot of gold rush fever around the deep learning topics, but it's not everything, it's not the entirety of what artificial intelligence is and there's a lot of other techniques and algorithms that that are also incredibly useful and widely used in a lot of industry contexts, but yeah this course will be all about deep learning and how to build neural networks, how to build deep learning based systems to solve a variety of tasks. So going a little bit into the history of artificial intelligence, so in the 50s many many many of the techniques here are old, even some are much even older than this so kind of machine learning and it is first mentioned in this book, in a paper about the perceptron, where they first built basically a machine to do machine learning, so it's that was the time where computers were still room-sized things and the perceptron was a machine that could do classification tasks by learning from data. And the the first instance of this was basically a series of machine for this single purpose. Sometimes later, in the 60s, we had way more techniques, and some of those are kind of the backbone of what we are still using today. So the backpropagation algorithm is from the 60s, and it's kind of the same math, the same ideas that power all the neural networks in use nowadays. So I'm not sure if it's... It's kind of funny that there hasn't been any changes in the fundamentals there. So there's little tweaks and some little engineering ideas to make it work better, but the core idea is still the same for the last 60 years. Back then, they discovered a few fundamental limits for neural networks. It's funny that back then, there was a big report about how what a simple linear model, for example, a linear perceptron can compute and what it cannot compute. And this report led to a lot of funding for AI research being frozen and a lot of research being discontinued, even though those fundamental limits are kind of... It's a pretty weak... It's not like they said a neural network cannot compute a lot of... cannot, for example, ever do image classification. It basically said that for example, one layer neural network can never solve the XOR function, which doesn't say anything about two-layer neural networks. And so this report was... misread by a lot of legislators back at the time. So, in the 80s, people rediscovered backpropagation and back then, we got the first proper industrial uses of neural networks. They had the first convolutional neural networks for identifying digits on letters. So, the US Postal Service was using a machine learning algorithm that used a convolutional neural networks, more on that later in the course, which classified the individual letters for the zip code on the envelopes and thereby kind of read in the zip code automatically. Back then, a lot of things that we kind of rediscovered later on were already in backpropagation. So, we had a lot of things that we kind of rediscovered later on, we're already in backpropagation. so, we had a lot of things that we kind of rediscovered later on, we're already in backpropagation. But also, we had a lot of things that we had been told not to have had been said not to read down again and it took some time until all those things were again rediscovered. So in the 2000s there were like two things which started to get everything going. There was one thing, the Netflix price. Netflix put out a prize money of one million dollars for somebody who could improve their movie recommender algorithm by 10% or more. And it turned out that, and they put out their movie recommendation data set for everybody to use and to fine tune their algorithms. And that was a pretty big thing because that was kind of the first time where a big proprietary data set was kind of free for the taking for everybody out there and to do research on. And so that was a big thing. And so that was kind of the first time where a big proprietary data set was kind of free for the taking for everybody out there and to do research on it. And probably the prize money was net and the prize itself was also a nice thing. But the fact that they put out a really, really huge data set for everybody to work on was kind of a novel thing. Up until then, most data sets existed in walled gardens. And this was one of the first times that they were able to do that. And so that was one of the first things that needed to be solved, the access to large amounts of data. And later other people started ImageNet, which was a kind of library of publicly available images tagged with classifications of what you can see on the image. And that was also publicly available. That then also became publicly available. So in the 2000s, it started to be a very big thing. And we started that we solved some of these data access issues. And in the 2010s, a neural network called AlexNet did soft image classification on this ImageNet data set on a level that was on par with humans. So it was almost as good as humans could classify those images. And that basically led to the deep learning boom that lasts till today. So since then, people discovered, okay, now we have access to enough data to train those really large models, and we have enough compute power to train those models. And it seems that we can now do really useful things with all those techniques that were discovered pretty far back then, which led to people doing more and more applications for this and finding more techniques to use these on different data sets on different types of data and to find new applications. Some of those applications. So we can nowadays basically do machine translation on a level where so like 10 years ago, machine translation was still something you could ask Google Translate and sometimes get pretty funny results. And sometimes translations back in the day used to be pretty still pretty shitty in some cases. Nowadays, machine translated texts are basically as good as a human could translate them. So it's kind of it's very rare that you see cases where a good machine translation software doesn't do a proper translation or does something where it results in anything funny. CTR can do object recognition, we can try identify objects and images classify them. This image also kind of yield is kind of lead leading up to another application, which is kind of Self driving cars. So nowadays we opt like image recognition is good enough that we can build reliable systems that can identify okay? Where is the lane or where is the lane off or where is the lane? on the street and where are other participants in the in the street so i can steer can reliably steer a car in this environment up to some limits so it's not not at the at the point where we can have fully autonomous self-driving cars but the tech is getting better and better and uh i i think it's just a matter of of like next 10 years i guess we will have fully autonomous self-driving cars as more and more issues get resolved some other other applications we got a protein folding which is uh used to be an incredibly hard problem so if you have a protein if it's easy to take a protein and see the sequence of the different molecules in the protein so if you if it's easy to to get some substance and identify okay what is the c in in which order are the different molecules within the protein but that just gives you a long string of molecules what is interesting and what determines the uh the way that the protein works is the shape that the protein will take on in the real world so if you take this long string of molecules they will fold into a certain shape and this shape determines the properties that the protein has and it's not trivial to know if you just have the string of molecules how they will behave in the real world it's kind of it the physics is kind of well understood they will fold into the configuration of least energy but it's non-trivial to know what this configuration of non of of of um uh least energy will be in the end and so and uh a team a a team from from google created this algorithm alpha fold which um is a deep learning based system that trains on proteins where we already know this so-called tertiary structure and learn and and from from from the the two-dimensional structure or from the one from the long one dimensional structure and um uh kind of learns how proteins the different molecules tend to interact and does a pretty pretty good job at predicting this three-dimensional structure which uh so it's it's still it's still pretty young but uh there have been a lot of medical breakthroughs thanks to this now now that they can um do things like we need a protein that kind of binds to certain other protein parts and they can now do things like oh okay we test a lot of different protein configurations now and check okay what will be the tertiary structure of that and then um from that uh uh uh they they they basically get the idea okay what is the protein that they need to synthesize and get kind of medica and and derive medications from there so there has has been some breakthroughs in uh for for artificial intelligence in games where we had certain games where uh humans were always kind of better than the machine than machines so chess was pretty was solved in the 90s with deep blue uh but uh like more more complicated uh the games where there is social interact there's interaction between people and um uh the complicated environments which are hard to parse um that took more much much more than chess did back then so you need to parse much more information in a visual image here and it's much harder to to to to to uh probably build a bot that can can can solve those environments but deep learning is no magic pixie dust it's not like you can have any kind of problem and you can just uh say okay let's just throw big deep learning at this and um it it will magically solve the problem that we have there's a lot of limitations of when can we use a deep learning algorithm for solving something for example we anything machine learning based will need as the name suggests something to learn from and if we don't have the data to learn from and if the data is not good enough to learn from we have no chance to build a learning algorithm for the problem that we have so that's the problem that we have so that's the problem that we have so that's the problem that we have so there's still a lot of tasks where we don't have like the proper the the the proper learning data the proper a proper way to solve that so it's not we we still need we still need to think ourselves to how to to approach the those problems as i said in the beginning artificial intelligence is a pretty big field so there's what we will cover in this course mainly the deep learning part which itself is a subfield of machine learning which covers much more than just neural networks which itself is a subfield of artificial intelligence which which also covers other things so artificial intelligence also covers things like planning algorithm a shortest path problem for example is also an artificial intelligence problem that we we won't cover over data here or how to solve for example if you want to solve a timetabling part and so how do you do that and that's what these people do into such powerful technology tabling problem like making this timetable for a university like here that's also an artificial intelligence problem but one where for example a deep learning algorithm is not the ideal choice for solving that so a question that we i already started to answer a little bit why do we have the deep learning boom right now so why is the is deep learning something that took off like six years ago and is kind of create creating so much fuss right now why didn't it in in the 80s when a lot of those algorithms were already known so in some way more information now is digital so back then almost no information was digital so there the internet was basically some kind of some something something that was used for universities to change a little bit of text data and communicate with each other but not not something everybody used and so digital data was not exist almost non-existent back then nowadays all the information is digital so we have images texts shopping transactions and whatnot and it's all already available in digital form because the information is basically directly created digital um if we think of so so this image is scaled a little badly, so the axis here would be data, so kind of on a log scale. So the amount of data. If we take very, very simple linear models, they kind of, they perform well with little data, but kind of, it doesn't matter how much data you throw at a very simple linear model. And so as long as you have only little data available, you don't realize that your model has kind of fundamental limits in what it can compute. But the bigger you build your model, the more powerful your model becomes, the more it can benefit from having large amounts of data available. So if you have, like, a very, very large neural network, you will basically have the effect that as long as you have only a little data available, it will underperform the linear model or a smaller neural network. But if you have a huge amount of data available, then it will start to give you more performance. And that is basically when, as we were still in an age where there was not that much, data available, there was no use in producing bigger models or training big neural networks. It kind of, there was just not enough data to train them properly. So if you look at something like ChatGPT nowadays, that is something that is trained on huge amount of crawled internet data. So with several, we don't know how much data they exactly use, but there is kind of the open competitors to ChatGPT, they use certain crawled data sets which have a few terabytes of data available. Some of that, I, on the Jupiter server, I have a copy of one of those dumps that can be used. It's like two terabytes of text data, and two terabytes is an enormous amount of text data. That is more than, so if you take, like, your average library and would digitize all the books in there, that's, you know, that's a lot. A few gigabytes, it's probably at the most, it's, terabytes of data is, of text data is incredible amounts of information. So if you think about, okay, the, all this, we don't do, our plan is not to use neural networks for, because neural networks are incredibly cool, they are, but the goal is, we want to solve problems, we want to build products that kind of, that we can, that can be used by somebody, and that do something useful. And to do that, we need kind of deep learning, groups of people who can create those products. So the question is what makes a successful deep learning team? So what is a team that can build a successful deep learning product? So, and, there's several factors that make, they make teams that can build successful deep learning products. So one thing is, they are really, really good at acquiring data, so, data is kind of the most important resource that you, that you have when it comes to machine learning algorithms. So everything else, if you start with the shitty model, it's, it's okay, you can improve on that later. If you have shitty data, you will never get better. So having good and enough data is the most important thing to start with. And if you have no way to acquire that, your product will definitely fail. So if you're good at this point, you have got the most important issue out of the way. The second thing is, good deep learning teams use every opportunity for automation. So if you think about it, artificial intelligence is all about automating things. So the idea is, we want to build algorithms that can solve something, that autonomously do something for us. And basically, a good deep learning team kind of tries to do the same on the inside. So you want to try to automate all the... all the things that you do even inside the team to scale up the resources that you have. So if you think about managing two terabytes of text data from the internet, you will not be able to kind of manually do anything in there. It has to be automated pipelines that process the data and do all the things in between in there. In a similar way, almost all companies have data that is stored away in different silos. So you have like different parts of the company and they rarely talk to each other. And an important part is that you kind of... that you are incredibly good at data warehousing. So taking in the different data streams from different sources and joining them together is also something that makes... makes really, really good deep learning teams. And if you think about it, if you have like... Which companies are incredibly good at... in artificial intelligence nowadays? You have mainly companies for which kind of those... For example, where this first part was incredibly easy. For example, Google. Aggressive data acquisition is incredibly easy for them because they are already completely digital. So all the... the... people come there, enter search terms into their... into their web search engine and produce already immediately digital data that they can use for... later on to improve their search algorithms and so on. And they also basically started at this point. They are not like an old chemical industries company like BISF in... where they started without... any kind of... where the internet... They started where the internet didn't even exist. So joining all the data sources is kind of... They basically could start with... When they started, they were able to make sure that... all the teams have access to all the data that is necessary for them. And they didn't even... They had... Were able to not even build up the silos in the beginning. And you have the same with all the big internet companies like... Amazon and Microsoft and so on, which now are kind of the dominant players as well for... when it comes to artificial intelligence. So this... Because they had it easier to... to get the data in the first place and to not have siloed data sources. And a lot of the big industry companies nowadays, which try to also get good at this. Think of, for example, the big car makers. They have a much harder job to... even get good at data acquisition. So Tesla kind of already built data acquisition into their product... from the get-go. So if you drive a Tesla, they will... They will gather driving data from your car all the time... with every mile you drive. Your Volkswagen is not doing that. So... Especially if you have older Volkswagen models. So... Having this ability to immediately build data... built-in data acquisition into your product... is kind of a pretty important thing. So... So... This kind of gives you an idea of... Data is incredibly important and... Everything we do in this course... will only be as good as the data that we use to feed those algorithms. So... Within the course... I will focus a lot about those algorithms. So you will learn... how to build... deep learning models. But a lot of those practical things... How to build data warehousing... How to build products in a way that you can... immediately acquire data from the user... will not be something I can teach you in this course. It's kind of... It would be out of scope. But it is also something that is incredibly dependent on the industry. So if you... For example... For example... How to build a webshop in the way that... You can always collect information... What the user actually wants to see and what not... Is kind of a very, very complicated thing... User interface wise... Because you need to do something... To build the interface in a way that... In a non-obstructive way... The user can give this feedback... Or automatically generates this feedback... Without... Giving you a shitty user experience... And that is... A very complicated thing. So... That is... It's kind of a very, very complex and... Skillful thing to do... In the first place. So... Within this goal I want to teach you the relevant deep learning models... And where to apply them. So we will cover several model architectures... I will teach you how deep learning works... From the mathematical side... How to implement deep learning models... We will implement a lot of those... Completely from scratch... And then... Slowly work ourselves up... Using frameworks that... Take away some of this... The necessary work... And so we can build bigger and bigger models... And more powerful applications... We will implement and train several deep learning models... And I will try to help you... Getting the know-how... How to debug those... So it's... If you think about how does any kind of software project work in practice... It's usually you try to do something and it doesn't work... And then you start debugging... And so... I will try to also teach you some ways of how to figure out... Why something you are doing is not working... And because that's usually the default status... For every kind of software... At least in the beginning... And yeah... Make you able to fix those problems... So I will not cover other... Machine learning techniques... Like for example support vector machines... Or k-nearest neighbors... Or a lot of other things that are... For machine learning or other... Artificial intelligence techniques... So this will not be part of the... At least of this course... So in the exercises we will implement... A lot from scratch... And to see how the details work... So we will... While there is a lot of deep learning frameworks... Where you can just say... Okay... I want to have a neural network... With three layers... This many neurons... And this is the data... Go train it... We will start with... Implementing everything from scratch... Say okay... This is the data... This way we turn it into... Into vectors... These are the matrices... That are define our neural network... This will be the gradients... Of those matrices... This will be the updating rules... How the neural network... Would update in each step... And so that you get a better understanding... How all those things work under the hood... Because that is kind of the... The thing that will be incredibly important... To be able to fix problems... Because if you just blindly use a framework... If it doesn't work... You have no clue why it doesn't work... Because you don't know... What is the error mode... What went wrong... And so my goal is to demystify... Those inner workings... Because kind of neural networks... Kind of tend to scare people away... They treat it as black boxes... Where nobody knows how they work... On the inside... And my goal is that... At the end of this course... You will know how they work... On the inside... And that is... That this mystery will be lifted... At least for you... And so... And that you know how the details... On the inside work... So... I showed you... At the beginning... I showed you this Jupiter server... Where you find the link on... In OLAT... If you don't want to use that... Or if you... For example... Want to work offline... Because you don't... The internet is bad... Which at the university... Can often be the case... So the Wi-Fi here... Is kind of flaky... In a lot of cases... And so... I think... That is the goal... And I think... That is the goal... And I think... That is the goal... In a lot of cases... You can install your own... Jupiter environment... So... One way to do that... Is for example... The Anaconda distribution... Which exists for most... Relevant... Operating systems... And... And which is kind of... One of the easiest ways... To install... Kind of... Jupiter... Python distribution... Alongside with Jupiter... And everything that... You might want to... Want to use... But you can... For doing the exercises... You can do that... Any way you want to... So it's not... There's no... Required way... And... Especially if you have... If you are more proficient... With your laptop setup... Then probably... You'll prefer... Some other way... But in that case... You... I also... You also probably... Don't need... My help to do that... Anyway... So... If you want to... Make a local... Python and Jupiter installation... This... Anaconda distribution... Is kind of the... The best way... To do that... So... Are there... Any questions... Regarding... Course... Logistics... The topics... Of the course... Yeah? I don't find... The OLAT course... For... For that... You don't find... The OLAT course... Anybody else... With that problem? No... I could find... You could... Okay... So... It should... So... I would... I would say... I'll send you the link... Via Teams... So... That would be... That's... That's the chicken and the egg problem... So... We can find it over the... Masters course... So... True... There should be... There should be a general... Masters course... So... Are you... Registered... Registered in the... Computer Science... Masters course... There is... There should be one... Where there's... A link... Otherwise... So... If I'm... I'm... I'm... I'm... I'm... I'm... Scoring Courses... Catalogue... So... Otherwise... If you are going to the... OLAD catalogue... And... Go to... thbingen... And... Go to... FB2... And then search for me... Which is... This... Nice-looking guy here... It should... then it should be, then I was too stupid to make sure that the course is in there as well. So, this one, and yeah. . Yeah, and now probably the internet broke down because it should, . So, and, here we go, so okay, now you can find it in my course list here. So, otherwise you can also, if you send me an email, I'll try to send you the link as well, so if you, so it, that goes for the entire course, the entirety of the course, so if you have run into troubles or issues at any point, feel free, ideally write something in the Teams channel, because that means maybe somebody, so somebody else might be even able to help you before I do, so it might, and other people can also see the solution for the problem as well, so if you have issues, just write in the common Teams channel, ideally, so, and then, then we'll try to resolve the problems. So, on Friday, as I said, I'll do kind of a, a small Python introduction. Now we'll start with the, the main part of the course, so we'll start with, the question, what actually is a neural network? These are actually kind of vegetables, animals, we deal with the P fit and randomness, we deal with the data. . In the presentation, if this isn't computerized unterstütztekintstock that I put this on it's name. So it shows me what a- How does it work? How does it show the data I'm seeing when I see it? How does it compare on other things? In other words, it is not exactly close to us, it shows us what the data is. How do I, not to confuse you, meters and I have the price on one axis so I've basically two dimensions of data and I have one two three four five six houses and what I want to do is I want to have a way to predict if I given any kind of size of one house I want to predict the price for it and one of the easiest ways to do that is create do linear regression so we can say okay I'll plot a line in here say which is a linear function of the size of the house and which which has two free parameters that will be the size of the house and which has two free parameters that will be zero and w one and if those two but once I know those two parameters I can calculate for any kind of size a prize for that house doesn't need to be the correct price it's just a way I'm the way I'm modeling the world I'm saying I I'm assuming the prize is roughly linear function based on the size of the house re an acting function based on the size of and I'm trying to learn the parameters of that function and those are the two parameters that I want to learn and given I have them I have my entire model H and that model will give me a price for the house and what we want to do is and this kind of linear model is kind of one of the the earliest things for machine learning in general so okay okay that was basically invented back by Gauss in the 1800 something how to calculate a regression line through several data points and what what we want to do would want to do is calculate those parameters such that the distance so and what the distance is will be a cover this see later but that that the distance between those between the actual prices of the data points that we have and the price that we predict gets minimal but if we if you think about what this model that we have here does then there is one issue that depends on the model that we have here and that is that the model that we have here does then there is one issue that depends on the model that we have here does then there is one issue that kind of would be more obvious if the if the kind of would be more obvious if the if the cropping wouldn't be so bad but if we have a price or if our the size of our house gets pretty small the price gets negative and that is kind of very very obviously wrong so we can try to fix this model and say okay we make a new model and that model is take the maximum of the what we the linear function and zero. So if the linear function that we just had is bigger than zero, we'll just take that one. And if it's below zero, we just take zero. So we kind of cut our function off at zero and make sure it doesn't get below that. And this is probably a better predictor than the one we had before. So because we kind of have fixed one of the small issues that we have with this, we never get a negative price and that makes things at least a little better than it was before. Still having a zero-priced house is probably pretty unrealistic, but it's at least not as wrong as it was before. And what we basically did here was we created a very, very small neural network. We have? Yes. Some input, which is the size of the house. We have our neuron, which is this little function here, which it takes as a linear predictor and this maximum of the linear predictor and zero part. So it has kind of something additional to this linear part and outputs some estimated price. So it's good. And. The neuron here is basically this function. So that is mainly what one neuron in an artificial neural network is. Doesn't need to be those functions. It doesn't need to look exactly like this, but it's one way a neuron could look like. When you hear people talking about neural networks, then neural networks are often compared to the brain. And this is, it's somehow, the comparison doesn't always hold very well. And especially in this case, human neuron is way more complicated than what this neuron does. So like the information processing that happens within one human neuron is way more sophisticated and does way more than like this simple linear plus a little bit on top operation over here. So the comparison between like human neurons, and this artificial neuron that we created here is weak at best. If. The neuron that we have here, as I said, it consists of a linear part and something on top of this. And this something on top of, is called the activation function, which is, it's a one to one, one to one activation function. And this is called the activation function, which is, it's a one to one function. So it is, it's a function that takes one input and produces one output. And in this case, we use the maximum of the input and zero. And say, okay, this is the, that's what this function G should output. And this particular active activation function has a name of its own, it's called the rectified linear. So it's called the rectified linear function. And this particular activation function has a name of its own, it's called the rectified linear function. And this particular activation function has a name of its own, it's called the rectified linear function. And this particular activation function has a name of its own, it's called the rectified linear function. So this particular activation function is Let me get back to this, let me see if I see this. Okay, isn't this a good one? The, what's the muscles inside, it's not. Okay, isn't this a muscle inside? this very very simple predictor might do some okayish job for predicting the house price but we actually probably want to do better and to do better we need to take in more information so that we the the size of the house is one particular piece of information that we can use but we probably want to use more information and um what we want to do is for example use more inputs like the size of the house number of bedrooms the location where it is the distance to the next public transport and so on so we have more information for each of our data points and we don't want to just use one stack of neurons but do something like have one neuron predict some intermediate feature so for example this neuron should predict not the price but the possible family size that the house could accommodate and it could predict that from the size and the number of bedrooms and this neuron should predict the school quality of the surrounding schools which it should be it might be able to predict from the location or the zip code and it might be and this neuron should predict the commute the commute time for for the inhabitant which it might be able to predict from the zip code and the distance to the nearest public transport this way those neurons derive some create some derived features they calculate something that is not directly in the input but can be computed from the input so we get more refined features and the next neuron will take those more refined features and predict the price of the house of the house from it and that is basically what a deeper a real neural network is we have several layers of neurons each layer computes some more refined features from from its inputs and it gives those to the next layer of of neurons which can use the more refined features to make either the final prediction that we want to have or create even more refined features and those in we do and when using uh building a neural network we usually do not observe those intermediate features we do not they they just get passed to the next layer of neurons we only observe that part of that part here we look at the the output that we are actually interested in we do not look at those those intermediate features and um because we do not look at those we also actually don't care if what the what they actually represent so we don't what what uh in what we will do in reality is we will let the algorithm figure out those intermediate features on its own so um it might turn out that one of those intermediate neurons will do something like predicting the possible family size because it's a useful intermediate feature but we do not force the algorithm to do exactly that we will let the algorithm figure out its own how what what might be a useful intermediate feature to make a better prediction for the price and then it will kind of train those neurons to predict that intermediate feature so that this neuron can has an easier job doing the price prediction over here so the the job of this neuron is basically figure out some intermediate property of the data you have here so that this neuron has an easier job to predict the price and so that's what we're going to do in the next slide so if you stack on more layers each layer has basically the job of make the job of the following layer easier and predict some figure out some property that might make the job for the next layer somehow easier and our training algorithm will later on figure out what the useful intermediate features will be so also in this case we said okay this neuron predicts the possible family size from the size of the house and the number of bedrooms because we do not know what the final features will be we usually do not put any limits on what kind of input which neuron can use but say okay you can use any of those inputs to make your prediction and you figure out which input is important and how important which input is so it might figure out that it doesn't need those and puts a weight of zero on this edge and that's the end of the project so we can see that the neuron doesn't use the zip code but it's up to the neuron to figure out what what feed input features it wants to use and what which not and we call this architecture being fully connected so every input from the last layer will be connected to each of the inputs of the next layer so each output from this layer is connected to each input of this layer and so on so the neural network does is each layer outputs a new more abstract features so the feed which will make the job for the next layer easier so and during training the algorithm decides what features are most useful so the algorithm will decide what what what it wants to learn to make the final prediction as good as it can as it can so and if you um what kind of applications can be built from this kind of abstract a general concept so in our case we had like several input features like house size zip code distance to uh to the next public transport and so on and we had one output variable which we want to predict for example in our small real estate application but we can have other applications so what we can for example do is we have as an input like an advertisement and a user's cookie history and as an output we want to have did the user click on the ad or not which is kind of one of the earliest use cases for big data where people where marketing internet marketing companies started to use those massive amounts of cookie history data from users to create more targeted ads which are haunting the internet ever since um other things can be the input our input can be some kind of image and the output can be what object or objects are in the image so like you want to take a photo or we want to find out if there is a cat on the image or not our input can be some audio data and our output could be something like the text transcript of the audio and we want to kind of do speed recognition on some audio data you could do something like machine translation where we have an an english sentence as an input and want a chinese sentence as an output uh we could have a lot of very very different inputs like like image data from different cameras some radar or leader information and we want to output the position of other cars and our position relative to them for like an autonomous driving applications okay application so when thinking about how to use deep learning for something we need to think about in in in this kind of abstract way what is kind of the input data that we have what is does this does the at any point in time what data does the algorithm have access to and what should be the prediction that the algorithm has to do so what is what is it that the algorithm should produce when it sees something and in some cases that is kind of pretty obvious but for example if you think in in some cases it it's a little bit surprising so for example with chat gpt the input is i have a text at the up till a certain point and the prediction target is what is the next character in the sentence so and which which is a if you is a which is a pretty surprising thing it is a thing because what when you start to build something like a chatbot you think about okay what i would do what i want is an answer to some certain amount a kind of question or something like that i have a question and i want to generate an answer but um answers are something where we don't have any training data for but the next character is something where we have a lot of training data for and if and surprisingly predicting the next character is uh doesn't give you the entire answer but you if you do it often enough you will get the entire answer so having using this kind of surprising target for that we have here in this case yields an incredibly powerful system at the end and so thinking about okay what what what will our our algorithm get and what should it output and do i have enough data for exactly this kind of combination so i i can think of a lot of things that i would want to have to want to have a prediction but where i don't have enough data for um and then so we kind of have to Do we have enough audios with text transcriptions at the end so that we can create our speech recognition system? It's kind of the important thing to think about when starting some projects. What exactly will be our input? What exactly will be the output that our algorithm has to predict at the end? And how do we get enough data of those input-output pairs so that the algorithm can train on that? When we go through those examples, the first two of them are very, very simple ones. So it's kind of very structured data. So the cookie history will be probably a list of different websites that the user visited. And we have a binary output. And this is just a number as an output. So we have very structured data and do some predictions on this. And this is kind of a use case for classical, fully connected neural networks that one can use for this. Or it doesn't even have to be a neural network. It could be also a use case for very, very classical machine learning algorithms, like just some kind of regression problem. When we look at other of those examples, it gets more difficult. It's difficult to think about what exactly those inputs and outputs are. So for an image, an image is not just... It's a way more complicated structure. So you have basically a matrix of pixel values. For each pixel, you get the value of a red value, a green value, a blue value. Which... Which... Which form the entire image. And images can be different sizes. Some images are larger, some are smaller. So they are not constant in size. So it's much, much harder to handle those. And for those kind of applications, we will learn about different architectures of neural networks that can handle those kind of more complicated inputs. Same way, a similar way. If you think about audio data, you get kind of a stream of... Audio signals. And if you want to have a text transcription that is also not like a binary output or like just one number. It's kind of, again, a stream of characters that you want to translate audio into. And again, we will look at... See about how several tricks that can be used to deal with like those more complicated structures of inputs. So these... This for example. This for example. Is kind of the classical use case for convolutional neural networks. Those will be the classical use cases for recurrent neural networks that can deal with sequences of information. And something like this might even need something very, very custom where you have like a very, very diverse amount of inputs. So if you do autonomous driving, you have kind of image input. But you have also image input over time. Because like the... The... The... The images... It doesn't just matter where... What you see on those images and on your sensors right now. But also what you saw like within the last 10 minutes. Because you might... Even if you don't see a certain car in any image at the moment, it might still be around you. And you might have to make an estimation of where it might possibly be. And so something like this might require a very custom and very specialized architecture. So if you... If you... If you think about, for example, image classification. So what we want to... What we get as an input is some kind of image. And what we want to produce is some kind of output. Is this a cat or is this not a cat? And... So we basically have a binary output. One or zero. And as an input, we have kind of a lot of pixel values. More of them later. But as before, we have like two inputs, X and outputs, Y. And the input notation that we want to use is we will say that our inputs are called X. And they are vectors in an N-dimensional space. So we have like... An input vector. So... And this one would be a one, two, three, four, five, six... Dimensional input vector. The label, or what we want to predict, is a variable that we call Y. And in this case, it's a binary one. So it's either zero or one. And we will call the tuple X and Y a single training example. So if we have like one piece of input data and the corresponding label, that is one piece of data that we can train our algorithm on. So... And we don't need just one example to train on. We need a lot of those. So we will need an entire set of training examples. And... We call this D-train. So our training data set will be a set of M examples, or M train examples. Each being a tuple of one input feature vector and the training label. So... And this number M is the number of training data that we... That we can use. Something else that we will later use is the number of test examples. So we will use a sec... Later, we will use a second data set, which we call D-test. Which also contains a number of examples that we will use for testing our algorithm. And that... We'll talk about this later again. But this will be an important thing. We should never build some kind of machine learning system. And then just use it without ever checking how good it does on data that it has not seen before. So the test data... The idea of the test data is basically that we use some data that is not part of the training data. That we can use to evaluate how well does our algorithm do. If it sees new information that it has not seen beforehand. And... Which is why we kind of need to withhold this information. There are some exceptions to this. If you, for example, train something like... A... A language model like ChatGPT on... 20 terabytes of data. And the amount of data that you have is so enormous... That your algorithm... During training will see each input example at most once. Then probably you will not need a testing data set anymore. Because the amount of data that you... The... Of data is humongous anyway. And you can just use the data that you trained on also for testing. Because it doesn't matter anymore. But on the other hand... Taking something out of such a big data set also doesn't matter anymore. So if you have that much data... Then kind of the... The rules change a little bit. When doing any kind of calculations here... We try to use... To do as much as we possibly can... Using vector calculations. So if you have ever worked with MacLab... Or with NumPy and Python, for example... Using... If you calculate anything in some kind of loop... If you write a for loop for the first value... And I multiply it with the first value in the other vector... And do that again and again and again... You will get incredibly slow code. Because the Python code part of this code is incredibly slow. And MacLab is also a pretty slow scripting language on its own. So you get pretty slow code if you... If you write anything... Write anything in loops. If you want to have fast code in Python... You need to vectorize things and use some kind of... A library like NumPy... That does vectorized operations and... Kind of... Turn your loops into vector operations. So... And to do that... We need to kind of... To make sure that we don't... Don't do too many mistakes this way. So... One thing we will do is... If we have like all of this training data that we have here... We can basically... Each of those vectors here... Is one column... Is... Each of our training examples is one input vector of information. And what we can do is... We can write a matrix... Containing all those input vectors here. So we get like the first input vector... The second input vector... The third... The last input vector... And... Write them into one large matrix... Which will be then an... N... Times M matrix... So N being the number of input features... So... How many inputs did we have here? So where... Like one input feature might be something like... House size... Zip code... Zip code... Distance to public transport... Number of bedrooms... And so on... And this is the first house... The second house... And the last house that we have... And... This way we get like one big matrix with all the input data. And this... We can do the same thing for our output in this case... So we can say... Okay... I'll have like the first output... The second output... And so on... And put that into one... Big... Yeah... This is one big matrix... And then... This is one by M matrix... So we kind of just have one entry in this direction... But otherwise it's kind of... It's stacked in the very same way than this vector was... And this way... And... Now when we do some calculations... We can do them for... Not just for one of the examples... But we can do them for all the examples that we have at once... Because we can kind of just multiply things with this matrix... And this way we can... We avoid doing a loop over all the training examples... But we can kind of multiply... We'll later multiply this vector with something else... And this way get kind of the benefit of avoiding some kind of loop over all the training examples... And this will be... Doing this consistently as often as we can... Will turn into a lot of performance benefits... And make the difference... Between something that actually works on... Actually works on something that is so slow... That you will never see the results of it... At least till the term ends... So... If we think... If we say... Okay we want to turn... We say we have some input features here... The question is... How do we turn things into input features? So this is kind of... We say we want to have one... One... Long vector... Of information here... And we want... Which we take as our input... If we start with... Our... The image of our cat here... How can we turn that into... One long feature vector? So if we start with this image here... So I've turned this into grayscale now... To simplify things... We get... 545... 54 by 564... 647 pixels... So that is kind of... Kind of the dimensions of this image... So it's... It's... 500... 500... 545 pixels wide and... 567 pixels high... And each pixel... Is a value between 0... And 255... So that's kind of the... You usually reserve one byte... For each pixel... For each color channel... So... Having... Which means we get this number between... 0 and 255 for each pixel... And... So... We can say... We can turn this image... Into this matrix here... Which has kind of the pixel values... At each position... So... And this is... This is the number... So... One always has to be careful with images and matrices... Because matrices... Usually take a lot of space... Usually take the row as the first index... And then the column as the next one... And if you talk about images... Then most image libraries... Take the width as the first index... And the height as the second index... And that is... Common source for a lot of bugs... Because that's... It's easy to mix those things up... And it's pretty annoying that... We have different kind of conventions there... But yeah... This way we can... We can turn our image into a... We can turn our image into... Into a matrix this way... And... Making sure that we don't mess up... The height and width... Otherwise we... Wouldn't matter too much in this case... Because we just get a catch... Which is flipped over... And... And this way we can... We have turned our input... Into one large matrix of information... If we have a color image... Image... We usually have three input channels... So we have like a blue channel... A green channel... A red channel... And each of them... Has its own matrix basically... So we get... Not one matrix... But... Three matrices... So we... Suddenly our information is kind of... What were the numbers here... Five... Five six seven... Five six seven... By... Five five four... Five five four... By... Three... So we have like... Three dimensional object here... Where we have... A list of matrices... And... Each of them has... Has... One... Each entry contains... One pixel information... For one of the color channels... Sometimes we even... Have a fourth channel... Which contains... So called alpha information... Which is kind of... How... How to... How to... How to... How to... How to... How to... How to... How transparent is the image... At that pixel... Which is for example... I think... GIFs have this information... And PNGs also... Where you... Can have like a... Transparent image as well... So you get a... Like a transparency channel as well... So you can also have four channels over here... The simplest way to turn all this... Into... Like a feature vector is... By just stacking those matrices... So we can just say... Okay I'll stack all this information... So I'll just say... Okay I'll take like... The first pixel up here... And it ends up here in a long... In a very very very long vector... And I'll just write... This way... I write all the values... From all the pixels down... Into one... One... Very very long vector... And... In this case... I get... A resulting big... Vector... Which has... 900... Almost a million dimensions... But we... There's a lot... But we... Suddenly we have turned... Our entire image... Into... A... A... A... A... A... Our entire image... Into one... Into a one dimensional... Into... Into a... One dimensional object... So into a one long vector... With... Yeah... So... With a lot of entries... So... And... Every image... A problem here is... Every image has different dimensions... So... Kind of... This... The... By... By the number of color channels... Might be... The same for all our input images... The... The height and the width... Might be the... Different for each image... So... The resulting vector... Might be different as well... As well... So the simplest way to... Kind of solve this... Is use some image modification software... And rescale every image... To have the same width and height... So... And... Make sure that all of them are... Are the same... Question is how... How large should we make this? And the answer to this is usually... Just large enough that... You as a human could classify it... So if you can identify... What is on the image... Then... You can... You can... You can... You can... You can... You can... You can... You can... You can... Identify what is on the image... Then... We can assume the algorithm... Should be able to do that as well... So if we... Turn the... Turn the... Our cat image... Into this size... Then... That's... Probably still enough... For you to identify the cat there... So probably for our cat classification... That might be still enough... So... With 64 by 64... And color... We get... 12,288 features... And if we can... Get away without colors... We can turn it into... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... A... This kind of preprocessing... Will also be... A big part of... What needs to be done... To make... To... To get actual... Deep learning systems to work... Because... Figuring out... What is the minimum... Amount of data... That we can get away with... Means... If we... than if we leave everything at the highest resolution. But this would also make it more difficult for the recognition to work, right? Like for me as a human, it is harder to . So, the algorithm has one advantage. It kind of, it sees every pixel in the same size than otherwise, so it's kind of, but it's true that if you scale it down too much, then it will get harder for the algorithm and the performance will drop. If you make it too large, the performance will also drop because for other reasons, we will cover those later, but if you get too many input dimensions, then the algorithm gets also a harder job at making a proper prediction. And we will get to see, other ways to work around those problems again, but it's often trying to find a sweet spot. So, you usually have several constraints. The quality that you want to achieve at the end is one of those, but also kind of the compute power that you can invest in there and the time you have and the result of the number of input images that you can use for training. And all those kind of determine what kind of size you can get away with here. So, if you have too little images, you can get away with a lot of the size. So, if you have too little images, you also need to scale it down because otherwise, you will run into problems that are called overfitting and then the problem, your algorithm won't work well. And it's usually a very fine trade-off and there is no silver bullet there. So, you will need to do experiments and see, okay, if I scale it down even further, does it improve or does it get worse? Or if I scale it up a little bit, does it get better or does it get worse? And, it highly depends on the application of what is the right approach here. But yeah, making it smaller will make it more difficult at some point, but it will kind of resolve other issues that you could have and so making it smaller will help you up to a certain point and then it gets worse again. So, I think I'll stop here for today. So, we covered quite a bit of basics, how to turn data into vectors and everything we will do will be, we will process vectors here. So, any kind of deep learning algorithm sees ever is a vector of inputs or maybe it's like several vectors of inputs, but everything will be numbers. So, one of the things we will always need to do is figure out how to turn things into numbers. Which has a lot of interesting facets as well. For images, it's almost easy, but for texts, for example, and words, this can get also a pretty, there's also pretty interesting answers of how we can turn words into numbers so that an algorithm can work well with those. Do you have any more questions till now? Yeah? So, will we have a written exam at the end? It will be a written exam at the end, yeah. So, I'll upload, I also upload the first exercise sheet today, so into OLAT, so there will be like a very, first exercise sheet which is all, the only introduction into NumPy and Python and so on. So, it's not, nothing real deep learning so far. So, we'll start with those then, with the next exercise sheet next week. And will the exam be sent on the computer or will it be? No, it will be written. So, the exam will not have any parts where you need to write code. There might be parts where there's some code and you need to identify what's wrong with it or something like that. So, but you don't, will not be required to write code in the exam. So, it's, in some way, I realize that it's not the end of the exam, but it's the end of the exam. So, it's, in some way, I realize that it's not the end of the exam. So, it's not the end of the exam. I see. Okay. So, the, the adventure is that we have theateur,thauteur application. And I have no idea what is about that. So, it's, the, the, the, the only one that I know about is that, the, the, the, right.monary examination that I'm, I'm trained, like, and, and they, the end would be at a National Bus Committee, in Stirrناん pronounced style-C, only for a test practice. So, so I saw, there are some looks of unity. So, heでattan workshopang- How about this? Do you have any practice I'm not interested, maybe, Yeah? Can you bring our laptops next time? The Wednesday part, it doesn't really matter because that will be more me doing, showing you something, but for the exercise, it's probably a good idea if you have the ability to follow along and even just typing something, even if you're just typing something off and trying it on your own, it's sometimes helpful to figure out how things work. Okay, any more questions? No. So then, then see you next Friday.\n",
      " Okay, last week we talked about machine learning systems and that one of the first things we need to do is we need to make sure that we can feed those with data in form of simple vectors. There are several ideas how we can turn stuff into vectors. For example, if we say we have some kind of color image, we can interpret that as having three matrices, each having the same size and dimensions, and one matrix is for each of the color channels. We have three channels. We have three colors. Each of them is an M by N matrix. So in total, we have some object that is M by N by three. And this object can be turned into one long vector by just stacking those matrices. So we can kind of, in NumPy, this would be taking this M by N by three object and just call reshape on that and just turn everything into one long vector. And this way we kind of get one vector with all the input data for this one image. So later when we talk more about images, we will see other ways how to properly deal with picture data. But for now, this is kind of the way how we can do that. So I think that's it. Thank you. We hope that if you found this useful, I hope you feel able to do so. I know a lot of people like to use the 해서 that we, I know people are very vaporized a little bit as we come into today's discussion. make sure that we rescale the image. So one thing is that each of the images has like different dimensions. So these numbers change from image to image. So this is kind of a problem. And another problem is that we might want to make sure that we don't have to deal with a million dimensions over here. So one thing we want to do with images is often to rescale them. And like a rule of thumb is to make sure that we rescale it so that it's just large enough that we can classify it. So in this case, for example, a 64 by 64 image might do the trick. So it's big enough that we can still see the cat inside. So classifying a cat should still work. So for the final algorithm, something like 64 by 64 might be the right number. And if we start experimenting at this point, we can then start experimenting. And see, OK, maybe it should be 128 by 128. Or maybe it should be 32 by 32. And we can kind of start experimenting from here and see if the performance of the algorithm will improve in any of those directions. On this, again, later. So probably we can also remove the color channel and just make everything grayscale. So that also kind of reduces the dimension we have over here. So this is kind of pre-processing our input. So we don't kind of pre-process the input just for the sake of turning everything into a vector. What we wanted to have in the end is make some kind of prediction on the input data. And one thing to start with, we want to start with a classification task. So that was unfortunate. So if we want to do classification, what does that mean? So what it means is we have a binary output. In our case, the picture is a cat, or it's not a cat. And if we have a binary output, one thing that we want to predict is the chance that, OK, we have a binary output. And we want to predict the chance that, OK, we have a cat. The image is actually a cat or not. So what we want to predict is, so ultimately, we want to predict it is a cat, yes or no. So we have a binary output. But we have an intermediate goal here. We want to predict the probability that the image is the target class, so in this case, a cat or it's not a cat, given the input bed, which is the cat. OK. So we have. So this is kind of the probability notation here. So it's probably you've seen that in some kind of statistics class beforehand. So we say, OK, probability of some random variable given another random variable. So it tells us, given we already observed something of the world, we want to give the probability of this random variable. If we would remove this one, it would basically say, what is the probability that any kind of image is an image of a cat? So that would be kind of, we take how many images are there in the world and how many of those are images of cats. So this would be kind of the probability that some random image is an image of a cat. That is not that interesting. So in our case, we always deal with those conditional probabilities that we say, we have some information about the world. In this case. In this case, the features that we observe. And we want to know, given the features that we have seen, what do we think is the probability of this random variable, which is the class that we want to predict at the end. So what we want to build is a machine that will give us or approximate this probability over here. We want to know what is the probability of, what is this probability over here. And this probability interpretation has some huge advantages in a lot of cases. So in the case with the cat image, you might say, OK, this is not something that has something to do with probabilities. Because it's either a cat or it's not a cat. So there's no probability in here. But in other cases, there is actual probability. So if you think about, for example, I want to classify, I have a patient. And I know the patient's blood pressure, age, some cholesterol level, and so on. And what I want to predict is, will this person have a bad COVID-19 . And in this case, even given the very same input features, two patients with the same blood pressure, same age, same cholesterol level, and so on, one might have a good outcome. The other might have a bad outcome. So even if all the input features are exactly the same, one patient might be good. The other might. The other might have a bad outcome. And this means there's a lot of tasks where only having those input features might not be enough to completely distinguish between those classes. And in this case, you actually have a probabilistic outcome. So you might say something like, given this blood pressure, this age, and so on, you have a 90% chance that you might, that you will be fine given your COVID-19 infection. So you kind of have a, so 90% of the patients with exactly this, who look exactly the same, will have this outcome over here. So in several cases, the probabilistic interpretation here is the only thing that makes sense because you might not have, you might not have enough information to really know if somebody will have a good or a bad outcome. And the information that you have might only give you like a statistical information. And that's why we, when dealing with machine learning systems, we always work with this statistical information and always say, okay, what we want to predict is a probability. It's a probability that there is a cat in the image given those are the pigs, and then the other one is a cat. What are the pixel values? And a good classifier should have a very high confidence over here. So given some, something here, the pretty good classifier should give you a very, very high probability over here. Because it's kind of, the task is something where, if there is a cat in there, it should give you a pretty high probability, but it will, what we will get is always some kind of the confidence of the classifier. If it gives you like a 50, like 50% chance, it means the classifier is pretty unsure. And it doesn't really know it. If it has seen a cat, it might be something. There's very famous pictures of where it's hard to distinguish if there's a muffin or a dog in the image. So it might be really hard to distinguish it. And this probability that we want to predict over here will kind of give us the level of confidence that our algorithm has in the prediction. It makes. So that's what we want to have. We want to predict this probability that we, that there is a certain class given those input features. So, and so that's what we want to have. How do we make, how can we make sure that this is what the algorithm will predict? We do that by saying, so at least for, as long as we, we start with logistic regression and the logistic regression formula for this prediction is we take a linear translation of our input features. So we multiply each of the features with some weight at some bias. So this is kind of, this is like one value. If we have 4,000 input features, this would be 4,000 values. So it's a value. So we take a vector that has exactly the same length as our input features. And we take some kind of function of this. And this function is called the sigmoid. So the sigmoid function is defined as one over one plus e to the power of minus whatever we put in here. And so this is how to do it. This is kind of the formula and the way this we, we, we will see in a bit how this looks like. So we, we have this, this sigmoid function of w. These are the learned parameters. And as I said, the learned parameters consist of a bias term b. So which is just one number and a weight vector, which has the same dimension as our input features. So, and all this together. So this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this, this. So we can put this, this, this, this, this thing together. We call hypothesis, hypothesis. So this thing is the hypothesis that we want to learn. So it's kind of, we want to learn a certain function. This function is parameterized by w and b. So there's like two free parameters, a vector and this bias term. And depending on, if we change those values, if we change those values, what happens next? What happens next? So if we put this, this, this, this, this, this, this, this, our prediction will also change. So we can modify those values and get different predictions and every kind of choice that we can take for this vector and this bias term over here will give us a different hypothesis. So that's the building blocks that we need for logistic regression. How does this sigmoid function look over here? So what is this function? This function is basically something that maps every input to a number between 0 and 1. So if we put in a very small number over here, so that means this number gets very big. If this number gets very big, this number gets very big. So everything in the denominator down here gets very large. And if that gets very large, we get in total a very small number. So it approaches 0 over here. And the other way around, if we get an incredibly large, large number over here, then this number gets close to 0. If it gets close to 0, the denominator gets close to 1. And if it's close to 1, we get 1 over 1. So in this direction, the whole thing approaches 1. So the function maps any value over here to something between 0 and 1. And that is kind of a nice property because that is exactly what we want to have if we want to predict a probability. If we want to say the output should be, if there should be some probability, then that should be a number between 0 and 1. So the probability over here, that should be a number between 0 and 1. Having like a probability of more than 100% doesn't make sense. And the probability of less than 0 doesn't make sense either. So making sure that what this hypothesis predicts is always something between 0 and 1 is kind of nice. So that means no matter what values we choose over here, the output will always be a valid probability. So that's already kind of nice. So given this, the next thing that we need to define is how good is the hypothesis. So we can choose any kind of value over here. We can choose any W, any B. And depending on the choice we make over here, we get different probabilities over here. And if we get, different probabilities over here, we get different predictions. So if it's a cat or if it's not a cat. And we have to kind of evaluate how well the prediction is that we make. So given any kind of data that we have, we need to define if we make a good prediction or not. So if we say we have one data point, so one example, one input image, and the target class, so the information if it's a cat or not, what we want to have is that the prediction that we have should be close to the actual class. So the actual class will either be a 1 or a 0. What we output here would be, it can be any number between 1 and 0. So it could be either a very large number, so very large probability, or a very small probability. And what we want to have is that this prediction should be pretty close to the actual value. So that's what we want to have. So for logistic regression, there is a very concrete loss function that we always use. And this loss function is defined like this. And this is called the logistic, logistic loss. And so let's look at what this does. So our target class, y, is either 0 or it is 1. If it's either 0 or 1, if it's 0, this means this part vanishes over here. If it's 1, it means this part vanishes over here, because this part, this thing becomes 0. So it means either we have this part, or this part, or we have this part of the loss function, depending on the value of y. So if we say y is equal to 1, and this part over here vanishes, and it means we take, our loss function will be the logarithm of our prediction. So, logarithm of our prediction. So what is, if we get a large prediction? So how does the log of any function look like? So I don't have made a plot of this. Would have been nice if I had some internet connection right now. So let's see if I can get, so, some plot of the logarithm. So the logarithm of this, the logarithm of this, the logarithm of this, and the logarithm of this, the logarithm of this, the logarithm of this, and the logarithm of this, and this. So, how does the logarithm look like? So the logarithm, so the logarithm, is some function that, getting closer to 0, approaches minus infinity, and then levels off, the closer, the larger the input gets. So, if I take, And if my y hat, so what I predict, is very close to 1, that means if it's close to 1, then the logarithm of my prediction will also be very, very close to 0. So it approaches 0. So my loss, if my target class is 1 and my prediction is very close to 1, then the loss over here, this number, will be very close to 0. So the loss function that I have for this example will be close to 0. If, on the other hand, my prediction is off and I have some number that is very, very small, then that means my logarithm over here is very, very, very close to 1. So it gets close to minus infinity. So it gets closer to minus infinity to the smaller this number over here gets. And that means, so the logarithm over here will be some very small, very negative number. I have a minus over here. So this entire thing will be a large positive number. So the more off I'm here, the larger my loss function over here gets. And I have the same thing the other way around. If I have a very small, if, if my target class is 0, then this thing gets, it gets cancelled out because it's 0 over here. And I have 1 over here. So what I'm looking at is the logarithm of 1 minus my prediction. And if my prediction is also close to 0, then the logarithm over here will be close to 1. And that means it gets, the output will be close to 0 again. And if my prediction is far off, then the logarithm over here gets more and more negative. And my loss function increases again. So that's kind of makes, it makes intuitive sense that this thing penalizes whenever our prediction is the other on the other side than what, what we wanted to predict. So if we have some, some number, some target, and, and, and our prediction is kind of on the, on the other side, then this loss function over here increases. So, and that's, that's exactly what we want. We want to have a function that is larger, the more wrong we are. So the more wrong our predictor is, the larger this number should be. So for linear regression, so there's another form of, of, of machine learning task where we don't, we don't want to, to, to want to learn a binary target. So if we want to learn some kind of real valued number, then, so if we have like our target is some kind of number that is just any kind of number and our prediction is not supposed to be some probability, but we want to predict exactly that value. Then what we often take as a loss function is the square of the difference of the loss function. So if we have like a, a, a, a, a, a, a, a, difference of those. So we take like the difference between our prediction and the actual value and see how far, far off we are and square that. So that means, that means the further away we are, the more it gets penalized. And that's kind of, that, that would be the loss function for linear regression. We won't, we will not be doing that much linear regression tasks in this vector because most things we want to do, I have, I'm, are more or less binary. So we usually want to predict something that is some kind of classification task where we have a binary output that we want to predict. But just so you have heard it, depending on what we want to predict, we might want to choose a different loss function. And for classification, this logistic loss over here is kind of the standard thing to do. And using this loss function has another advantage. And that is this loss over here, which is also called the cross-entropy loss. Using this loss function over here makes sure that... What we have here, the numbers we predict here, can actually be interpreted as probabilities over here. So it makes sure that the numbers we generate are calibrated as proper probabilities. Again, I won't go into the statistical details for this, but it's not like this number is... So if we look... If we look at this formula, it turns out that it's something where being wrong is penalized and being right is not penalized. So it looks like it does the right thing, but the formula doesn't just fall from the heavens, but it's a number that makes sure that, in the end, we will predict numbers for which this property over here holds so that we can actually interpret those numbers as probabilities later on. So, long story short, this is the loss function for a single training example. So we have one data point. If we have a lot of data points, we look at this cost function. So we look at the cost function across our entire training data set. So we take all the training data that we have, sum up the loss function for each of them, and we divide by the average over how many data points we have. So m is equal to the size of the train. And this gives us the so-called training loss, the loss over the entire training set. This number over here, is a little bit arbitrary. It's just a constant factor. It makes sure that if we take twice the amount of data, then the training loss will still stay the same, but it's a number that later on we can also drop, and it doesn't affect anything. But the main point is we want to take the average of the losses of all the training examples over here. So, having defined all those things, the real question is, how do we get the... How do we get the values of these parameters w and b? So that's when we defined our hypothesis at the beginning. We said that the hypothesis kind of depends on those two parameters over here. And we said, okay, the hypothesis is sigmoid of w, the dot product between those two vectors plus b. So having those, what we want to get in the end is, we want to know these parameters, because if we know them, then we know the hypothesis, and then we can make predictions about new data points. So as soon as we have them, those we are happy. And the way to get them is, we want to find w and b, such that our training loss gets minimal. So we want to minimize this function over here. So we want to minimize... The training loss, the loss over all the training data, and we want to choose those parameters such that this loss over here gets minimal. And... When we do logistic regression, there's several ways how to calculate those values. So there's several ways how one could decide on those. For linear regression, there's even analytical ways, how to just calculate them, given the training data that we have. In our case, we want to use some technique that will always work, even for something that is not logistic regression, and that will later keep working when we do larger neural networks, and that is gradient descent. So if we think about this function here, j, the loss function is a function that depends on, the parameters we put in here. So if we change those parameters, if we change w and b, then we change our hypothesis, and if we change the hypothesis, we change the training loss. So the training loss is mainly a function that depends on the parameters w and b. And if we want to minimize it, we look at the point where this function gets minimal, and if we think about, for example, if this would be w and this would be b, so in just two dimensions, then this would be our training loss. And what we kind of look for is, we look at the surface of our training loss and we, whenever, if we start with some values for w and b, we want to say, okay, let's see if there is a direction in which the training loss decreases, and then we want to make a step into that direction and say, hey, that's a Nice, that's a Nice, that's a Nice, here it is, and it's safe to time here step into the direction in which the training loss decreases and see okay we get get get a new new values for w and b and then we want to look again in which direction does the training loss decrease now and then we do another small step into that direction until we find a point where we can the the training loss does not decrease any further so and this technique will that will keep working even even in for for more complicated hypothesis so in this case our hypothesis is pretty simple but the gradient descent approach where we say okay always do a very small step into the direction in which the the training loss decreases will hold for for many many other uh uh uh uh hypothesis later on so what is the direction in which the uh the the hypothesis the the training loss decreases the most the direction in which something decreases the most is the gradient with respect to the parameters so what we want gradient descent means we will repeatedly do so you'll obviously guess that we are losing some things because the previous number of parameters has superimposed on the applauding you even the current number of parameters same thing happens so you will see that many of the predecessors once you take the parameters that gives you aID that is unique our training loss is not an area of d and there is this 1984 model four m又 arteen we take our parameters and subtract from those parameters the gradient of our t raining laws at the current point in fueronert our target so if we choose the learning rate too large then we will just for example if we for example in this point we might make a step that is too large into this direction and then we get off at a point where we are worse than we were before so kind of the the learning rate is something that makes makes the algorithm more stable more on this again later let's look at this thing first so what is the gradient the gradient is the uh the the generalization of the derivative so if you had if you remember your analysis classes from from from back in the day then probably you still remember the gradient in some way so if you have the derivative of some function um then so if you have f of x is equal to x to the square then you might remember that the derivative of it might will be 2x and this works all nicely as long as you have only one input variable if you have multiple input variables and in our case we have like potentially a few thousand input variables you need to generalize this derivative and what we want will do is we take the partial derivative into the direction of each of those input variables and for each of the input variables get like one entry in the gradient that gives us how much the function changes in that input direction. To make this more concrete, I'll take an example. So I have a function that has two inputs and one output, and the input and the function itself will be x1 times x2 squared. So the gradient will be, I first take the derivative in the direction of x1. If I take the derivative in the direction of x1, this is a constant term. So what I get is this part vanishes, so it will be x2 squared. If I take the derivative in the direction of x2, this is a constant term in this case. So I the derivative will be 2x2 times this term over here, so it will be 2x1x2. So the derivative is kind of this vector over here that in each dimension tells us how much the function changes if we make a small step in the corresponding input dimension. So for example, if I'm at the point 3, 2, it tells me if I do a small step in the corresponding input dimension, I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So I'll get a constant term. So if I do a small step in the first dimension, so if I, for example, look at F3.1, 2, then the output will change roughly by 0.4. That's kind of what the derivative tells me. So if I make a step in size of 0.1 into this direction, of the first dimension, then my function will increase by 0.1 times 4, roughly. And the same way, if I look at F3, 2.1, then I know that my function will change roughly by 1.2. So that's kind of what the derivative tells us. So putting all this together, for each dimension, the gradient tells us the slope in that direction. So we could also say, OK, I have a multidimensional function. So it could be several directions. So I'm very bad at drawing something multidimensional. And the gradient kind of tells us, if I take a cutout of this multidimensional function in one direction, then it tells us the slope on this plane that we are focusing on at the moment. So for each dimension, it tells us how much the function changes if we do a little step into that direction. The gradient in total. So if I'm at this point, then this is a vector in the direction in which the function increases the most. So if I want to increase it, so if my point is 3, 2, then I want to make a step into the direction 4, 12. So it's probably a small step. So times 0.01 to increase the function value. So that it increases the most is kind of the reason why, back here, we have this minus sign over here. So this is the direction. So this is the direction in which our loss function increases the most. So we do a small step in the opposite direction. So that we have, like, this is the direction in which it increases the most. And minus the gradient is, conversely, the direction in which it decreases the most. And as we want to decrease the loss function at the end, we do a small step in the opposite direction of the gradient. So this is kind of, that's the motivation. Why? At each iteration, we do a small step into the opposite direction of the gradient because that is the direction in which the function decreases the most. Another example. So if we, the entire gradient is the gradient in each input dimension. So we look at each of the inputs of our function. And for each input here. We get an entry in the gradient. We can also take the gradient just for certain inputs. So we can say, okay, I have, like, a function with a lot of parameters. And I only take the gradient for a few of them. And for each of the directions that I take over here, I get a parameter over here. That will come in handy later that we can take the gradient for just the subset of the parameters. And this is kind of a selection of the entire gradient. So we just select a few parameters, a few parts of those. Kind of like in Python that we take slices of lists. So let's make the example a little more concrete. So let's assume we have, like, this loss function over here. So which would be squared loss, like, in linear regression. So we take, have one parameter. And the parameter minus two squared. Will be the loss at the end. So if we start. So what is the partial derivative? So we, in this case, we only have one dimension. So, like, we only have to look at this derivative over here. So the derivative of the whole thing will be two times W minus two. So it's, like, inner derivative times outer derivative. The inner is just one. So it's. We are left. We are left with this part of the derivative. And let's start at point W equals zero. So let's. If we start over here. The function value that we have will be four. So zero minus two squared is four. And the derivative is minus four. So if we put in zero over here, we have two times minus two will be minus four. And minus four means. The slope. Of the function of our loss function over here. Is minus four. So the slope over here. Of the tangent. At this point is minus four. The derivatives. Points in this direction. Minus four. It points into this direction. It tells us to. If we want to increase the loss function. We have to go this way. So what we will do is. We go the other way around. And say we could make a small step. So learning rate. Small step. Into the other direction. Going this way. And this way we will turn out. Get a new point over here. Get a new slope over here. Make a new update. And this way slowly get closer to. The point where. Our derivative gets zero. And we have like the smallest value for our loss function over here. So. In our case. We have like two parameters. The full update step that we have. Is we do the same thing for all the parameters that we have. So we have like. In our case we have like two variables. One is a vector. The other is just a single value. And. What we basically do is. For each of the parameters we make a small step. Into the direction of the. Into the opposite direction of the derivative. With respect to those parameters. So that's. That's where the. Notation comes in handy. That we can just select a few. A subset of the parameters over here. If we get more parameters. We will kind of do the same thing for. For other parameters. So it will be always. The same thing that we do for each of the parameters. We will always keep doing this. That we. Look at the derivative in the direction of those parameters. And do a small step into the opposite direction. So. One thing we haven't talked about a lot yet. This learning rate. Rate eta over here. The learning rate. Determines how stable. Our. The convergence of this algorithm is. So. If we. For example take a very large learning rate. So if this number is very high. We might make a long. A big step into this direction. And might end up at a point. Which where we are. Further away from the optimum over here. Than we were before. So. Having a large learning rate. Means we might make. We will do larger steps. And we might reach the optimum faster. But we might also have points. Where we run away from the optimum. And. Making everything less stable. If we use a very small learning rate. Convergence will be more stable. So we usually. We will usually not overshoot the optimum. But. It might make everything slower. So we will need more iterations. And. It's sometimes. There is no golden bullet. For this number over here. So there is not. The dependence of. Whenever you train some kind of. Machine learning algorithm. The learning rate will usually be something. That you need to calibrate for your use case. So. It's usually something that you start with. 0.01 or 0.001. Some number like this. And then you will see. Okay. It doesn't converge at all. So you need to make this number smaller. Or that you realize. Okay. It's going to small. So you start to increase the number over here. And you'll have to do a little bit of fine tuning. And calibration to get a number here. That gives you a good. Good training progress. And. Without your algorithm. Getting unstable. All in all. I would say it's better to have. A learning rate. Which is slightly too small. So you shouldn't do it. Shouldn't make it incredibly small. So. Because then you. It will take ages for your training algorithm. To converge. But if you. But it's usually better to be. A little bit on the safe side. And. Use a smaller number over here. So that. You don't waste a lot of time. Waiting. And. Just to see that. At the end. Everything works out. But at the very end. Stuff starts to diverge. So it's better to pay with a little bit more waiting time. And having a smaller. Smaller learning rate over here. So. That you have a little bit more stability. And training. So. Now. Now that we have those parts. So we. Have kind of the basic. Set up for the algorithm. And. We need to determine this formula over here. So. The. This gradient over here. We know that. It's. It's defined as. Being the partial derivatives. In each of the directions. That we have as inputs. But we now need to. Determine how we can compute this derivative. Over here. So we need to. In. In this case. Was easy. We kind of have the analytical formula. For the derivative. And can say. Okay. This is. Depending on. Where we are at the moment. We can. Determine. Which. What the derivative is. At this point. And this way. Determine the direction. That we want to go. But in general. This might be. A pretty complicated function. Over here. So. In our case. That we. In the logistic regression case. We already have. That. We take. This. Cross entropy loss. So we have. Like for. One single training example. We have. Y. Times. The. Logarithm. Of. So. And. Here we have. The sigma. Sigma. Of. So the sigmoid function. Of. W. Transposed. X. Plus B. And so. This would be. Like what we predict. And. Then again. Plus. One. Minus. Y. Times. The logarithm. Of. One. Minus. The sigmoid. Of. W. W. Transposed. X. Plus. B. And so on. So. And. This. And. And. This. This is just for logistic regression. Where this function. Is still a very simple one. So. Having. Putting all this together. For. For. For. For this thing. We can still calculate. The derivative. By hand. And get kind of a good. Nice formula for this. But if. If we. Start making this. Number. In here. So our. If we. Start making the. Prediction over here. More complicated. We need some. Automatic way. To do the different. Differentiation. Over here. And. The way to do this. Is. We define. All the computations. That we. Do here. In the form. Of a compute graph. What is the compute graph? A compute graph. Is a directed. A cyclic. Graph. Where every node. Represents. A mathematical operation. So. For example. A node. Could be something. Like. Addition. Where we say. Okay. We have two inputs. A and B. One output. C. And. For each. Of the incoming. Parts. We know the derivative. Derivative. In this direction. So we know. The derivative. In the direction. Of A. Which for addition. Is just one. And the. Derivative. In the direction. Of C. Of B. Which is also. Just one. So. The derivative. Into. In those directions. Just as a reminder. It's. It's kind of. The rate of change. In that direction. And. One can. Kind of. Imagine. It this way. So if I have. Like. A plus B. And I. Add a little. Epsilon. In this direction. In the direction. Of A. Then. C. Will also be. One epsilon. Larger. So. The. Which is. Kind of. The reason. Why. The derivative. In the direction. Of A. Will be one. And the same. Goes for. Derivative. In the direction. Of B. And we can. Do. Now do that. With all. The simple. Mathematical. Operations. That we need. So we can do that. For multiplication. And say. If I have. Like. A node. That is. A multiplication. I can say. Okay. I have an input. A. And an input. B. And the derivative. In the direction. Of A. Is B. And the derivative. In the direction. Of B. Is A. So I have. Like. My. My. My. Operation. Is A. Times B. And if I change. A. A little bit. Then the output. Will change. By. A little B. And if I change. B. By. Some. Like. A small number. Then. The output. Will change. By A. Times. The small number. So that's kind of. The derivatives. Into. Into. Into. Those directions. And multiplication. Is kind of. One of the main. Operations. For which. The derivative. We will need. The derivative. So. It's kind of. Nice to repeat. Again. That. Kind of. The. In the direction. Of A. The derivative. Is just B. And in the direction. Of B. The derivative. Is. Just A. So it's the. It's always like. The value. On the other side. That determines. The. Derivative. On. On. On the other side. So. We can. Now do that. For all. The. Mathematical. Building blocks. That we might need. Subtraction. So if we. Like. Do A. Minus B. We have. Like. Minus one. For. The derivative. Of B. If we. Square things up. We can. Define the derivative. Of that function. So it's. Kind of. It's a single. Input function. So we have. Just one. Input. And. It's like. Two A. Will be the. Derivative. If we. For A. Squared. If. We. Have. Some function. Like. Rectified. Rectified. Linear. Which. Is. A function. That. Is linear. As long as. The input. Is. Positive. And after that. It's. Just zero. So the. If we have. A function. Like this. The derivative. Will be. One. If. The input. Is bigger than zero. And zero. Otherwise. So this thing. Here is notation. For. An. Indicated. One. So. If. The. One. It. Will be. One. As long as. This condition. Is true. And otherwise. It will be zero. So. It's. One. If. A. Is greater than zero. And otherwise. The. The. The. Derivative. Over here. Will just be zero. We can take the. If we have. For example. A maximum. Function. So it. Is something. That takes the maximum. Of A. And B. We can. We again. Can take the derivatives. Over here. So we have. Like. In the direction of A. If. A. Is bigger than B. Then the derivative. Is one. In the direction of A. So. Increasing A. Makes the maximum. Larger. As long as. A. Already is the maximum. If it's not the maximum. Then. The. Derivative. Here. Will be zero. And. Nothing changes. If I change A. And. The same goes. For. For the input B. If I. If B. Is. Larger than A. Then B. Is already the maximum. And. If I change B. Then. Also the maximum changes. But if B. Is smaller than A. Then. The derivative here. Will be zero. Because. Changing B. Doesn't. Affect. The maximum. So. And. We can do that. For. All kinds of. Small. Of primitive. Mathematical operations. And from those. We can. Create complex functions. So I can. Like. Create. A. Compute graph. Where. I say. For example. I have a function. That is. A. Times B. And. The result. Will be squared. And. If I do that. I can say. Okay. This will be. This compute graph. Over here. I. Multiply B. And A. Get an intermediate results. That I call C. Then I will take. C squared. And get a result. Which is D. So. And. How do I. Calculate the derivative. Over here. And the way to do that is. So I want to. Calculate the derivative. Of. The final output. So. The. I. The. I want to calculate. The derivative. Of. My. Entire function. Of D. Into the direction. Of A. And. The chain rule. Basically says. The derivative. Of D. Into the direction. Of A. Is equal to. The derivative. Of D. Into the direction. Of C. Times. The derivative. Of C. Into the direction. Of A. Of. D. And this. Up. So toanzel those two. Yeah. It kind of. . To. Make it easy to remember. So if you could. Like this. Cleanseed those. The season. Out then we would get. The. sam investments of. It. do is we have a product over here. We have a product of two smaller derivatives. We have like the large derivative over here that we want to have and we divide it into a product of two smaller derivatives where we make a smaller step. So this is like a big step from here till here and we divide it into two parts where we have the derivative of here till here and then we do a step from here till here. So we divide it into two small steps and for each of those smaller steps we basically have the derivative written onto this arc over here. So we have like this arc where in the compute graph and for each of those mathematical operations we kind of know we know the derivative. So the derivative of from here is the derivative of from here and then we divide it into two smaller steps. So we have here till here is we wrote over here so it will be 2c. So if we have c squared the derivative from d to c will be 2c. So let's write this over here and so we know this one and if we look at this one we can say okay the derivative from c to a is just what we wrote over here. So it will be just b over here. So now we have a derivative from c to a and we have kind of the chain rule tells us that this will be the derivative from d into the direction of a and c is basically just the forward computation from going forward over here. So it's basically we can replace c by a times b. So we get this formula over here and if we kind of multiply this out then we get that the derivative from d to a is just what we wrote over here. So we have the whole derivative will be 2 times a times b squared which again if we want if you would like just go from the calculus way of deriving this derivative you would take the inner derivative times the outer derivative and would derive a times b squared 2 times a b squared as the derivative in the direction of b of a for what we have here. So we have a derivative from c to a over here. So what we did over here kind of works. And the nice thing about this is this the algorithm that we used over here that will work for arbitrarily large compute graphs. So no matter how many nodes you have over here you can kind of always do this calculation over here that you split up the entire gradient into all the small steps that you have in between. At each step you know the derivative of this small step over here and at the end you need to calculate all those small derivatives and just multiply all of them and this way you get the entire derivative for all the way up. So kind of putting all this together gives us the back propagation algorithm. And the algorithm is that for each of the compute nodes we define two values the forward value and the back propagation value. So we have the forward value and the back propagation value. So we have the backward value. The forward value is just what you would do if you calculate the result of the compute graph. You put in some value here some value here and just do all the computations through the graph up till the last of the final result. So that's those are the forward values and the backward values will be the gradients coming from the final value and going downwards towards the input values again. So you kind of start multiplying up those gradients from the intermediate nodes. So we kind of start calculating at the leaves to get the forward values and then we start at the root node of the compute graph and calculate the forward values. So we start at the root node of the compute graph and calculate those gradients backwards till we reach the leaf nodes again. So let's do an example for this. If we have a logistic regression then we say our loss function is this one over here for a single example. So if we have like one single example we say the loss this will be the loss we have. y hat is defined as the sigmoid of some value z where this is the sigmoid function and z is defined as some linear operation where we have like a weight for the first input variable a weight for the second input variable and some bias term b. So these three are the input parameters. So if we have those building blocks we need kind of it's a nice thing to say to. To define one node so we can it could say OK these are like several mathematical nodes for several operations but as this is kind of used a lot it makes sense to kind of define the derivative of this function of the entire sigmoid function and make and so we can use that as a single node in our compute graph and say OK. If we have some value z that's the input of our sigmoid function. And. The derivative of the sigmoid function is the sigmoid of z times one minus the sigmoid of z. So if you want. If you feel like it you can try to value it to to to validate that by calculating it by hand but for now I'll just give you the this this result so if I have take the derivative of this. Kind of gets gets I get gets. Like. The. The. This. This value for the for the derivative and the value this value is just that number here so it's kind of the sigmoid of that times one minus the sigmoid of that which. Is kind of it would be this number so if I. If you. If you remember that why hatch so our prediction is just the sigmoid of that so the derivative will be. The prediction that we made. Times one minus the prediction that. We make. So that's that that's that's the derivative term over here. If we look at our loss function so that we. The loss function was this number over here. And again we will create one compute note for this for this function over here so again as this is kind of used a lot it makes sense to kind of. Take. Do those calculations instead of like. To do splitting it up into smaller smaller notes and the derivative of. The cross entropy loss so the cross entropy loss which is this number. It turns out to be this number over here which is minus. What the number that we wanted to predict divided by what we have predicted plus one minus the number that we. Would. The the the actual class. Divided by one minus our predicted class. So. That. Which is the derivative into the direction of y hat. Why don't I write the derivative into the direction of y over here. That is because we never take the derivative into this direction. Why don't we take the derivative into this direction. Because we don't care about. We don't we cannot change this value over here that state that's just a data point we can change what we predict over here we can make a change in what we do predict. We can never change what the data was so we can do the exchange that obviously if we like change the data points but we cannot. The algorithm takes those values over here. As its ground truth and it only it only observes them and uses those to kind of calculate the loss function over here. But we don't need to take the derivative into this direction because we cannot change those values so we only can change the parameters that we have downstream this way so we don't need the derivative into this direction we only take need to go down this way. When calculating derivatives because over here there's no parameter that we can change. So. Let's. Let's go further in our example we have let's assume. That we have a data point. That where x is minus two and three. So that is our input of input features x. Why. It is equal to one. And that is kind of the class that we would have liked to predict for this input example. And let's assume the weights that we currently have. A two and one. And. There should be some value for B as well because. He is kind of also. Something that we need later on. But. So. I really have to work on the formatting of those images here. Make this full screen. So. So. This is our compute graph. We multiply W1. With x1. Multiply W2. With x2. Add those values. Then add the parameter B. The result will be put into the sigmoid function. And the result of that. Will be compared. With our. With the target class. For our loss function. So in this case we only have like one data point. In general we would have again. Some of those loss functions. So we would sum up a lot of loss functions. For a lot of data points. But for now we just skip that part. So it would just mean one more addition up here. So. This is the compute graph that we have. And. These are the derivatives at each of the branches. Into each of those directions through the graph. So let's put in values over here. So. If we have. Those input values over here. And I. B should be. Is 0.5 over here. So if we. Put in. W1 as 2. X1 as minus 2. So W1 as 2. X1 as minus 2. And again. W2 is 1. X2 is 3. B is 0.5. And the target class that we want to predict is 1. So these are kind of the given values that we have at this. At this moment that we want to calculate the gradient. Into this direction. This direction. And this direction. So these are the values that we want to change at some point. At the end. So. We want to adjust them. So we need the gradient into those directions. What do we do? We start with the forward step. So we do. Multiply 2 by minus 2. And get minus 4. 1 by 3 is 3. Minus 4 plus 3 is minus 1. Minus 1 plus 0.5 is minus 0.5. And. The sigmoid of this. Turns out to be 0.37. 378. So. At this point we stop having round numbers. But yeah. That's. That's just. What. If we. Have. A number that is slightly smaller than 0. We also will get. Probability that is slightly smaller than 0.5. If you remember the sigmoid function. So if we have. Like 0 was here. And this would be 0.5. So if we go. Slightly this direction. We will have a probability that will be slightly below 50%. So this is kind of the probability that we predicted. And. Our loss function. Will be. Now be the cross entropy. Between this. And this one. So again. This will not be around number. But it will be something that is. Quite a bit larger than 0. Because we are kind of off from this. So it's. We predicted something smaller than 50%. Even though the actual class is 1. So this should be. Sufficiently large number. So that to reflect this. And the smaller we get over here. The larger this number should be. And. What. We. Need to do now is. Calculate the. Derivatives backward. And how do we do that. We kind of. Just fill in those. Formulas over here. So we go. Go back. Through each of those arcs over here. So we take. We know that. For this formula. We need the values of y. And y hat. So we have all them. We computed them in the forward step. So we kind of fill in. Those numbers over here. And get. This value over here. As the derivative. Of the loss function. Into the direction of. Y hat. So this is the derivative. Into the direction of our loss. Function. Of our prediction. And that basically says us. Tells us. That if we decrease the prediction. Our loss will increase. So makes sense. If we make our prediction even smaller. Then our loss will be even larger. So it also tells us. We should increase. The value that we predicted. To get. A smaller loss at the end. So if we could directly control. The prediction. It would tell us. Please decrease the predicted value. To decrease the loss. That we had at the end. Makes sense so far. Next step. We calculate the derivative. Into this direction. So to get the derivative of. Of. Our predicted value. Into the direction. Of the value that we put into. The sigmoid function. Which we call z over here. And. This will be. So we put in. 0.378. Into this formula over here. So we can get. Get the loss function over here. And this tells us. That if we. Want to. Increase. We should. Increase z. In order to increase y. And. Which again makes sense. And tells us. Kind of also the magnitude. Of how much we would. Should increase that. To increase. Y hat by one point. And we. Kind of keep doing. Doing that now. So we. And at each node. We write the derivative. As we have. As the compute graph. Graph tells us. For the additions. It's incredible. Credit. To the derivative. And we. We. Get the. Durability. And. So. So what. What we. Are able to do. Is compare. The. Final. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. The. and that formatting here is incredibly off. What we need to do now is, we need to, if we want to do the derivative into the direction of w1, we multiply each of those partial derivatives on the entire path from the root node to w1. So it will be this times this times this times this times this. And the same way in the direction of w2 and in the direction of b. So we get the derivative of... There's no way to get this right at this moment. But if I have the derivative, it's a derivative of... If I have the derivative of w, I have this formula over here, which tells us I should decrease w1 to decrease the loss function, and I should increase w2 to decrease the loss function. And in the same way, I should increase the parameter b in order to get a better loss function. So if we think about this, we wanted to have a smaller prediction over here. And... So we wanted to have... In order to get a better prediction over here, we want to have a larger value over here. So increasing b would make this value larger. So it would increase this value over here. So it would increase everything. So it would increase everything up the chain up here. So increasing b would increase this value over here. Increasing w would again... This is a positive value over here, so everything should increase this path. And decreasing w1 would again increase everything up the chain over here. So it kind of makes sense that what the derivative tells us, the gradient tells us, is some way to increase the entire value y-hat over here, which should decrease the loss function. So... And the derivative kind of... It is something that tells us exactly in which direction we should change each of the parameters in order to get close... To get a better loss function at the end. And so it looks... It kind of always... It looks scary, the entire calculations, but it's... It's nice that each step consists of a very simple calculation. So each step along the compute graph is kind of plugging it in something into a formula that you know, and then just multiplying up everything at the end along the entire chain of calculations that we have here. Turns out things will get a lot complicated later on when we do a lot of matrix multiplications, because it kind of... You need to make sure that you remember which dimension, you have to multiply with which to get the right result at the end. But it's always... You always need to remember that the... What you are doing under the hood is just what we did here. So go... One step after the other in a larger compute graph to multiply up the partial derivatives. One thing that one can do quite often is combining those two derivatives, because... Those two derivatives, because... The derivative of the loss func... The cross entropy loss and the sigmoid function, they kind of cancel out nicely. So the derivative of the loss function was this one, and the derivative of the sigmoid was this one. And if you multiply those, you get this times this. And as you can kind of see that you have like this thing over here, and this thing, those match. And so you can kind of... Like multiply everything here with this number over here, and in total get something that is simpler than all the parts over here. So what one kind of often does is kind of combining the sigmoid function and this loss function into like one single node to make the calculations of the derivative a little bit easier, because... If... If... If one just combines them into one node, it gets... You get an easier derivative. It's not strictly necessary, but it's kind of my... Sometimes makes calculations a little easier, because things... If you take this one, you can kind of multiply out everything, and it turns out that putting everything together just yields like y hat minus y. So if... It kind of tells you, if my prediction was too large... If my prediction was too small, then I need to increase the value, and if it was too large, I need to decrease it. So it's just like linear in the direction of my prediction. So... And because we kind of all very, very often have like cross entropy and sigmoid as like some things that we need to use together. When we want to do neural networks, we want to do neural networks. We want to do neural networks. We need to vectorize things, and that's why we... It's useful to use kind of the derivatives of vectorized operations. So if I'd want to take the gradient into the right direction of w, of this dot product between w and x, it's just the vector x. So it's kind of the same way if I have like a single value of w times x, then the derivative, the gradient of this function into the direction of w would be just x. So it's kind of, if we vectorize things, it kind of stays the same. And... When doing any kind of calculations, any kind of like gradient computation, we always want to try to put everything into a vectorized form again. So something like this, and if we have like more dimensions, then it's kind of, we also still want to keep everything in the vector form. Do you have questions so far? So probably that was a lot. So probably that was a lot. So probably that was a lot. So probably that was a lot. So we can now take in... So the first exercises that go into this direction will be a little bit tough for you because it's kind of, you need to go through those... Those kind of, my hint for you is try to make, try to do everything in little steps so it's kind of like we did over here, as long as you do very, very small things, it's actually pretty easy to get the results. If you go and you take it over here, small steps. Everything is kind of simple because if you multiply two things, the derivative into one direction is kind of the value on the opposite side and like additions, the derivative is one. So kind of break, if you do something, try to calculate derivatives for some small neural network, break things up in this way. Draw the compute graph, try to calculate which is multiplied by which, what is the entire compute graph that I deal with over here so that you kind of get comfortable with what's happening over here. Once this clicks, you start to realize that what we do here is actually pretty simple because it's just those, basically what I told you, the derivative always tells you should I increase or decrease the value that I have at the moment over here. So it's kind of this. Okay. Okay. So this number here tells me if I want to increase the loss function, I should decrease the value that I predicted over here. So, and as so, and obviously I want to go into the opposite direction to decrease the loss function. So that's what this number over here tells me. And for going this way, this way up here, the sigmoid kind of tells me if I want to increase the prediction that I made, I should increase whatever this number is that that I put into the sigmoid function. And so if I want to decrease the prediction, I multiply this by this number and thereby get kind of that. If I want to, if I want to increase the entire loss function, what should I do with my value that I should put this one multiplied by this one. So I should. Decrease the value set over here so that my loss function over here changes again. And that goes for the sum over here. It should also be, I multiply those things. So it should also be increased and the product over here should also be in a decreased if I want to increase the loss function and so on. So I, I, I, I, while multiplying up, I always know that at this point I want to increase or decrease. The value. And I also know by how much, so the direction is kind of the, just the sign over here. So it's kind of the easiest thing to argue about, but it also tells me how much compared to all the other values. So how much should I increase or decrease a certain value over at a certain node compared to all the other notes that I have in order to increase the loss function. And at the very end, I just flipped the sign because I want to actually decrease the. The loss function. So that was a lot to take in. And, uh, I, I, uh, I, I hope to be, uh, so at the beginning we will start trying to put neural networks completely from scratch using those things that we had here. So we will go through all those parts, building up the, the, the, the gradients of the single layers that we have to get kind of built a small, small neural networks completely from scratch so that you can build this intuition. Okay. What those gradients do and how those competitive, what happens when we do train a machine learning system and later on, we will, uh, uh, start to push out those, this work to, uh, to, to the frameworks that we want to use and, uh, where the framework does basically manages this compute graph and does those calculations for us. But like the first exercises, we will try to build a complete neural network completely from scratch so that we kind of see what happens under the hood and what the framework later on. Does for us when it, uh, when it comes, when, when we do do kind of auto differentiation using those, and if there's no more questions, then thank you and see you on Friday.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = \"\"\n",
    "\n",
    "# Iterate over files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".mp3\"):\n",
    "        audio_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Transcribe the audio\n",
    "        transcription_result = model.transcribe(audio_path)\n",
    "\n",
    "        # Append the result to the string\n",
    "        result += transcription_result[\"text\"] + \"\\n\"\n",
    "\n",
    "# Now, 'result' contains the concatenated transcripts of all mp3 files in the folder\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86353295-6806-4dd0-8f72-f22241a514c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "203"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
    "\n",
    "# Split the documents into chunks\n",
    "chunks = text_splitter.split_text(result)\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19843e57-9f15-41a4-9c01-c29f6916033e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file has been updated at chunks.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"chunks.json\" download>Download json file containing chunks.</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def save_json_to_file(data, filename):\n",
    "    file_path = \"chunks.json\"\n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(file_path):\n",
    "        print(\"file already exists\")\n",
    "        # Load existing JSON data from the file\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            existing_data = json.load(json_file)\n",
    "    else:\n",
    "        # If the file doesn't exist, initialize an empty list\n",
    "        existing_data = []\n",
    "\n",
    "    # Append the new array to the existing data\n",
    "    existing_data.extend(chunks)\n",
    "\n",
    "    # Convert the combined data to JSON format\n",
    "    json_data = json.dumps(existing_data, indent=4)\n",
    "\n",
    "    # Write the JSON data back to the file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json_file.write(json_data)\n",
    "\n",
    "    print(f\"JSON file has been updated at {file_path}\")\n",
    "\n",
    "def generate_download_link(filename):\n",
    "    download_link = f'<a href=\"{filename}\" download>Download json file containing chunks.</a>'\n",
    "    display(HTML(download_link))\n",
    "\n",
    "# Example usage:\n",
    "data = chunks\n",
    "filename = \"chunks.json\"\n",
    "save_json_to_file(data, filename)\n",
    "generate_download_link(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1627b55-a6d2-4441-875e-0fb8a057a397",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
